Construction InnovationExploratory study of using unmanned aerial system imagery for construction site 3D mappingJuliana Sampaio Álvares, Dayana Bastos Costa, Roseneia Rodrigues Santos de Melo, Article information:To cite this document:Juliana Sampaio Álvares, Dayana Bastos Costa, Roseneia Rodrigues Santos de Melo, (2018)"Exploratory study of using unmanned aerial system imagery for construction site 3D mapping", Construction Innovation, https://doi.org/10.1108/CI-05-2017-0049 Permanent link to this document: https://doi.org/10.1108/CI-05-2017-0049Downloaded on: 08 May 2018, At: 05:45 (PT)References: this document contains references to 29 other documents.To copy this document: permissions@emeraldinsight.comAccess to this document was granted through an Emerald subscription provided by emeraldsrm:478304 []For AuthorsIf you would like to write for this, or any other Emerald publication, then please use our Emerald for Authors service information about how to choose which publication to write for and submission guidelines are available for all. Please visit www.emeraldinsight.com/authors for more information.About Emerald www.emeraldinsight.comEmerald is a global publisher linking research and practice to the benefit of society. The company manages a portfolio of more than 290 journals and over 2,350 books and book series volumes, as well as providing an extensive range of online products and additional customer resources and services.Emerald is both COUNTER 4 and TRANSFER compliant. The organization is a partner of the Committee on Publication Ethics (COPE) and also works with Portico and the LOCKSS initiative for digital archive preservation.*Related content and download information correct at time of download.
   Exploratorystudy of using unmanned aerial system imageryfor construction site 3DmappingJuliana Sampaio Álvares, Dayana Bastos Costa andStudy of using unmanned aerial systemRoseneia Rodrigues Santos de MeloDepartment of Structural and Construction Engineering,Federal University of Bahia, Salvador, BrazilAbstractPurpose – The purpose of this paper is to present an exploratory study which aims to assess the potential use of 3D mapping of buildings and construction sites using unmanned aerial system (UAS) imagery for supporting the construction management tasks.Design/methodology/approach – The case studies were performed in two different residential construction projects. The equipment used was a quadcopter equipped with digital camera and GPS that allow for the registry of geo-referenced images. The Pix4D Mapper and PhotoScan software were used to generate the 3D models. The study sought to examine three main constructs related to the 3D mapping developed: the easiness of development, the quality of the models in accordance with the proposed use and the usefulness and limitations of the mapping for construction management purposes.Findings – The main contributions of this study include a better understanding of the development process of 3D mapping from UAS imagery, the potential uses of this mapping for construction management and the identification of barriers and benefits related to the application of these emerging technologies for the construction industry.Originality/value – The importance of the study is related to the initiative to identify and evaluate the potential use of 3D mapping from UAS imagery, which can provide a 3D view of the construction site from different perspectives, for construction management tasks applications, trying to bring positive contributions to this knowledge area.Keywords Construction management, Photogrammetry, 3D mapping,Construction sites and buildings, UAS imagery, Unmanned aerial system (UAS)Paper type Case studyIntroductionThe construction projects are complex and dynamic in nature, being characterized by usual tasks fragmentation. Therefore, the construction industry has been investing in new visual technologies to improve the management process of construction, making it easier, more effective and efficient and with ever-higher quality. Among these visual technologies,Received29 May 2017Revised13September201720November2017 Accepted 7 February2018studies have pointed out the potential of using 3D mapping of construction sites and buildings from unmanned aerial systems (UASs) imagery to assist in management tasks (Kim et al., 2016; Han and Golparvar-Fard, 2017).UASs are aircrafts that function without a human pilot onboard (Puri, 2005). Thistechnology has attracted attention for applications in Architecture, Engineering andConstruction (AEC) (Puri, 2005; Kim and Irizarry, 2015; Irizarry and Costa, 2016; Melo et al., 2017). Such applicability is related to some UAS attributes including high mobility, easiness of use, agility, low-cost, high capacity of data acquisition from different angles and heights,Construction Innovation© EmeraldPublishingLimited1471-4175 DOI 10.1108/CI-05-2017-0049from difficult-to-access areas and the possibility to attach different kinds of devices to UASs (cameras, thermal sensors, infrared sensors, lasers, radars, gyroscopes, GPS – Global Positioning System) (Puri, 2005; Eisenbeiß, 2009; Siebert and Teizer, 2014).  Regarding to UASs operation regulation, the rules to civilian uses are established by different countries regulations. In Brazil, the legal operations with UASs are regulated and monitored by the National Civil Aviation Agency (Agência Nacional de Aviação Civil – ANAC). In its regulation, ANAC (2017), the UASs are classified based on their maximum takeoff weight and the aspects of their operation, including its purpose and the line of sight requirements (Visual Line of Sight – VLOS or Beyond Visual Line of Sight – BVLOS). In the USA, the Federal Aviation Administration (FAA) is the entity in charge of defining the rules for the use of UASs. According to the FAA (2016), flights with small UASs (less than 25 kg) are allowed under the following conditions: flying only in VLOS, operated by a certificated pilot and under the maximum altitude of 120 m (FAA, 2016). In Europe, European Aviation Safety Agency (EASA) is responsible for regulating the airspace, and its proposal regulation defines three categories of UAS operations from low to high risk (EASA, 2015). From the activities with lower risk, only flights in VLOS are allowed, a maximum altitude flight of 150 m, covering UASs with maximum take-off mass of 25 kg (EASA, 2015).  The UASs with cameras and GPSs connected to them allow the acquisition of georeferenced images, which containing information about the spatial location of the recorded physical elements, based on a geodetic coordinate system of reference (Kim et al., 2016). Thus, those images can be used for geo-referenced 3D mapping with software, using the digital photogrammetric processing by overlapping images (Kim et al., 2016). Digital photogrammetry enables the automatic reconstruction of a three-dimensional space (or part of it), by computational tools, using a set of two-dimensional digital images (Schenk, 2005). According to Remondino (2011), the photogrammetric processing is able to provide accurate and detailed 3D information, by means of identification of corresponding points between images. The advantage of using UASs for photogrammetry is its greater accessibility and lower cost, with maintenance of good quality and accuracy of the data, compared to conventional aerial photogrammetry methods (Remondino et al., 2011).  In particular, 3D mapping of buildings and surfaces from UAS imagery have been used for assessment of building damage (Roca et al., 2013; Emelianov et al., 2014), photogrammetric surveys of terrain and buildings (Remondino et al., 2011; Siebert and Teizer, 2014), historical heritage conservation (Eisenbeiß, 2009; Li and Li, 2011;), urban planning (Jizhou et al., 2004; Jarzabek-Rychard and Karpina, 2016), among others. The potential use of UAS technology for construction site 3D Mapping has explored recently (Kim et al., 2016), once provide the opportunity to identify different construction site elements simultaneously and some of this elements with difficult access. Siebert and Teizer (2014) highlight the accuracy and reliability of those technologies for supporting topographic surveys and measurements tasks to assist construction management monitoring, based on field tests and 3D models.  Despite the advances in studies that report the use of 3D mapping from UAS imagery in the AEC, there are still gaps regarding to the use of this new technology as a tool for managing tasks in construction, such as work progress monitoring, logistics operations, general visual inspections and measurement of objects. The importance of increasing the knowledge about how visual technologies can be support the effectiveness of valuable information for managing tasks in construction projects is highlighted by different studies. Sadeghpour and Andayesh (2015) point out that one of the main constraints that directly affect the productivity and safety in construction sites is the logistics of the space available to perform the activities. Golparvar-Fard et al. (2015) mention that the difficulty of visualizing the current status of the construction is one of the barriers in the project  
monitoring task. This happens because different activities are carried out simultaneously at the construction sites and sometimes in difficult-to-access areas, which directly affects the operations related to logistics (Sadeghpour and Andayesh, 2015) and visual progress monitoring (Golparvar-Fard et al., 2015).  Therefore, further studies are still needed aiming to highlight the main limitations and benefits of using the technology of 3D mapping from UAS imagery in construction projects, regarding to UAS flight constraints on jobsites and the quality of 3D mapping of construction sites and buildings. In addition, there is a need of a better understanding about how this technology can contribute to the process of construction management, helping and improving the decision-making by managerial project team, including top managers, production managers, engineers, architects, safety managers, among others.  This study aims to assess, in an exploratory way, the use of 3D mapping of construction sites and buildings developed from images collected with UAS as a tool to support construction management tasks, addressing the easiness of development, the quality and the usefulness and limitations of the 3D mapping from UAS imagery for construction management purposes.BackgroundThere are different methods and remote sensing devices that enable visual data acquisition for 3D reconstruction of surfaces, terrain and objects. Among these, the use of optical sensors can be highlighted, including active sensors that use range data, in which laser scanning technologies predominate (for example, the LiDAR – Light Detection and Ranging) and passive sensors that record image data, more specifically high resolution digital cameras (Remondino, 2011; Bemis et al., 2014).  Laser scanners directly capture the 3D geometry of surfaces, generating point clouds with 3D coordinates of each point from the scanning of the scene, especially laser pulse systems with measurement of transmission and return time (Eisenbeiß, 2009; Remondino, 2011). Eisenbeiß (2009) explains that through a laser pulse pointed toward the surface to be mapped, the scanner captures the return of this pulse, and the distance between the sensor and surface is calculated based on the operation time (transmission and return) and the pulse speed. In case of aerial laser scanners, the recorded positions are determined based also on flight altitude and spatial coordinates provided by a GPS, which is usually connected to the device (Eisenbeiß, 2009).  In case of image-based 3D mapping, a computational method and mathematical formulation is necessary to transform measurements based on 2D images into 3D information, through the identification of images correspondence (Remondino, 2011). Bemis et al. (2014) and Remondino (2011) state that the digital photogrammetry can be regarded as the best technique for image data processing, highlighting the automatic photogrammetric processing method, also known as structure from motion (SfM) and dense stereo matching (DSM). Based on the combination of photogrammetry fundamentals and computer vision, 3D mapping software algorithms allow for automatic identification of the overlap of images, matching of common points from different photos and extraction of 3D coordinates of points from the photographed surface (Bemis et al., 2014) generating a geometric model of point cloud.  To obtain good quality 3D mapping, without visual inconsistencies, few requirements must be considered. Authors point out that is necessary to: use more than two images that capture the same points (same elements of the scene), ensure high overlap between images, use a proper visual sensing device to capture images with high resolution and good quality and establish an effective covering of all the area of interest by photographs (PierrotDeseilligny et al., 2011; McCoy et al., 2012; Bemis et al., 2014).  Another important prerequisite for such a mapping method is the scaling and georeferencing requirements for the reconstructed surface, which vary according to their intended use. Some processing software are able to reconstruct a surface without any kind of information about scaling or positioning, but the accuracy and quality of the 3D final product and the extraction of data of scaling from 3D mapping is compromised (Bemis et al., 2014). Commonly, the camera position (coordinates) is obtained from the GPS device.  Owing to the extensive development of image-based 3D reconstruction methods, results with good quality and high resolution, generated by automatic photogrammetric processing, are attained in applications related to development of digital surface models, 3D modeling of cities, 3D monitoring of structures and buildings, construction as-built point cloud models, mapping for historical heritage documentation, 3D modeling for construction project planning, among others (Eisenbeiß, 2009; Remondino, 2011; Golparvar-Fard et al., 2011; McCoy et al., 2012). These 3D uses are similar to the main applications of 3D products from LiDAR and others laser scanning devices (Remondino, 2011).  Bemis et al. (2014) and Pierrot-Deseilligny et al. (2011) highlight the main advantages of photographic sensors in relation to laser scanners, such as greater portability (smaller and lighter), lower power consumption, faster operation, lower costs and the ability of color representation. Thus, the choice between both 3D reconstruction methods presented depends on the purpose and peculiarities of the required application.  Different AEC applications have been exploring the use of 3D models generated by automatic photogrammetric processing (Li and Li, 2011; Golparvar-Fard et al., 2011; Roca et al., 2013; Siebert and Teizer, 2014; Kim et al., 2016; Jarzabek-Rychard and Karpina, 2016). This wide use relates mainly to the improvement of this 3D mapping method, its advantages and the variety of commercial software available, which permits the automatic development of 3D mapping, facilitating its use for different profiles of users.Research methodThe research strategy adopted was the exploratory case study. According to Yin (2014), case study is an empirical research strategy that investigates a contemporary phenomenon within its real-world context, involving qualitative and/or quantitative analyses. Case studies are generalizable to theoretical proposition and do not represent a “sample”, thus the goal will be to expand and generalize theories (analytic generalization) and not to extrapolate probabilities (statistical generalization) (Yin, 2014).The present study was divided into the following stages, detailed in the next sections:  literature review about the 3D mapping technology and the use of UAS imagery for3D mapping in construction applications; equipment and software selection;  development of the case studies; and  data analysis and assessment of results.Based on the literature review, this work established the theoretical proposition that the use of 3D mapping from UAS imagery can contribute to the process of construction management, supporting the decision-making process by managerial project team. Also, to support the data collection and analysis, an analytical framework was developed, according to Figure 1, involving concepts related to the construction sites 3D mapping from UAS imagery, the potential uses of the 3D mapping products for construction management and the factors influencing construction sites 3D mappings (process and products), which aim to support the decision-making process by managerial project team.The equipment used was a quadcopter, DJI Phantom 3 Advanced, which selection is related to an accessible and commercial platform, with features that facilitate their operation at construction sites. The features of the UAS adopted include flight stability, vertical takeoff and landing, light and small equipment, weighing 1,280 g, batteries with maximum flight duration of 20 min, and it is operated by remote control and by using the DJI Go app (using a tablet or smartphone). In addition, it has a 12.4-megapixel camera and a GPS connected, allowing for the capture of geo-referenced images.  The Pix4D Mapper and PhotoScan software were used for automatic photogrammetric data processing and 3D reconstruction. Both of them enable the use of 2D geo-referenced images for automatic development of 3D geo-referenced outputs from the initial generation of point clouds, including 3D textured models, digital surface/terrain models and orthomosaics, which can be exported in different file formats. The PhotoScan and Pix4D also allow for the taking of measurements of distances between points, areas and volumes of surfaces directly on 3D mapping, as well as generate reports with the processing parameters and results.  According to Pix4D (2016) and Agisoft (2016), both software develop 3D mapping initially through the compilation of uploaded images and their subsequent alignment, in which the Pix4D and PhotoScan identify, for each photo, characteristic common points (keypoints). Afterwards, these characteristic points are matched through the overlapping of images, followed by the identification and optimization of the camera positions using geolocated points, based on GPS data and optional Ground Control Points (GCPs) (Pix4D, 2016; Agisoft, 2016). In PhotoScan, such process of the identification of cameras positions is also accompanied by the refinement of the camera calibration parameters (Agisoft, 2016).  The GCPs are points with spatial locations known (for example, measured by a total station), and they can be marked on the ground to be captured by the aerial imagery (Pix4D, 2016). The coordinates of GCPs can be added to the software to aid in the processing of the images, improving the photogrammetric accuracy of results (Pix4D, 2016). The output of this first processing step is a sparse point cloud and a set of camera positions, in which each of the three-dimensional point belonging to the point cloud is formed by a set of key-points (Pix4D, 2016; Agisoft, 2016).  After initial processing stage, the densification of the sparse point cloud is performed, generating a dense point cloud (Pix4D, 2016; Agisoft, 2016). According to Pix4D (2016), the densification of the point cloud occurs only where there is sufficient visual content and it is accompanied by the point filtering. PhotoScan and Pix4D have algorithmic methods which allow the reconstruction and texturing of a 3D polygonal mesh from the point cloud. This 3D mesh is generated through the automatic triangulation of points (geometric reconstruction) and color processing (fitting the texture), thus creating the 3D model of the surface and objects registered in the images (Pix4D, 2016; Agisoft, 2016).Case studiesThe study was conducted in two residential construction projects located in Salvador– Brazil, chosen by represent projects with distinct characteristics (although they are both residential), aiming to represent two different site arrangements and constructive typologies. Table I describes the main features of each project.  A total of nine field visits were carried out for image data collection on construction sites with UAS (four in Project A and five in Project B), as shown in the Table II. The sequence of steps and activities that make up the whole process of image data collection with UAS and processing of 3D mapping is shown in Figure 2, and for supporting and guiding the activities performed in these steps, the following research protocols were used: Planning meeting form: It standardizes data collection for flight planning, defining points of takeoff and landing and indicating areas of interest for 3D mapping. In addition, the physical characteristics of the construction site and surroundings are surveyed, identifying possible barriers to UAS flight mission. UAS flight mission checklist: It records the flight’s technical data and a checklist of all necessary procedures for a UAS flight mission according to safety requirements. Flight log worksheet: It lists all the flight’s data recorded in DJI Go app and UAS flight mission checklist. Visit log worksheet: It provides information about the projects and flight planning and records of all activities carried out during and after field visits.Table I.Project features descriptionProject AProject BResidential high-rise building (single tower)26-story building with a total of 104 unitsLand area: 2,500 m2Construction visited during execution of facade coatings stageVertical profile, with activities concentrated along the towerResidential low-income housing project 91 five-story buildings and five three-story buildings with a total of 1880 units Land area: 150,000 m2Construction visited during foundation, structure lifting and cover assembly stagesHorizontal distribution of the jobsite and activitiesTable II.Field data collection with UASProjectPeriod of visitsNo. of visitsNo. offlightsTotal of photosMaximum flight distance (m)Maximum flight altitude (m)Total flights durationABFour months Five months45912499902734.0173.5120.0 60.01:22:571:47:34After field data acquisition, the images were analyzed, selected and processed at the Lab (the same set of images was processed in both Pix4D and PhotoScan), resulting in 15 3D models from each software (six from Project A and nine from Project B). In total, 30 3D models and their respective quality/processing reports were developed. Figures 3 and 4 present examples of 3D mappings developed.  In addition to the data collection with UAS, field activities in the case studies also included interviews with project management teams, which were carried out to assess the usefulness of 3D mapping as a supporting tool for some construction tasks, according to potential users’ perception. In this study, the all potential users available that were part of the construction management teams from the case studies A and B (listed in Table III) were interviewed, not being considered external potential users or specialists. Therefore, in total, nine interviews were conducted (five in Project A and four in Project B). For these interviews, two sets with three 3D models each (defined as the most representative models of each project) were presented, in way that the interviewees examined only the three models referring to their own project, which were processed by Pix4D software, as presented in Table III.The interviews script includes the following topics: general information of the interviewee; general perception of the interviewee about the construction tasks in which 3D mapping could be used and its limitations observed, including open questions such as: “In what construction management tasks performed in your own project, do you think that the set of 3D models presented could be used as support tool?”, and “What would you like to be able to view about the project through the 3D mapping presented, but it was not possible?”;Table III.Interviewees and 3D models presentedProjectSets of 3D models presentedIntervieweesABModel_4AModel_5AModel_6AModel_2BModel_3BModel_6BDirector of construction companyConstruction safety managerConstruction architectConstruction engineer Surveyor technicianConstruction managerConstruction engineerTwo engineering interns assessment of the degree of usefulness of 3D mapping for pre-selected tasks according to the literature review (jobsite logistics, visual monitoring of work progress and measurements tasks), using a five-level Likert Scale (lowest, low, medium, high and highest); and assessment of the degree of interferences caused by visual inconsistencies (distortions, shadows and visual content gaps) in use of 3D models, also using a five-level Likert Scale.Data analysisThe data analysis was based on the evaluation criteria presented in Table IV, including three main constructs, associated to variables and sources of evidence. Those  
Easiness of development of 3D mapping from UAS imageryQuality of 3D models developedUsefulness and limitations of 3D mapping for construction tasks application Analysis of the aspects of image acquisition with UAS and data processing that interfere in the easiness of the development of 3D mappingAnalysis of technical parameters provided by software processing/quality reports and visual inconsistencies identified in 3D modelsIdentification of construction tasks with potential for using 3D mapping and assessment of the usefulness of the mapping to thosetasks as an auxiliary toolImage collection with UAS: Access to suitable sites for takeoff and landing Number of points for takeoff and landing Physical barriers that cause interference in UAS flight mission Disruptions on constructionsiteDifficulties related to UAS flight missionSoftware processing:Processing timeTechnical parameters: Average ground sampling distance (GSD) of the images Percentage of covered area with overlap of over five images per pixelVisual inconsistencies: DistortionsShadowsVisual content gapsConstruction tasks in which 3D mapping could be used Main limitations of 3D mapping Degree of 3D mappingusefulness for preselected tasks Direct observation Data collected from protocols Software processing/ quality reportsSoftware processing/ quality reports Interviews with potential users Direct observationInterviews with potential usersDirect observationTable IV. Evaluation criteria for the use of 3D mapping from UAS imagery  
constructs and variables have been defined based on literature review and previous studies.Results Easiness of development of 3D mapping from unmanned aerial system imageryImage collection with unmanned aerial system. During the flights performed in Project A, no significant presence of physical barriers and obstacles to fly the UAS was noticed and no flight limitation concerning the regulation was observed. In addition, suitable locations for takeoff and landing were found, requiring only two different locations, within the jobsite limits, to cover the entire area of interest.  However, in Project B, the UAS takeoff and landing location from the construction site was not possible, owing to the constrained jobsite with restricted accesses and the fact that it was located in a dense populated urban area with buildings closely surrounding it. The takeoff and landing locations in neighboring condominium areas were an alternative and used based on the permission of people in charge of those condominiums. To cover the four facades of the building and external areas of the jobsite in Project B, four different takeoff and landing locations were required.                   The difficulties of performing a single photo shoot to evenly cover the whole Project B tower resulted in the development of different 3D models for each building side (facade). In addition, due to restricted conditions of flights, recommendation of maximum height of 60 m in dense urban areas and VLOS requirement (ANAC, 2017), effective coverage of the top (around 80 m tall) and corners of building was not possible.  In addition, strong winds during two flights in Project B prematurely ended data collection in an unplanned manner.  According to Agisoft (2016), the corners can be classified as “blind-zones” because to rebuild their geometry at least two images with sufficient overlapping are required, to capture the same points. Therefore, by trying to combine image sets of different facades for the development of a single 3D model, the perceived visual distortions in these “blind-zones” (corners) were marked, causing unsatisfactory results, which justified the development of different 3D models for each building facade.  With regards to disruptions in construction activities, in Project A there was no record of any kind of interference. On the other hand, in Project B it was necessary to interrupt the crane operation during flights, to avoid any possibility of an accident.  In relation to UAS operational difficulties, some signal losses can be highlighted, in which the connection between the aircraft and control station was lost. However, due to the “Return to Home” failsafe system of DJI Phantom 3 Advanced, the UAS returned to the takeoff point safely in all occurrences. Thus, such difficulty was not considered as having significant impact on expected results, both in relation to flight’s safety, regarding to device integrity and mainly to the safety of the people involved (workers and people connected directly to flight missions) and for each mission’s purpose (image data to be collected). Before each flight all workers and persons present in construction sites were informed about the UAS flight mission.  Another aspect related to the UAS used was the optimization of batteries duration. For the present study, three batteries were used, with flight duration of around 20 min each; however, for safety purposes, each battery was used for an average of 15 min. It was observed that the flight total time of 45 min was not limiting for obtaining the number of images required for full coverage of areas of interest in both projects.  Data processing by Pix4D and PhotoScan. During the data processing stage using Pix4D and PhotoScan, the most important criterion analyzed was the processing time for densification and texturization of 3D models (Table V and Figure 5). This time is directly related to computer configuration, number of images uploaded, processing parameters chosen and particularities of each software’s implementation of the automatic photogrammetric processing method.  According to the specifications suggested by Pix4D (2016) and Agisoft (2016), the computer used (Intel VR ® CoreTM i7 – 4790 QM CPU @ 3.60 GHz, with 32 GB RAM and 240 GB SSD) met these parameters, and in some aspects, it even surpassed the recommended configuration for proper software performance, which makes data processing faster.  Despite the relative difference in how each software processes data, which influences processing time, some processing parameters were chosen aiming to obtain 3D models comparable between different software. Such parameters are also related to the 3D models’ quality expected. Thus, this aspect must be also considered for parameter choice.A 1A2A3A4A5A6AProject A averageB 1B2B3B4B5B6B7B8B9BProject B average513017791339868 9773889172119484158 7600:22:1300:12:4400:04:5000:51:1000:57:4100:56:2200:34:1001:19:5500:32:3501:02:4801:20:3800:43:1501:25:0900:16:5700:17:4001:04:3300:53:4300:21:2000:11:2800:05:3900:30:4501:08:2900:42:5900:30:0700:41:0200:34:5100:37:0200:44:4800:24:3701:04:5200:12:4900:13:5500:19:0800:32:3400:21:4600:12:0600:05:1500:40:5801:03:0500:49:4000:32:0801:00:2900:33:4300:49:5501:02:4300:33:5601:15:0100:14:5300:15:4700:41:5100:43:09Table V.Number of uploaded images and 3D models processing time              No. of uploaded	Pix4D processing	Photo Scan	Overall average time per Project	3D model	images	time	processing time	model and per projectAccording to the Table V and Figure 5, more images tended result in longer processing time in almost all models (Model 6B – second with more images and greater overall average of processing time and Model 3A – smallest number of uploaded images and lower overall average of processing time). For both Projects A and B, in most of the models (except three of 15 developed), Pix4D presented longer processing time than PhotoScan (Table V). Comparing the projects, Project B models presented greater average per software and highest overall average, 43 min and 9 s to 76 images, as opposed to 32 min and 8 s to 68 images of Project A.  Despite differences observed, no 3D mapping took more than one and a half hour for complete densification and texturization, and this time can be considered as a compatible processing time for the proposed use of 3D mapping highlighted by the study.Quality of 3D models developed                 Technical parameters. Technical parameters extracted from quality/processing reports were analyzed based on their correlation with the quality of 3D mapping, including average ground sampling distance (GSD) of the images and percentage of covered area with good overlap of images. Such parameters depend on the mapped area characteristics, the flight plan, how the images were captured and the particularities of the implementation of the automatic photogrammetric processing method of each 3D  mapping software.  The GSD or image spatial resolution represents the correlation of the linear distance between two consecutive pixel centers (pixel size) on the image, with the actual measurement in the field, that is, the average GSD is the effective surface resolution on the aligned image set (Pix4D, 2016; Agisoft, 2016; Poser, 2012). The higher the GSD is from photogrammetric analysis of the image the lower the perceived level of image spatial resolution and details visualized, making the match of points in common among uploaded images harder for the development of 3D mapping (Pix4D, 2016). Such parameter is mainly related to the average of flight height, the camera focal length distance, camera angle, different levels of surface elevation and images’ imperfections (Pix4D, 2016; Poser, 2012). Table VI presents the average GSD of the 3D models.  Based on Table VI, the overall average of GSD for Project A (4.96) was higher than it was for Project B (2.43), as well as the average per software, suggesting an easier 3D reconstruction of Project B models, both by Pix4D and PhotoScan.  Nevertheless, the results also indicate that the spatial resolution level and details perceived by PhotoScan in the images of all developed 3D models (in both projects) were relatively higher than the levels perceived by the Pix4D processing. It is believed that the reason for such difference between the average GSD computed by the two software could be the implementation of the processing method of each one, considering it was used the same image set and the 3D mappings were developed under similar conditions (same computer and similar processing parameters chosen). However, this study did not propose itself to evaluate the functioning behind the software applications.Table VI.Average GSD of 3DmodelsProject	3D modelAverage GSD –Pix4D (cm)Average GSD –PhotoScan (cm)Overall average per model and per project (cm)A 1A2A3A4A5A6AProject A averageB 1B2B3B4B5B6B7B8B              9B Project B average3.193.3016.085.69 2.577.236.343.73 3.46 4.37 1.79 2.61 4.35 3.82 3.683.493.482.752.025.91 4.30 1.884.563.571.92 1.33 1.66 1.22 1.11 1.31 1.09 1.151.661.382.972.6611.005.00 2.235.904.962.83 2.40 3.02 1.51 1.86 2.83 2.46 2.422.582.43Concerning the level of the overlap of images, the higher this level is, the better the quality of surface 3D reconstruction is. When there is a high degree of the overlap of two images, the common captured area is greater, thus, more points (key-points) can be matched between the photos (Pix4D, 2016). Therefore, the image acquisition plan must be carefully designed to ensure sufficient overlap of images (Pix4D, 2016).  Although it is possible to perform UAS autonomous flights, through specialized software that enables scheduled recording of images based on fixed parameters, such as the uniform rate of images overlapping, in the study only manual flights were performed. The reason for this choice was because Project B was a high rise-building, with vertical elements to be recorded, which made the fully autonomous flight infeasible, in addition to ANAC’s requirement (ANAC, 2017), which does not recommend UAS autonomous flight in dense populated urban areas in Brazil.  In Table VII the percentages of covered areas with good overlap of images (over five images computed per pixel, in accordance to an average scale between the parameters presented by both software) are shown. Those percentages were obtained by the treatment of areas represented in graphs available in quality/processing reports generated by Pix4D and PhotoScan.  Based on individual results of the models (Table VII), more than 55 per cent of the covered areas in all models of both projects, developed in both Pix4D and PhotoScan, presented overlap of over five images per pixel. Additionally, the averages per project were all above 77 per cent (for data processing in both software), representing relatively satisfactory results, especially considering the manual flight modality.  According to the overall overlap average per project (Table VII), Project B models presented a slightly higher percentage of covered area with good overlap of images (85.36 per cent) than the Project A models (84.87 per cent). Regarding the both software result, the PhotoScan indicated a higher overall percentage of covered area with good overlap of images than Pix4D; meanwhile, the overall results point that the products generated by both software were satisfactory for the proposed goal, and the differences from the specific  
Percentage of covered area	Percentage of covered area with	Overall average with overlap of over five	overlap of over five images per	per model andProject	3D model	images per pixel – Pix4D (%)	pixel – PhotoScan (%)	per project (%)A	1A55.5893.1674.372A65.7195.5780.643A82.2868.5775.434A67.2198.0782.645A94.67100.0097.346A99.7397.8698.80Project A average77.5392.2184.87B	1B71.6899.3485.512B72.3493.3682.853B98.0198.5198.264B95.1992.5193.855B92.6481.9687.306B74.1395.8284.987B65.3984.7375.068B94.5880.4787.539B60.5485.2372.89Project B average80.5090.2185.36  
Table VII.Percentages of covered areas in 3D models with overlap of over five images per pixelfunctioning of the processing method behind each software were not evaluated, as mentioned before.  Visual inconsistencies. The visual inconsistencies of 3D models are arising from bugs in texturing of the area of interest and may be caused by visual interferences captured in the photographs, such as moving objects and surfaces without enough texture variation and by images recorded from unfavorable angles and heights.                 Among the types of visual inconsistencies analyzed, the occurrence of: distortions (Figure 6),  visual content gaps (Figure 7) and shadows (Figure 8) were noted. The distortions occur when there is no exact definition of the geometry of the surface texturized and a kind of blur in 3D model occurs. The visual content gaps occur when there is not enough visual content of a particular area to compute 3D points, that is, there were insufficient records of this area in uploaded photos, and they can still occur when the automatic correlation of points of a particular area is hampered by the presence of uniform textures. Finally, the shadows are related to luminosity and the sun’s position at the moment of the photo shoot.
The results presented in Table VIII show that in general (considering the average rating for both projects), among distortions, shadows and visual content gaps, the interviewees assessed the level of distortions as the defect that most hampers the use of 3D mapping (3.15), followed by visual content gaps (2.93) and shadows (2.28).  Except for the shadows’ results, the highest interference levels by visual inconsistencies were obtained for Project B 3D models. Such an occurrence can be associated with the capture of moving elements causing distortions, such as the safety net of building facade, in addition to the physical flight limitations, which often hamper the registration of certain points that were part of the area of interest, causing visual content gaps.  Even though a considerable part of these visual defects was caused by circumstantial events, the lack of more efficient flight planning also contributed to the occurrence of some inconsistencies. However, the results show overall averages lower than 3 for two inconsistencies on a scale of 1 to 5, and an average of slightly above 3 (3.15) for the other one, indicating that these interferences were not very impacting in the use of the 3D mapping, according to the interviewees’ perception.  Although only the 3D models developed by Pix4D software have been assessed in the interviews, according to the researchers’ visual observation, the same kind of visual inconsistencies were identified in 3D models generated by PhotoScan. For this specific study, the levels of distortions and visual content gaps perceived in the 3D models by PhotoScan seemed to be smaller, thus, PhotoScan generated 3D models a slightly more complete and uniform than Pix4D for the same set of images uploaded, according to researchers’ observation. However, further simulations and a proper analyze need to be developed for understand the real difference between the software for this aspect.Usefulness and limitations of 3D mapping for construction task applicationTable IX presents the interviewees’ perceptions of construction tasks in which 3D mapping could be used as well as, its limitations. Table X presents the assessment of the degree of usefulness of 3D mapping for construction tasks, pre-selected based on the literature review.Table VIII.Averages ofVisual inconsistences	Project A averages (n = 5)	Project B averages (n = 4)	Overall averages (n = 9)interference levels byDistortions	2.80	3.50	3.15	visualVisual content gaps 2.60 3.25 2.93 inconsistencies in 3D Shadows 2.80 1.75 2.28 models (Likert scale)  
Potential uses of3D mappingLimitations of 3D                    mapping Table IX.Potential uses of 3D mapping andlimitations observedJobsite logisticsVisual monitoring of work progressConstruction planning Monitoring of construction tasks and identification of general errors Jobsite general visualizationLack of details in close range view of 3D reconstructed elements Difficulty of viewing the insides of buildings Presence of visual defects and content gapsVisual monitoring of work progress Jobsite general visualizationVisualization of some safety devices(external elements)Jobsite logisticsSome visual inspectionsLack of details in close range view of3D reconstructed elementsDifficulty of viewing the building top  
Table X.Assessment of the degree of usefulness of 3D mapping for preselected tasks(Likert scale)Construction tasks   Project A averages (n = 5)   Project B averages (n = 4)Overall averages(n = 9)Jobsite logisticsMeasurements tasksVisual monitoring of work progress4.804.003.404.253.504.004.53 3.753.70Based on the results (Table IX), jobsite logistics, visual monitoring of work progress and jobsite general visualization were listed as the main common potential applications for 3D mapping, according to the interviewees from both projects. In terms of the common limitations identified, in both studies the lack of details in close range view of 3D reconstructed elements was questioned, making it not possible to analyze constructive details through 3D models. Individually, the difficulty to visualize the inside of buildings was pointed out in Project A, which is associated with UAS technology limitations and the difficulty of viewing the building top of Project B because of the ANAC’s recommendations for flights.  Based on the results shown in Table X, the potential of 3D mapping of construction site and buildings for jobsite logistics (4.53) is greater, followed by measurements tasks (3.75) and visual monitoring of work progress (3.70). The logistics aspects most commented on were the possibility of analyzing the storage locations, the places for loading and unloading materials, internal routes of pedestrian and equipment traffic and spatial visualization of work locations and of sequence of activities in the jobsite, as shown in Figure 9. For the visual monitoring of work progress, which was best assessed in Project B (average of 4.00), Figure 10 presents an example of construction progress observed in the back facade of the tower through 3D mapping.ConclusionsThis paper presents the results of the potential use of 3D mapping for construction management based on two case studies developed in residential construction projects, with distinct characteristics. In addition, a set of criteria were defined to evaluate the 3D mapping including easiness of model development, 3D model quality and usefulness and limitations of 3D mapping for construction management use.Figure10.Example of scheme with construction progress of theProject B back facade, using the 3D mappingThe findings showed that 3D mapping from UAS imagery can offer a wide, fast and external view from different perspectives on the construction site, facilitated by greater interactivity between user and tool, as both 360° viewing and manipulation of 3D models are possible.  With respect to the potential noted for the projects studied, better results were observed in Project A than in Project B. The difference in results can be because of the horizontal profile of the construction site layout in Project A and its location, facilitating image collection with UAS. In addition, Project A 3D models demanded smaller amounts of images for covering a larger area and it was possible to obtain good results with less processing time.  Regarding to the quality analysis, a higher overall average of GSD for Project A was noticed. It can be justified mainly by a larger variation of height captured by the images recorded in Project A. In relation to the percentage of area covered with good overlap of images, positive results were generally obtained.  In comparison between the two software, the results indicated that both are suitable for the proposed use, presenting satisfactory results. However, some differences were observed. Regarding to processing time, for example, the Pix4D took more time than PhotoScan to processing most of the 3D models generated in the study, considering the same set of uploaded images, processing machine and comparable processing parameters.  According to the potential users’ perception (the construction management teams from the case studies A and B), jobsite logistics, visual monitoring of work progress, jobsite general visualization and some measurement tasks were identified as the main potential use for the 3D mapping. However, some limitations were identified related to the UAS device and its local regulation criteria (ANAC regulation from Brazil), such as the difficulties of visualization inside of buildings and the top of the building when it is higher than maximum height recommended by regulation.Barriers related to the use of 3D models were also identified, including the lack of details in close range view of 3D reconstructed elements and the presence of some visual defects. They were primarily caused not only by circumstantial events or inherent characteristics, such as the presence of moving objects, the occurrence of strong winds and the presence of elements with uniform textures, but also some aspects related to flight plan mistakes and variances in the UAS operations control could be impacting, as it was performed by manual flights. Nevertheless, according to the users’ perception, the visual inconsistencies identified do not represent a great impact for the proposed use of 3D mapping.  Therefore, the main contribution of the study is a better understanding of the potential uses and contribution of 3D mapping from UAS imagery to the process of construction management, supporting the decision-making process by managerial project team. Also, in terms of practical contribution, this paper provides useful information, including computing time with the specific computer configurations to process certain sets of images, performance differences between two software applications and feedback from field practitioners about the qualities of output models. This sort of information would be helpful for modelers and other personnel in relevant areas to consider when they make decisions to choose a software application for their projects.  Despite some particularities observed in the case studies performed, globally the construction industry presents common managerial issues that could be improved by using the technology of construction sites 3D mapping from UAS imagery, highlighting the meaningfulness of the study results. Owing to the exploratory nature of this study, future studies are needed to evaluate systematically the use of 3D mapping in construction, testing its incorporation into the construction management processes and assessing the improvements reached in those processes by using the 3D mapping, to assist in decision-making.ReferencesAgência Nacional de Aviação Civil (ANAC) (2017), “Regulamento brasileiro da aviação civil especial (RBAC-E n°94)”, Brasilia, DF.Agisoft (2016), Agisoft PhotoScan User Manual: Professional Edition, Version 1.2, p. 102.Bemis, S.P., Micklethwaite, S., Turner, D., James, M.R., Akciz, S., Thiele, S.T. and Bangash, H.A. (2014), “Ground-based and UAV-based photogrammetry: a multi-scale, high-resolution mapping tool for structural geology and paleoseismology”, Journal of Structural Geology, Vol. 69 (Part A), pp. 163-178.Eisenbeiß, H. (2009), UAV Photogrammetry, Robinson Eidgenössische Technische Hochschule (ETH), Zurich.Emelianov, S., Bulgakow, A. and Sayfeddine, D. (2014), “Aerial laser inspection of buildings facades using quadrator”, Procedia Engineering, Selected papers from Creative Construction Conference 2014, CC2014, Vol. 85, pp. 140-146.European Aviation Safety Agency (EASA) (2015), “Advance notice of proposed amendment 2015-10”.Federal Aviation Administration (FAA) (2016). “Advisory circular N° 107-2”, Washington, DC.Golparvar-Fard, M., Peña-Mora, F. and Savarese, S. (2011), “Integrated sequential as-built and asplanned representation with D4AR tools in support of decision-making tasks in the AEC/FM industry”, Journal of Construction Engineering and Management, Vol. 137 No. 12, pp. 1099-1116.Golparvar-Fard, M., Peña-Mora, F. and Savarese, S. (2015), “Automated progress monitoring using unordered daily construction photographs and IFC-based building information models”, Journal of Computing in Civil Engineering, Vol. 29 No. 1, p. 04014025.Han, K.K. and Golparvar-Fard, M. (2017), “Potential of big visual data and building information modeling for construction performance analytics: an exploratory study”, Automation in Construction, Vol. 73 (January), pp. 184-198.Irizarry, J. and Costa, D.B. (2016), “Exploratory study of potential applications of unmanned aerial systems for construction management tasks”, Journal of Management in Engineering, Vol. 32 No. 3.Jarzabek-Rychard, M. and Karpina, M. (2016), “Quality analysis on 3D building models reconstructed from UAV imagery”, Proceedings of the International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences, Prague, pp. 1121-1126.Jizhou, W., Zongjian, L. and Chengming, L. (2004), “Reconstruction of buildings from a single UAV image”, Proceedings of the International Society for Photogrammetry and Remote Sensing Congress (ISPRS), Istanbul, Vol. 20, pp. 100-104.Kim, S. and Irizarry, J. (2015), “Exploratory study on factors influencing UAS performance on highway construction projects: as the case of safety monitoring systems”, Proceedings of the Conference on Autonomous and Robotic Construction of Infrastructure, Iowa State University, Ames.Kim, S., Irizarry, J., Costa, D.B. and Mendes, A.T.C. (2016), “Lessons learned from unmanned aerial system-based 3D mapping experiments”, Proceedings of the Conference of Associated Schools of Construction, Associated Schools of Construction, Provo, Vol. 52.Li, Z. and Li, Y. (2011), “Photogrammetric recording of ancient buildings by using unmanned helicopters - cases in China”, Proceedings of the International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences (ISPRS), Zurich, Vol. 38, pp. 189-193.McCoy, A.P., Golparvar-Fard, M. and Rigby, E.T. (2012), “Reducing barriers to remote project planning:comparison of low-tech site capture approaches and image-based 3D reconstruction”, Journal of Architectural Engineering, Vol. 20 No. 1, p. 05013002.Melo, R.R.S., Costa, D.B., Álvares, J.S. and Irizarry, J. (2017), “Applicability of unmanned aerial system (UAS) for safety inspection on construction sites”, Safety Science, Vol. 98 (October), pp. 174-185.Pierrot-Deseilligny, M., De Luca, L. and Remondino, F. (2011), “Automated image-based procedures for accurate artifacts 3D modeling and orthoimage generation”, Geoinformatics FCE CTU, Vol. 6, pp. 291-299.PIX4D (2016), Pix4Dmapper Manual 2.1, Lausanne, p. 323.Poser, J. (2012), “Comparative imagery analysis of non-metric cameras from unmanned aerial survey aircraft”, papers in Resource Analysis - Saint Mary’s University of Minnesota Central Services Press, Vol. 14.Puri, A. (2005), “A survey of unmanned aerial vehicles (UAV) for traffic surveillance”, University of South Florida, Tampa, FL.Remondino, F. (2011), “Heritage recording and 3D modeling with photogrammetry and 3D scanning”, Remote Sens, Vol. 3 No. 6, pp. 1104-1138.Remondino, F., Barazzetti, L., Nex, F., Scaioni, M. and Sarazzi, D. (2011), “UAV photogrammetry for mapping and 3D modeling – current status and future perspectives”, Proceedings of the International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences (ISPRS), Zurich, Vol. 38, pp. 25-31.Roca, D., Lagüela, S., Díaz-Vilariño, L., Armesto, J. and Arias, P. (2013), “Low-cost aerial unit for outdoor inspection of building façades”, Automation in Construction, Vol. 36 (December), pp. 128-135.Sadeghpour, F. and Andayesh, M. (2015), “The constructs of site layout modeling: an overview”, Canadian Journal of Civil Engineering, Vol. 42 No. 3, pp. 199-212.Schenk, T. (2005), Introduction to Photogrammetry, The Ohio State University, OH.Siebert, S. and Teizer, J. (2014), “Mobile 3D mapping for surveying earthwork projects using an unmanned aerial vehicle (UAV) system”, Automation in Construction, Vol. 41 (May), pp. 1-14.Yin, R.K. (2014), Case Study Research: Design and Methods, 5th ed., SAGE Publication, Thousand Oaks, CA.Corresponding authorJuliana Sampaio Álvares can be contacted at: alvares.juliana@hotmail.comFor instructions on how to order reprints of this article, please visit our website:www.emeraldgrouppublishing.com/licensing/reprints.htm Or contact us for further details: permissions@emeraldinsight.com  CI    Study of using unmanned aerial system  CI  Study of using unmanned aerial system  