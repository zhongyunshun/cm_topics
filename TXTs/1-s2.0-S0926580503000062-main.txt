	Automation in Construction 12 (2003) 407–417	www.elsevier.com/locate/autconEvaluating the value IT adds to the process of project information management in constructionRodney A. Stewart*, Sherif Mohamed1School of Engineering, Griffith University, Gold Coast Campus, PMB 50 Gold Coast Mail Centre, Queensland, QLD 9726, AustraliaAccepted 8 January 2003Abstract   This paper looks at the potential applications and benefits of using the Balanced Scorecard (BSC) as a framework to evaluate the value IT adds to the process of project information management in construction. The paper builds upon recently published works by the authors, by further strengthening the conceptually developed ‘Construct IT’ BSC framework, through the validation of the frameworks five (5) IT-related performance measurement perspectives and associated performance indicators. Construction professionals from large construction contracting and project management organisations located within Australia were used as the target group for a questionnaire survey. The survey results supported the five perspective ‘Construct IT’ BSC framework. Evidence of reliability and validity is presented for the conceptual framework. D 2003 Elsevier Science B.V. All rights reserved.Keywords: Balanced scorecard; Information technology; Performance measurement; Information management; Construction projects1. Introduction  During the last decade or so, significant productivity improvements experienced by a wide range of industries have been associated with IT implementation. IT has provided these industries with great advantages in speed of operation, consistency of data generation, accessibility and exchange of information. However, despite the well-documented high expectations of construction organizations achieving ITinduced improved responsiveness, efficiency and con-trol of business operations [1,2], some of these organisations are dissatisfied by their IT investments [3]. This dissatisfaction is due in part to the limited understanding about the definition and measurement of IT [4], leading to some concerns as to the value IT adds to the process of project information management in construction. In an attempt to evaluate this degree of IT-induced value adding, Stewart and Mohamed [5] argue that organizations should adopt sound and consistent IT performance evaluation techniques that allow for benchmarking the overall performance improvement resulting from IT investments.   * Corresponding author. Tel.: +61-75552-8778; fax: +6175552-8065.E-mail addresses: r.stewart@mailbox.gu.edu.au (R.A. Stewart),s.mohamed@mailbox.gu.edu.au (S. Mohamed).1Tel.: +61-75552-8572; fax: +61-75552-8065.  This paper adopts an information-centric definition, which encompasses the use of electronic machines and programs for the processing storage, transfer and presentation of information. This is to demonstrate the key role that IT plays in improving0926-5805/03/$ - see front matter D 2003 Elsevier Science B.V. All rights reserved.doi:10.1016/S0926-5805(03)00006-2  
the effectiveness of communication and information exchange in the context of managing a construction project. Additionally, the paper focuses only on the IT performance evaluation phase due to the perceived lack of an appropriate IT performance measurement framework, developed specifically for construction projects [6]. The paper provides a framework to assist construction organisations to evaluate the value IT adds to the process of project information management. The proposed framework is in the form of a Balanced Scorecard (BSC), which incorporates five (5) IT-related performance measurement perspectives and associated performance indicators [5,7]. The framework reliability and validity was tested through a questionnaire survey approach targeting large construction contractors and project managers in Australia. The paper has been organised as follows. The first section provides a brief background on the design and development of the theoretical framework and associated performance perspectives and indicators. Following this is the description of the theoretical framework and associated performance perspectives and indicators. Then, the methodology of the study is described, followed by the results of the analysis. Finally, the paper ends with some implications for practitioners, suggestions for future research and conclusions.2. Theoretical framework  Generally, IT investment appraisal is more difficult than other investment decisions because IT-induced benefits are hard to identify and quantify [8]. As a consequence, more traditional investment appraisal methods such as Return on Investment (ROI), Net Present Value (NPV) or Internal Rate of Return (IRR) have been difficult to apply despite being widely understood by senior managers [9]. The IT productivity paradox prompted calls for new approaches to evaluate IT-related investments [10].  In an attempt to address the IT productivity paradox in the context of project information management in construction, the authors recently conducted a comprehensive review of IT performance evaluation frameworks [5,7]. As a result, this paper suggests that the BSC has the potential to help organisations to identify and evaluate the value IT adds to the process of project information management, in a holistic manner, through the process of benchmarking.2.1. ‘Construct IT’ BSC  In an attempt to provide a balanced approach to IT performance evaluation, the authors recently developed an IT performance evaluation framework, in the form of a ‘Construct IT’ BSC, for the construction industry [5]. This framework incorporates five (5) robust IT-related performance measurement perspectives: (1) operational; (2) benefits; (3) user orientation; (4) strategic competitiveness; and (5) technology/system (see Fig. 1). These perspectives and their associated indicators were customised for the specific elements of IT and construction. The framework utilises project-, tool- and process-specific IT indicators designed to reflect the particular aspects where IT implementation can improve project-based information management processes. In a more recent industrybased case study, which utilised the framework for the evaluation of a web-based communication system on a construction project, individual indicators were developed, screened and refined for each perspective of the framework [7]. This empirical case study yielded 25 indicators spread across the five perspectives of the framework, for evaluating users’ perceptions of web-based technology. The reader is referred to References [5,7] for a complete description of the ‘Construct IT’ BSC perspectives and indicators utilised herein.  This study goes beyond the initial development and case-specific application of the ‘Construct IT’ BSC by validating framework perspectives and ranking associated indicators. For evaluating the value IT adds to the project information management process, potential indicators were initially extracted from general management, construction management and IT literature [11–16]. The outcome of this review has led to a list containing a large number of potential indicators, for each perspective, deemed to be applicable to measure IT-induced performance. Using industry input, a further screening of this comprehensive list was conducted to ensure validity, reliability and significance of performance indicators [6,7]. This, in turn, has led to two distinct groups of performance indicators. The first of these is objective whereas the second is a subjective group of 30 items.Fig. 1. Proposed ‘Construct IT’ BSC with five performance perspectives [5].The former of these groups focuses on quantitative measures, which are complementary to what is discussed herein, but outside the scope of this paper. The latter is the focus of this paper. Mohamed and Stewart [7] detail the rationale for selecting subjective performance indicators for each perspective (see Table 1).2.2. Perspective dependency and indicator interdependency  In addition to developing and refining IT performance perspectives and indicators, this study attempts to model the dependency of perspectives on indicators and the interdependency of indicators across the five perspectives. To achieve this research objective, the approach utilised was the Performance Measurement Process Framework (PMPF), developed by Kagioglou et al. [17]. The PMPF is in the form of a matrix, which was designed to enhance the measurement properties of the BSC, and encompasses all its elements in a structured layout. The primary advantages of the PMPF are as follows.  (1) The possibility to accumulate the results of each performance indicator and derive a result, which indicates the indicator’s importance in terms of indicator interdependence. This illustrates that the specific indicators developed for a specific perspective might have an influence on another perspective. Therefore, the performance indicators can be analysed to illustrate which are the critical ones, e.g. the ones with a high score that can have influence beyond their own perspective.  (2) The possibility to accumulate the results for each perspective and derive the perspective dependence on indicators. The result can minimise the number of metrics used to determine the goals of the perspective. Additionally, it can illustrate the fact that no one goal can be measured by only one indicator in isolation. Furthermore, it illustrates the importance of understanding and clarifying the relationships between indicators.  The application of the PMPF concept in this study is illustrated further in Section 5 of this paper. For a more detailed explanation of the intricacies of the PMPF, the reader is directed to Kagioglou et al. [17].  
Table 1	3. Research methodologySummary of IT performance indicator responses  As mentioned earlier, the indicators were collated, screened, and refined by the construction industryOperational perspective (OP) (weighting 28%)1.040.890.940.950.871.19 1.090.860.770.900.80 0.82 0.78 0.760.910.780.770.74 0.680.800.76through questionnaire dissemination. In order to further refine the screened ‘list’ of indicators, a follow-up project-focused questionnaire was developed and disseminated, with the aim to achieve the following goals: Validation of the developed BSC perspectives; Refinement of the screened ‘list’ of indicators at the project tier; Quantifying the relative importance of indicators; Calculating the interdependence of indicators; Calculating each perspective’s dependency on indicators; and Ranking perspectives and indicators.3.1. Questionnaire design  In order to achieve the above research goals, the questionnaire contained questions on the background of the survey respondents and the IT portfolio of their organisation. This is followed by five sections, which are devoted to the developed BSC perspectives. Each perspective includes a list of screened indicators, where respondents were required to circle the level of importance of each indicator on a 5-point Likert scale with ‘Not Important’ at the one extreme and ‘Very Important’ at the other. The final section asks the respondents to rate the importance of each indicator to the five perspectives, on a scale of 1 to 5 as detailed previously. The aim of this section is toQ1	IT-enhanced processing of progress claimsQ2	Improved contract administrationQ3	IT-enhanced coordination and communicationQ4	IT-enhanced decision-making processQ5	Faster reporting and feedbackQ6	Reduced unnecessary site visitsQ7	Reduced no. of quality assurance(QA) non-conformancesBenefits perspective (BE) (weighting 20%)Q8	Time savings due to efficient document managementQ9	Reduced multiple handling of documentsQ10	Improved document qualityQ11	Realised cost savingsQ12	Quicker response timesQ13	Optimise staff utilisationQ14	Streamlining of processesQ15	Improved client satisfaction3.563.924.163.414.062.75 3.314.054.143.884.14 4.00 3.95 4.154.03Technology/System perspective (TS) (weighting 17%)Q16	Reliability of IT tool	3.96Q17	Appropriateness for application	3.95 functionQ18	User friendliness	4.27Q19	Improved quality of output	3.96Q20	Effective system security	3.93 Q21	Suitability for site conditions	3.94Strategic competitiveness perspective (SC) ( Weighting 19%)Q22	Improved staff computer literacy	3.83	0.82Q23	Enhanced organisational	3.94	0.86 competitivenessQ24	Enhanced organisational image	3.65	0.94Q25	Project alliances forged through	3.25	1.02 electronic meansQ26	Ability to attract more	3.36	1.17sophisticated clientsUser orientation perspective (UO) (weighting 16%)Q27	Satisfactory level and frequency	3.83	0.82 of IT trainingQ28	Satisfactory level and frequency	4.04	0.82 of IT supportQ29	Effective IT utilisation	3.88	0.80Q30	User satisfaction (user, client, other)	4.18	0.78Notes to Table 1:Operational perspective (OP): concerned with the impact of IT on productivity and efficiency.Benefits perspective (BE): investigates the link between IT implementation and associated tangible (monetary) and intangible (non-monetary, i.e. time savings) benefits.Technology/System perspective (TS): refers to the hardware and software, covering issues such as tool performance, reliability, availability, security and suitability to the application/process.Strategic competitiveness perspective (SC): focuses on the longterm strategic goals of the organisation and how the newly implemented technology creates competitive advantage.User orientation perspective (UO): covers issues associated with the usage such as tool utilisation rate, availability of training and technical support and satisfaction with the tool.  
quantify perspective dependency and indicator interdependency using the performance measurement relationship matrix developed by Kagioglou et al. [17].3.2. Sampling procedure  Large construction contractors and project management organisations were targeted as they were most likely to adopt innovative IT for project information management and construction professionals working for these organisations would be more suited to evaluating the importance of perspectives and indicators. Additionally, these organisations would benefit the most from IT implementation because of the size and complexity of their projects [3].  The questionnaire was sent to 322 construction project professionals representing large construction contractors and project management organisations. A small sample of government project managers also participated in the survey. A total of 108 positive returns were received, representing an average response rate of 33%. This rate appears to be consistent with other reported mail surveys in the literature [18]. Five questionnaires were eliminated due to missing data, leaving a final sample size of 103.4. Data analysis and results4.1. Respondent profiles  Respondents were classified into four categories: director/operations manager (30%), project manager/ project engineer/construction manager (53%), IT professional (14%) and other (3%). The position of other includes human resources manager, or finance officer, or project administrator. The average work experience of respondents engaged in the survey is 13.4 years, with about 34% of respondents having more than 20 years of experience.  The next part of the questionnaire survey asked respondents to detail what IT applications and tools they had available to them on construction projects. As mentioned previously, the survey adopts an information-centric definition of IT and thus only these types of applications/tools were included in the survey. The survey demonstrated a high percentage of respondents utilising a variety of IT applications and tools including: (1) Intranet; (2) Internet; (3) e-mail; (4) local area network (LAN); (5) wide area network (WAN); (6) web-based project management application (WBPMA); (7) video conferencing; and (8) online remote network (mobile).  Respondents were requested to detail the primary driving force behind the utilisation of these IT tools. The results indicate that the larger construction organisations have been pro-active in planning for innovative IT implementation with 85% of respondents indicating company strategy as the primary driving force. Only a small fraction of respondents indicated client requirements as the primary driving force.4.2. Perspectives and indicators  This section was the most imperative component of the questionnaire survey. Its purpose was to gauge the opinions of industry professionals as to the importance of the various IT performance perspectives and their associated indicators. The aim of these questions was to determine the relative weighting of perspectives, the relative importance of indicators and to validate the developed framework perspectives through statistical analysis. To facilitate understanding of the proposed ‘Construct IT’ BSC, the survey describes perspectives and indicators clearly and includes illustrative examples, where necessary. In addition, a coloured pamphlet detailing the research project and conceptual framework was included with the survey.  Respondents rated the importance of the five perspectives of the ‘Construct IT’ BSC. The mean weighting of the five perspectives in descending order is: (1) operational 28%, (2) benefits 20%, (3) strategic competitiveness 19%, (4) technology/system 17%, and (5) user orientation 16% (see Table 1). This indicates that respondents place the most importance on the operational perspective. However, the other four perspectives have weighting between 16% and 20%, indicating that all five perspectives are required to evaluate the value IT adds to the process of project information management. If the situation presented itself where one of the five perspectives was substantially less than the remaining, then there may be a case to remove it from the framework.  The next section asked respondents to rate the importance of each performance indicator associated with the perspectives detailed above. The questionnaire respondent was required to circle the level of importance of each indicator on a 5-point Likert scale ranging from: (1) not important; (2) slightly important; (3) somewhat important; (4) important; and (5) very important. The mean value and standard deviation for the 30 performance indicators is detailed in Table 1. The mean values range from 2.75 for Q6: Reduced unnecessary site visits, to 4.27 for Q28: User friendliness. The mean value for all indicators detailed in the questionnaire is 3.85 indicating that the respondents rated the indicators, on average, as important. Only one value has a mean less than 3 (i.e., Q6: Reduced unnecessary site visits). This indicator was removed from further analysis. The remaining items (29) were subjected to a principal component factor analysis, followed by a varimax rotation, to determine the underlying perspectives of the framework. The data was deemed to be appropriate for the analysis by exceeding the 0.5 threshold level, as indicated by the Kaiser–Meyer–Olkin factor solution measure of sampling adequacy of 0.75 [19]. The initial analysis using SPSS V10.0 yielded a fivefactor solution, which accounted for 57% of the variance (see Table 2). However, the interpretability of the solution was rendered problematic because of four complex items, which loaded on more than one factor. For example, Item Q4: IT-enhanced decisionmaking process, was diffused across three factors with loading less than 0.5. Similarly, items Q7, Q14 and Q22 were equally diffused across two or more factors with loading less than 0.5. Due to the problematic nature of these four items, they were removed from further analysis.  A subsequent analysis of the remaining 25 items yielded five factors with eigenvalues greater than one, which together accounted for 61% of the explained variance. Table 3 details the factor loadings, explained variance, eigenvalues and Cronbach’s a for the five factors. As can be seen, all analysed items have loadings greater than the minimum values of 0.5 suggested by Hair et al. [19] and were selected to define the five factors (perspectives). Cronbach’s a for individual factors ranged from 0.73 to 0.89, which are well above the lower acceptable limits of 0.50–0.60, indicating adequate external consistency [20]. A 1:4 item to observation ratio has been suggested by Hair et al. [19]. The respective item to observation ratio inTable 2Varimax factor loadings for the initial five-factor solutionItem Factor analysis components	Factor 1:	Factor 2:	Factor 3:technology/ operational benefits systemFactor 4:	Factor 5: user	strategicorientation competitivenessQ10.1190.596a0.1220.0100.311Q20.0200.588a0.0960.1810.275Q30.0400.540a0.0490.1230.318Q40.0620.458b0.0630.173b0.227bQ50.0490.686a0.0110.1220.130Q70.206b0.467b0.246b0.209b0.188Q80.0410.0630.860a0.1090.105Q90.0230.1860.909a0.1240.122Q100.2850.0140.573a0.0520.219Q110.0590.1870.803a0.0820.129Q120.2530.574a0.1200.1630.167Q130.1360.689a0.1580.0240.148Q140.1860.434b0.479b0.2390.144Q150.2030.3240.1610.1680.522aQ160.848a0.0200.1550.1410.116Q170.796a0.0130.0200.0270.000Q180.1790.1150.0370.595a0.023Q190.842a0.0020.0050.0220.095Q200.755a0.1410.2200.1740.087Q210.799a0.0360.0270.1420.206Q220.0140.0450.408b0.392b0.419bQ230.1760.2160.0210.1940.644aQ240.1910.0610.1690.0500.739aQ25 0.1660.2210.2190.0190.646aQ26 0.0190.1740.2720.0820.632aQ27	0.0080.1900.1770.830a0.018Q28	0.0750.0340.0590.729a0.025Q29	0.1130.2680.0990.676a0.322Q30	0.0200.2210.0160.754a0.214a Variable loads strongly into only one factor. b Variable is diffused over two or more factors.this study is approximately1:4.1, suggesting that the study meets the required standards for factor analysis. 4.3. PMPF matrix analysis  This section demonstrates the analysis of the PMPF and describes its various elements (see Table4). The main aim of the framework presented in Table 4 is to present a holistic performance management/ measurement process framework accounting for input, process and output of performance measurement, as suggested by Kagioglou et al. [17].  Using the five perspectives and their associated performance indicators established from factor analy-Table 3Varimax rotated factor loadings for the five-factor solutionFactorRef.Items(identifying questions)Factor loading1. OperationalOP1IT-enhanced processing of progress claims0.65Variance=10.69%OP2Improved contract administration0.60Eigenvalue=2.67OP3IT-enhanced coordination and communication0.53Cronbach’s a=0.73OP4Faster reporting and feedback0.70OP5Quicker response times0.63OP6Optimise staff utilisation0.642. BenefitsBE1Time savings due to efficient document management0.85Variance=11.65%BE2Reduced multiple handling of documents0.90Eigenvalue=2.91BE3Improved document quality0.59Cronbach’s a=0.85BE4Realised cost savings0.813. Technology/SystemTS1Reliability of IT tool0.85Variance=14.63%TS2Appropriateness for application/function0.80Eigenvalue=3.66TS3Improved quality of output0.84Cronbach’s a=0.89TS4Effective system security0.75TS5Suitability for site conditions0.804. Strategic competitivenessSC1Improved client satisfaction0.57Variance=11.99%SC2Enhanced organisational competitiveness0.66Eigenvalue=2.99SC3Enhanced organisational image0.76Cronbach’s a=0.73SC4Project alliances forged through electronic means0.67SC5Ability to attract more sophisticated clients0.615. User orientationUO1Satisfactory level and frequency of IT training0.85Variance=12.03%UO2Satisfactory level and frequency of IT support0.73Eigenvalue=3.01UO3Effective IT utilisation0.69Cronbach’s a=0.82UO4User satisfaction0.77UO5User friendliness0.57sis, it is now possible to construct the matrix. When providing responses for the PMPF, respondents were asked to rate the importance of the indicator to each of the five perspectives, on a scale of 1 to 5, where: (1) not important; (2) slightly important; (3) somewhat important; (4) important; and (5) very important. For example, for the importance of the indicator OP1: ITenhanced processing of progress claims, on the five perspectives, can be described as follows: Important—very important (score 4.20) to the operational perspective since IT is supposed tostreamline the process; Somewhat important—important (score 3.61) to the benefits perspective since more efficient processing of progress claims will generate cost savings to the organisation; and Somewhat important (score 3.04) to the technology/system perspective because if the hardware or software fails the user will have to resort to manual procedures.  As suggested earlier, the primary advantage of the PMPF is that it can help identify each indicator’s interdependency and each perspective’s dependency on indicators. Indicator interdependency is calculated by summing the mean values for each of the five perspectives. For example, for the indicator OP1: ITenhanced processing of progress claims, the sum of the mean values is (4.20 +3.61+3.04+2.90+3.15= 16.89). This interdependence value can be compared to that of other indicators to examine which indicators have the highest perspective interdependence. Indicator interdependence ranges from 15.88 for SC4 to 19.20 for TS1. As expected, indicator TS1: reliability of IT tool, has a high interdependence value since all five perspectives rely on IT reliability to achieve their desired objectives. Also, all indicators in the user orientation perspective have a high interdependence because this perspective is a key enabler to achieving the other objectives.  In addition, it is possible to accumulate the results for the five perspectives and derive the perspective’s dependency on indicators. By summation of each column in Table 4, perspective dependency can be calculated. The results of the questionnaire survey are as follows: (1) operational=97.8; (2) benefits =90.8; (3) technology/system=84.3; (4) strategic competitiveness =85.8; and (5) user orientation =83.8. These results indicate that the perspective dependence is highest for the operational perspective, suggestingTable 4Performance measurement relationship matrixPerformance indicator	Perspective	IndicatorinterdependenceCode	Description	Operational	Benefit	Technology/	Strategic	UsersystemcompetitivenessorientationOP1IT-enhanced processing of progress claims4.203.613.042.903.1516.89OP2Improved contract administration4.333.703.103.293.1317.55OP3IT-enhanced coordination and communication4.323.653.273.393.3117.94OP4Faster reporting and feedback4.163.443.203.523.2217.54OP5Quicker response times4.283.813.193.713.4118.40OP6Optimise staff utilisation3.903.853.123.523.3217.70BE1Time savings due to efficient doc. management4.264.143.273.263.2118.15BE2Reduced multiple handling of documents4.173.993.123.173.2817.73BE3Improved document quality3.723.833.203.413.0417.21BE4Realised cost savings4.154.253.223.593.1618.37TS1Reliability of IT tool4.113.644.323.373.7619.20TS2Appropriateness for application/function3.993.553.983.303.5618.37TS3Improved quality of output3.633.703.573.543.1717.62TS4Effective system security3.493.063.903.232.9316.61TS5Suitability for site conditions3.633.203.663.033.1816.70SC1Improved client satisfaction3.713.813.023.773.0117.32SC2Enhanced organisational competitiveness3.633.823.124.083.1817.83SC3Enhanced organisational image3.543.552.953.982.9516.97SC4Project alliances forged through elect. means3.373.093.063.552.8115.88SC5Ability to attract more sophisticated clients3.723.232.893.572.6516.06UO1Satisfactory level and frequency of IT training3.663.493.503.204.0317.88UO2Satisfactory level and frequency of IT support3.903.363.723.204.1318.30UO3Effective IT utilisation3.813.473.653.493.9418.37UO4User satisfaction3.933.913.523.534.1419.03UO5User friendliness4.173.743.773.164.1318.97Perspective dependency97.890.884.385.883.8Perspective rank12435that, in order to gain a realistic picture of IT-induced value adding to the process of project information management, operational indicators and measures are essential. These results relate very well with the perspective weight values obtained independently (see Table 1), where the operational perspective has the highest weighting (28%).4.4. Ranking indicators  The ranking of indicators (see Table 5) has been calculated by multiplying the indicator mean (IM) value by the indicator interdependence mean (IIM) value. For example, for the indicator OP1: ITenhanced processing of progress claims (3.56  16.89=60.132). Using this technique, the rank within each perspective and the overall rank of each indicator is calculated. The two highest ranked indicators in each perspective and the 10 highest indicators overall are in bold and underlined in Table 5. The highest ranked indicator was UO5: user friendliness, whilst the lowest was SC4: project alliances forged through electronic means. It is important to note that even though the technology/system and user orientation perspectives have 5 of the 10 highest ranked indicators, they are the two lowest ranked perspectives according to weight and dependency on indicators. This suggests that the respondents see these ‘soft’ perspectives as key enablers to achieving IT-induced value adding in the process of project information management. However, their overall perception is that the majority of value generated from IT implementation is derived from the ‘results-driven’ operational and benefits perspectives. Moreover, the indicator interdependence values for the indicators in the strategic competitiveness perspective were quite low,Table 5Ranking indicatorsCode	Description	Indicator	Indicator	IMIIM	Rank within	Rank overall	mean (IM)	interdependence	perspectivemean (IIM)OP1IT-enhanced processing of progress claims3.5616.8960.132623OP2Improved contract administration3.9217.5568.799517OP3IT-enhanced coordination and communication4.1617.9474.64115OP4 Faster reporting and feedback 4.06 17.54 71.205 3 12 OP5 Quicker response times 4.00 18.40 73.594 2 7 OP6 Optimise staff utilisation 3.95 17.70 69.930 4 14BE1	Time savings due to efficient doc. management	4.05	18.15	73.494	2	8 BE2	Reduced multiple handling of documents	4.14	17.73	73.416	3	9 BE3	Improved document quality	3.88	17.21	66.757	4	19 BE4	Realised cost savings	4.14	18.37	76.046	1	4TS1	Reliability of IT tool	3.96	19.20	76.050	1	3TS2	Appropriateness for application/function	3.95	18.37	72.579	2	10TS3Improved quality of output3.9617.6269.768316TS4Effective system security3.9316.6165.270521TS5Suitability for site conditions3.9416.7065.805420SC1SC2Improved client satisfactionEnhanced organisational competitiveness4.033.9417.3217.8369.81170.261211513SC3Enhanced organisational image3.6516.9761.936322SC4Project alliances forged through electronic means3.2515.8851.616525SC5Ability to attract more sophisticated clients3.3616.0653.977424UO1Satisfactory level and frequency of IT training3.8317.8868.478518UO2Satisfactory level and frequency of IT support4.0418.3073.92536UO3	Effective IT utilisation	3.88	18.37	71.278	4	11UO4	4.18	19.03	79.528	2	2UO5	4.27	18.97	80.982	1	1suggesting that these indicators have low relevance to the other perspectives. This further suggests that IT is yet to be viewed as a strategic tool by construction professionals. Also, it reflects the difference in the respondents’ perceptions towards realised benefits (short-term) and potential benefits (long-term).5. Discussion  This research study empirically refined and validated the proposed five-perspective ‘Construct IT’ BSC framework. The study demonstrated that all five perspectives of the framework were justified through a varimax rotated factor analysis. The survey respondents considered the Operational perspective to be the most important, carrying a weighting of 28%, however, all perspectives were deemed necessary with minimal disparity between the weighting of the other perspectives. This reinforces the assumption that all five perspectives are necessary to holistically evaluate the value IT adds to the process of project information management. The results from the performance measurement relationship matrix (see Table 4) also confirm this assumption by having only a 16% variance between the highest and lowest perspective dependency value. Weighting the operational perspective higher than the other perspectives suggests that respondents are more concerned with how IT can directly affect the day-to-day information management processes. As expected, gains in the efficiency or productivity of operational processes seems to be noticed and acknowledged quickly while flow-on effects to the Benefits and Strategic Competitive perspectives may not be as obvious. The results further indicate that none of the indicators within the strategic competitiveness perspective have made it in the top 10 ranked indicators. This is perhaps due to the fact that the majority of respondents are operations/project managers that are not heavily involved in the process of project-based information managing. It would be of interest to determine if strategic competitiveness indicators will have a higher-ranking order in a top-management focused survey.  Within each perspective are a number of indicators that are ranked based on their mean and indicator interdependence values. All of the retained 25 indicators were perceived as important (i.e., mean values of >3) by the respondents for capturing the various tangible and intangible elements of value derived from IT implementation. However, the flexible nature of the framework enables organisations to choose other indicators that reflect their particular goals and objectives. Despite this, the authors recommend adopting the two highest ranked indicators, at a minimum, within each perspective. The study showed that these indicators were the most effective for capturing IT-induced value. In summary, this research approach has elicited an IT performance evaluation framework, in the form of a ‘Construct IT’ BSC, that can evaluate the many diverse elements of value derived from IT for improving the process of project information management in construction.6. Concluding remarks  Without the effective use of IT to facilitate the process of information management amongst project participants, it is unlikely that major improvements to the communication process will eventuate by continuing to use traditional paper-based processes. This paper has sought to emphasise the importance of a structured evaluation framework to evaluate the value IT adds to the process of project information management. A balanced scorecard approach was chosen, as the template for this framework, due to its success in a wide spectrum of industries/applications.  The framework is in the form of a ‘Construct IT’ BSC with IT performance perspectives and indicators developed specifically for managing information on construction projects. The conceptual framework was developed through extensive review of the IT literature and consultation with construction management academics and industry professionals. Following this process, the conceptual framework was then subjected to industry scrutiny through questionnaire survey. The questionnaire targeted large construction contractors and project management organisations located within Australia, and 103 valid responses were received. The final framework was in the form of a ‘Construct IT’ BSC which goes beyond traditional evaluation approaches by accommodating the wider intangible human, organisational and strategic benefits of IT investments.  The contents of this paper have two primary implications for researchers and practitioners in the construction industry. Firstly, the research study has demonstrated that IT projects need to be evaluated across a range of diverse perspectives. Secondly, a variety of indicators spread across these perspectives are imperative to encompass the complete spectrum of value elements obtainable from innovative IT investments. The attractiveness of the ‘Construct IT’ BSC to the construction industry is its simplicity and flexibility. It is the authors’ contention that evaluating ITinduced value added to project information management should be measured across the proposed five perspectives, however, the proposed indicators of the framework should not be considered fixed, e.g. indicators can be individually developed to suit the goals of the organisation. The dynamic nature of IT requires that the indicators must also continually evolve to accurately quantify the value IT adds to the process. Therefore, construction organisations should lay the foundations for an IT performance measurement and management culture, by actively seeking to quantify the value IT generates. This only happens when top management is sincerely supportive and involved in the process itself.References[1] M. Betts, M. Shafagi, A Health Check of the Strategic Exploitation of IT: An Industry Study, Construct IT Centre of Excellence, University of Salford, 1997.[2] B.L. Atkin, J.V.L. Gravett, Benchmarking Best Practice Report: Integrated Project Information, Summary Report for the Construct IT Centre, Salford, 1999.[3] F. Pena-Mora, S. Vadhavkar, E. Perkins, T. Weber, Information technology planning framework for large-scale projects, Journal of Computing in Civil Engineering (ASCE), (1999, October) 226–237.[4] Z. Irani, P.E.D. Love, The propagation of technology management taxonomies for evaluating investments in information systems, Journal of Management Information Systems 17(3) (2001) 161–177.[5] R.A. Stewart, S. Mohamed, Utilizing the balanced scorecard for IT/IS performance evaluation in construction, Journal of Construction Innovation 1 (3) (2001) 147–163.[6] K.D. Hampson, R.J. Peters, D.H.T. Walker, S.N. Tucker, S. Mohamed, M. Ambrose, D. Johnston, Case Study of the Acton Peninsula Development, Government Research Report, Dept of Industry, Science and Resources, Commonwealth of Australia Government, Canberra, 2001.[7] S. Mohamed, R.A. Stewart, An empirical investigation of users’ perceptions of web-based communication on a construction project, Automation in Construction 12 (1) (2003) 43–53.[8] P.L. Powell, Information technology evaluation: is IT different? Journal of Operational Research Society 43 (1992) 29–42.[9] R. Kumar, Understanding the value of information technology enabled responsiveness, Electronic Journal of Information System Evaluation 1, 2000.[10] B.L. Dos Santos, L. Sussman, Improving the return on IT investment: the productivity paradox, International Journal of Information Management 20 (2000) 429–440.[11] J. Ballantine, M. Bonner, M. Levy, A. Martin, The 3-D model of information systems success: the search for the dependant variable continues, Information Resources Management Journal 9 (4) (1996) 5–14.[12] M. Parker, Strategic Transformation and Information Technology, Prentice-Hall, Upper Saddle River, USA, 1996.[13] T. Saarinen, An expanded instrument for evaluating information system success, Information and Management 31 (2) (1996) 103–118.[14] J. Ballantine, S. Stray, Information systems and other capital investments: evaluation practice compared, Logistics and Information Management 12 (1–2) (1999) 78–93.[15] M. Betts, Strategic Management of IT in Construction, Blackwell, Oxford, UK, 1999.[16] V. Serafeimedis, S. Smithson, Information systems evaluation in practice: a case study of organisational change, Journal of Information Technology 15 (2) (2000) 93–106.[17] M. Kagioglou, R. Cooper, G. Aouad, Performance management in construction: a conceptual framework, Construction Management and Economics 19 (2001) 85–95.[18] R. Fellows, A. Liu, Research Methods for Construction, Blackwell Science, Australia, 1997.[19] J.F. Hair, J.F. Anderson, R.L. Tatham, Multivariate Data Analysis, 5th ed., Prentice-Hall, Upper Saddle River, USA, 1998.[20] R.M. Kaplan, D.P. Saccuzzo, Psychological Testing: Principles, Applications and Issues, Brooks/Cole, California, USA, 1993.408	R.A. Stewart, S. Mohamed / Automation in Construction 12 (2003) 407–417  	R.A. Stewart, S. Mohamed / Automation in Construction 12 (2003) 407–417	409    