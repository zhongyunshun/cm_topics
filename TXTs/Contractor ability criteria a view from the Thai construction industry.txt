Contractor ability criteria: a view from the Thai construction industryJakrapong Pongpeng & John ListonTo cite this article: Jakrapong Pongpeng & John Liston (2003) Contractor ability criteria: a view from the Thai construction industry, Construction Management and Economics, 21:3, 267-282, DOI: 10.1080/0144619032000049647To link to this article:  https://doi.org/10.1080/0144619032000049647Full Terms & Conditions of access and use can be found at https://www.tandfonline.com/action/journalInformation?journalCode=rcme20
Construction Management and Economicstractor ability criteria	 (2003) 21, 267–282	Contractor ability criteria: a view from the Thai construction industryJAKRAPONG PONGPENG* and JOHN LISTONPhysical Infrastructure Centre, School of Civil Engineering, Queensland University of Technology, AustraliaReceived 8 February 2002; accepted 16 October 2002Realizing that there is a lack of commonality in selecting criteria to evaluate contractor ability, the study aim was to develop a common set of contractor ability criteria for both government and private sectors. This included a standardized set of physical characteristics (hierarchical organizational units) of contractors. The Thai construction industry was surveyed as to the degrees of importance placed on a range of criteria and measures. Similarities and differences between the government and private sectors in selecting contractor ability criteria have been analysed by comparing the importance index and ranking order and comparing mean importance placed on criteria and measures. Relationships between all criteria and measures have also been explored by using correlation coefficients. Factor analysis has been applied to group all highly correlated measures together so as to develop a common set of contractor ability criteria. The result of analysing similarities and differences indicated only slight differences in the mean importance of criteria and measures between the government and private sectors. Thus, a common set of contractor ability criteria has been developed by applying factor analysis, namely, ‘engineering/construction’, ‘procurement/contract’, ‘project managers’, ‘human resources’, ‘quality management systems’, ‘health and safety’, ‘plant/equipment’, ‘financial strength’ and ‘public relations’.Keywords: Contractor ability criteria, contractor ability, Thai construction industry, prequalification, factor analysis
IntroductionIn the construction industry, problems such as schedule delays, budget overruns, low quality work, a large number of claims and litigation, suffering of workmanship and the requirement of more supervision from the client result largely from not selecting the best contractor to complete a construction facility. These problems then affect the achievement of objectives, the day-to-day operations and the long-term performance of the client’s company.  To reduce these problems, tender evaluation processes were studied (Pongpeng, 2002). In that study, competitive bidding concepts underpinning tender evaluation were also reviewed. A questionnaire survey was conducted to investigate tender evaluation procedures used in the Thai*Author for correspondence. E-mail: kpjakrap@kmitl.ac.thconstruction industry. A result of the survey shows that the selective tendering processes with and without prequalification processes use a two-step evaluation: step 1 evaluates contractor ability and step 2 evaluates tenders. In contrast, the open tendering process uses a one-step evaluation. That is, bid price and contractor ability are evaluated at the same time. All of these procedures involve multiple criteria. This reflects a move by the clients that the lowest bid is not the only criterion to select the best contractor. They sometimes trade off between bid price and contractor ability during selection (‘contractor ability’ concerns differences in how well contractors perform a project).Construction Management and EconomicsISSN 0144-6193 print/ISSN 1446-433X online © 2003 Taylor & Francis Ltd http://www.tandf.co.uk/journalsDOI: 10.1080/0144619032000049647  Although the development of criteria for the selection has been done by various researchers, a common set of contractor ability criteria, incorporating organizational units of contractors, for both government and private sectors still does not exist. In addition, different clients and different researchers suggest different criteria to evaluate contractor ability. For example, Liston (1994) suggested ‘past performance’, ‘business’, ‘capacity’, ‘financial’, ‘resource’, ‘procedure’ and ‘quality assurance’; whereas those by Hatush and Skitmore (1997) were ‘financial soundness,’ ‘technical ability,’ ‘management capabilities,’ ‘health and safety’ and ‘reputation’. In contrast, Holt et al. (1994) considered ‘contractors’ current workload’, ‘contractors’ past experience in terms of size of projected completed’, ‘contractor management resource in terms of formal training regime’, ‘time of year – weather’, ‘contractors’ past experience in terms of catchment’ and ‘experience in terms of projects completed’. This then results in a waste of researchers’ and clients’ repetitive resources in developing contractor ability criteria (cf, Hatush and Skitmore, 1997). To reduce the waste, there is a need for developing a set of contractor ability criteria that are common between government and private sectors.  This paper presents a study aimed at developing a common set of criteria with weights of relative importance to evaluate contractor ability (step 1) for government and private sectors, which is primarily developed on the basis of existing hierarchical organizational units of contractors (a physical feature of contractors). In this development, first data focusing on the degree of importance of criteria and their measures were gathered through a questionnaire survey within the Thai construction industry from 17 February 2001 to 23 March 2001.  Participants were chosen from both government and private organizations, whose functions are involved with tender evaluation. Then, three main analyses have been performed to:• determine similarities and differences in the selection of contractor ability criteria between government and private sectors using the comparison of importance index (mean/STD) and using hypothesis tests on mean differences of criteria and measures;• examine relationships between all criteria and measures using Spearman rank correlation coefficients; and• apply factor analysis to group all highly correlated measures together.The results of examining similarities and differences have revealed that both the government and private sectors consider similar criteria for evaluating contractor ability. Thus, a common set of contractor ability criteria can be developed for both the sectors. Subsequently, a result of factor analysis has suggested a common set of contractor ability criteria, namely, ‘engineering/construction’, ‘procurement/contract’, ‘project managers’, ‘human resources’, ‘quality management systems’, ‘health and safety’, ‘plant/equipment’, ‘financial strength’ and ‘public relations’.Methodology of data gatheringBoth government and private organizations involved with various construction works in Thailand were targeted. A hand-delivered questionnaire was given to a total of 210 construction professionals: 103 government and 107 private agencies.  Due to the difficulty of measuring contractor ability, a hierarchy of subcriteria was developed on the basis of the existing hierarchical organizational units of contractors:• outline the criteria and measures according to contractors’ organizational units. (Based on a multilevel approach, any developing system should be primarily partitioned according to an organizational hierarchy (Dirickx and Jennergren, 1979).);• review textbooks about necessary processes of organizational units of contractors (for more details, see Pongpeng, 2002);• consider Thai standards for contractor registration of Bangkok Metropolitan Administration, Department of Accelerated Rural Development, Department of Highway, Public Works  Department and Royal Irrigation Department;• review the relevant published works, for example, Construction Industry Development Agency (CIDA, 1993), Hatush and Skitmore (1997), Holt et al. (1994), Liston (1994, 1999), Russell(1996), Russell and Skibniewski (1990, 1998) and Russell et al. (1992);• synthesize the above to initially develop a common set of criteria for evaluating contractor ability; and • pilot the set of criteria with postgraduate students at the School of Civil Engineering, Queensland University of Technology and with practitioners in Australian and Thai construction industries to initially ensure validity including the exhaustive list of criteria and measures.In assigning a scale to the criteria, a combination of a Likert scale and a bipolar adjective scale was used, 1 = very low importance to 5 = very high importance (for more details, see Pongpeng, 2002).Sample characteristicsTypes of organizations with their response rate are summarized in Table 1. The total rate of return was 68% (142). The government sector returned 79 questionnaires and had the highest return rate of 77% whilst the private sector returned 63 questionnaires at a return rate of 59%. This overall return rate is considered good as Babbie (1989) suggests that any rate over 50% can be reported, over 60% is good and over 70% excellent.  The sectors involved have a total annual contract value of A$24 932 million with the minimum and maximum values of A$0.01 million and A$10 000 million as shown in Table 2.1 In terms of annual average, the government sector has the higher contract value (A$306.9 million) compared to A$138.3 million for the private sector. The government sector engaged in various works totalling 20 459 contracts annually; whereas those of the private sector were 943 contracts. Clearly, the data covers a large number of contracts in various construction works with a large contract value from both government and private sectors.Qualification analysisIn this study, the criteria together with their measures were developed based on the theory of hierarchy, multilevel, systems (see Mesarovic et al., 1970) and on considering Thai standards for contractor registration of Bangkok Metropolitan Administration (BMA), Department of Accelerated Rural Development (DARD), Department of Highway (DoH), Public Works Department (PWD) and Royal Irrigation Department (RID). In addition, the relevant published works was considered, for example, Construction Industry Development Agency (CIDA, 1993), Hatush and Skitmore (1997), Holt et al. (1994), Liston (1994), Russell and Skibniewski (1998) and Russell et al. (1992). The quality of the questionnaire was tested in terms of validity and reliability.ValidityTable1 Sample characteristics in the Thai construction industrySector	OrganizationPercentage returnNumber of questionnaires	Sent	ReturnGovernmentPrivateBangkok Metropolitan AdministrationThe Department of Accelerated Rural DevelopmentThe Department of HighwaysThe Royal Irrigation DepartmentThe Public Works DepartmentThe Electricity Generating Authority of ThailandThe Airports Authority of ThailandSubtotalConsultantContractorOthers (e.g. clients and engineering)SubtotalTotal20314202025110329522610721016 311131520 179153315631428010079657580100775264585968Note: The government organizations are large. They have a number of multiple decision-makers for tender evaluation.Table2 A summary of characteristics of the respondents’ organizationsvalue (A$M)MinimumMaximumGovernmentPrivate306.9138.30.01 0.0110000.0 1304.0SectorAverage annual numberBuilding worksCivil worksServicesMaintenance worksOther worksGovernmentPrivate Total5641326966186 590 67762240 160 240011205   20 1122526441305Sector	Approximate average annual contract	Contract values (A$M)Note: Bahts were converted to Australian dollars using the exchange rate of 23 Bahts/Dollar.Validity means measuring what is expected to be measured. As a basis for discussion, the validity of any set of criteria/measures is open to criticism. No one set of criteria perfectly explain contractor ability (an abstract construct). All criteria of a set collectively explain contractor ability. Accordingly, they should correlate with one another in evaluating contractor ability (cf. Nunnally, 1967). Russell et al. (1992), for example, use
correlations between criteria for validation. Here too, correlation analysis was used to examine whether relationships between all criteria and their measures existed to ensure validity. The example results shown in Table 5 ensured that all criteria and measures werecorrelated.ReliabilityTo ensure at a certain level that the scale (1–5) for measuring criteria/measures yields the same result over time, the internal consistency method was used. This method aims at finding the reliability coefficient based on the average correlation amongst criteria/measures (the internal consistency) and on the number of criteria/ measures. The basic formula for finding the internal consistency reliability is called coefficient alpha. In this study, Cronbach alpha was performed to test the internal consistency reliability of the criteria scale by solving (Nunnally, 1967):α= N	N −1	σxwhere α is Cronbach alpha, N is the number of criteria/ measures (items) within a questionnaire, ∑σ2i is the sum of variance of each criterion/measure score and σ2x is the variance of a sum of all criteria/measures’ scores.  The alpha, as a reliability coefficient, varies from 0 to 1; the higher the alpha, the greater the internal consistency reliability or the greater the inter-criteria correlations. Here, the Cronbach alpha of 0.98 for the criteria scale indicated a good internal consistency reliability of the scale (the alpha should be greater than 0.7 (SPSS training, 1998)).Data analysisThe data was analysed using the SPSS package. Three main analyses were performed: (1) finding similarities and differences between the government and private sectors using a comparison of importance index and comparison of mean importance; (2) revealing relationships between all criteria and their measures using correlation coefficients; and (3) clustering together all measures using factor analysis.Test of similarities and differencesTo find similarities and differences between government and private sectors, means and standard deviations of all criteria and their measures were explored. However, means may not fully represent the data if the data have high standard deviations. Thus, a standardized ratio (making the standard deviation equal 1) of the mean and standard deviation was constructed for the use of comparative purposes, which was written as (cf. Lehmann, 1989):Importance index = Mean Standard deviationMoreover, to draw a conclusion as to whether government and private sectors consider criteria differently as they evaluate contractor ability, the mean importance of each criterion and measure was compared using the Mann Whitney U test.Comparison of ranking order and importance index across sectorsFor a descriptive analysis and the sake of readability, the five most important criteria and measures were compared. A summary of the comparison is presented in Table 3. Overall, the five most important criteria were: (1) ‘project planning’, (2) ‘project monitoring’, (3) ‘project management experience’, (4) ‘ability to adjust a project’ and (5) ‘performance’. The five most importance measures were (1) ‘master plans’, (2) ‘continuously reporting’, (3) ‘a list of plant/equipment’, (4) ‘past performance’ and (5) ‘problem-solving skills’.  Clearly both sectors considered ‘project planning’, ‘project monitoring’ and ‘project management experience’ as very important. ‘Performance’ and ‘ability to adjust a project’ were indicated by the government sector as important. A possible reason is that these two criteria largely affect the timeliness of a project, which guarantees that the fiscal year budgeting requirements are complied with. On the other hand, the private sector indicated ‘subcontractor control’ and ‘financial ratios’ as important possibly because these two criteria extensively affect the cost of a project. This, in turn, ensures economic viability of private organizations in business.  It is interesting to look at the criteria on quality and safety. As shown in Table A1 in the Appendix, both sectors rated criteria ‘quality system selection’ (importance indices of 2.94 and 3.64 by public and private sectors, respectively), ‘quality system implementation’ (importance indices of 2.98 and 3.60) and ‘quality system audits’ (importance indices of 3.44 and 4.32) as being of medium-to-high importance. Based on these results, the quality system selection, implementation and audits are not of high concern for either sector. On the other hand, although health and safety performance can block the execution of a project and lead to an additional cost to a project, it is rated as semi-important by the government sector (an importance index of 3.56) but as rather important by the private sector (an importance index of 4.79). This reinforces the belief that any criteria possibly affecting project cost are most likely to be of great importance to the private sector.Table3 Comparison of the five most important criteria and measuresSectorFive most important criteriaFive most important measuresCriteriaIndexMeasureIndexOverallGovernmentPrivateProject planningProject monitoringProject management experienceAbility to adjust a projectPerformanceProject planningProject monitoringProject management experiencePerformanceAbility to adjust a projectProject management experienceSubcontractor controlProject planningProject monitoringFinancial ratios5.81 5.70 5.45 4.73 4.69 6.07 6.07 5.27 5.01 4.78 5.74 5.65 5.53 5.255.15Master plansContinuously reportingA list of plant/equipmentPast performanceProblem-solving skillsMaster plansPast performanceContinuously reportingProblem-solving skillsA list of plant/equipmentTechnical abilityBudgetingMaster plansObservation skillsAnalysis skills5.22 4.93 4.82 4.82 4.80 5.06 5.06 4.93 4.78 4.67 6.34 6.06 5.57 5.365.18  In the measures shown in Table A2, only ‘master plans’ was indicated as highly important by both sectors with the government sector placing a higher priority (ranked first) than that (ranked third) of the private sector. This again shows the possible underlying philosophy that time tends to be of more concern to the government sector. In contrast, the private sector ranked ‘budgeting’ as highly important (ranked second). A  possible explanation is that this measure helps to establish financial viability. However, the government sector ranked ‘budgeting’ 26th, which again highlights the possible underlying philosophical differences between the government and private sectors.  Other measures amongst the five most importance rankings for the government sector were ‘past performance,’ ‘continuously reporting,’ ‘a list of plant/equipment’ and ‘problem-solving skills’. The possible reason why the first three measures are considered as important is that all these measures are prescribed by most government sectors’ control manuals and cannot be easily breached. Also, having ‘problem-solving skills’ as a project manager is of major concern perhaps because most government organizations require contractors who have the ability to solve their own problems (e.g. allocating project resource requirements, surviving company constraints and managing risks associated with the project) and to correct errors/mistakes that may occur in the specifications and drawings without having to request solutions from the superintendent.  For the private sector, the remaining five most important measures were ‘technical ability’, ‘observation skills’ and ‘analysis skills’. A possible explanation why these three measures are important is that the private sector wants sub/contractors that have high technical ability, show basic technical knowledge and understand construction projects. Also, the contractors tend to require a project manager who has good communication skills and is therefore able to effectively and efficiently deliver plans, controls, tasks and standards to other colleagues, helping to achieve the completion of the facility to a pre-specified budget.  Of interest are measures describing quality, and health and safety. Both the public and private sectors rated ‘AS 3900 series’ as being of low importance (1.85 and 1.86, respectively), whereas ‘ISO 9000 series’ was of medium importance (2.54 and 3.03, respectively). The comments from some respondents were that they were more familiar with standard ISO than joint standard AS/NZS. ‘Progressive steps of implementing a quality system’ was rated as being of medium importance by the public sector (an importance index of 3.09), but of rather high importance by the private sector (an importance index of 3.98).  Another interest was that ‘documented processes being followed by contractor,’ ‘documented processes in place ready to address standard elements,’ and ‘documented processes being effective and suitable’ were rated as being of ‘medium’-to-’high’ importance (range between 3.16–3.53) by the government sector, and as ‘ratherhigh’-to-’high’ (range between 3.76–4.15) by the private sector. Also ‘health and safety plan’ and ‘health and safety control’ were rated as being of medium importance (range between 3.06–3.16) by the government sector and as ‘rather-high’-to-’high’ importance (range between 3.95–4.08) by the private sector.  The comparison of ranking order between government and private sectors has shown that three out of the five most important criteria, 60%, are selected in agreement. However, only one out of the five most important measures (‘master plans’, 20%), is similarly selected. In addition, when importance indices of criteria and measures on quality and health and safety are compared, the overall statistical figures show that the government sector places a lower priority on these criteria (importance indices of 3.23 and 4.09 by government and private sectors, respectively) and measures (importance indices of 3.26 and 3.97 by government and private sectors, respectively) than does the private sector. Furthermore, as discussed earlier, the five most important criteria and measures indicated by the government sector are likely to be time-related whilst those of the private sector are likely to be cost-related. Nevertheless, at this stage it cannot be concluded whether the government and private sectors consider criteria and measures differently as they evaluate contractor ability. To explore this further, hypotheses on which criteria and measures make the two sectors different at specified statistical levels were tested.Hypothesis testIn conjunction with the previous section, differences and similarities in characteristics between the two sectors were further inspected. A nonparametric statistical test, Mann Whitney U test, was performed to compare mean importance of each criterion and measure as to whether there was any statistical difference at the 95% level of confidence.  The aim of the Mann Whitney U test is to draw a conclusion on the existence of mean differences of variables between two population groups which are selected independently (for more details, see Seigel and Castellan, 1988; Keller and Warrack, 1997). The test was done against the null hypothesis: (H0) the mean importance of each criterion and measure are equal for both the government and private sectors.  Table 4 summarizes the result (listed only the criteria and measures indicated as statistical differences between government and private sectors). In the table, only five out of 23 criteria, 22%, were indicated as statistically different in terms of mean importance, namely, ‘financial ratios’, ‘quality system implementation’, ‘project execution’, ‘communication skills’ and ‘adaptability’. Also, only 19 out of 63 measures (30%) were statistically different, including ‘gross profit’, ‘progressive steps of implementing a quality system’, ‘competitive incomes/ welfare’, ‘master plans’ and ‘budgeting’.  It can be seen from Table 4 that less than 31% of the number of criteria and measures are indicated as statistically different at the 95% level of confidence. This means that more than 69% of the number of criteria and measures are similarly selected by government and private sectors. Therefore, it can be inferred that both government and private sectors consider criteria and their measures rather similarly (69%) in evaluating contractor ability.Relationships between all criteria and measuresTable4 Criteria and measures indicated as statistical differences between government and private sectorsCriteria indicated as statistical difference*Measures indicated as statistical difference*Financial ratiosQuality system implementationProject executionCommunication skillsAdaptabilityGross profitCurrent banking organizationAverage length of time that the contractor pays subs/suppliersConditions in bank guaranteeProgressive steps in implementing a quality systemCompetitive incomes/welfareGeneral conditions of subcontractorsCommunication lineMaster plansBudgetingContingency plansCommunication of the plans to involved peopleTechnical abilityManagement of conflictPrevious and current positionObservation skillsAnalysis skillsPersuasive skillsTolerance for ambiguity*statistical difference at the 5% level of significance.To identify that the criteria and measures were valid and relevant to the evaluation of contractor ability, the relationships between them were examined. The Spearman Rank Correlation method was selected to calculate thecorrelation coefficient, r, since normality of population is not required (Seigel and Castellan, 1988). The coefficient ranges between −1 and +1 where −1 and +1 indicate high relationships but 0 does not.  The coefficient was used to test the null and alternative hypotheses: (H0) that there is no relationship between the two criteria or the two measures and (Ha) that there is a relationship between the two criteria or the two measures. The level of confidence for the test was 95% or 99%. Almost all criteria and their measures were correlated except the criterion ‘quality system selection’ to its measure, ‘AS 3900 series’.  Criteria considered as having high and low importance are shown in Table 5. The statistically significant relationships between the criteria and their measures are indicated by * (at the 5% level of significance) or ** (at the 1% level of significance). Clearly ‘financial ratios’ and ‘banking arrangement’ had the weakest relationships with other criteria. ‘Delivery control’ was strongly correlated to ‘subcontractor control’, as was ‘project planning’ and ‘project monitoring’. Similarly, there was a strong relationship between ‘project monitoring’ and ‘ability to adjust a project’. Furthermore, in an observation of the correlation figures, the measures were likely to separate into clusters because the measures of a cluster correlated highly with one another and correlated much less with the other measures of other clusters. This gives a convincing evidence for applying factor analysis to group highly correlated measures together.  In the overall section, criteria and measures were correlated. This confirms the relevance of all the selected criteria and their measures to the evaluation of contractor ability.Factor analysisFactor analysis was used to group highly correlated measures together and then to find weights of relative importance amongst those groups. The two basic reasons for the grouping are (1) the simplification of modelling problems and (2) the exploration of the underlying structure of measures, particularly whether the structure is compatible with hierarchical organizational units. The details of factor analysis can be seen in Aaker et al. (1998) and Lehmann (1989).  A condition required by the factor analysis model is that the number of observed samples must be greater than the number of measures. For this reason, any measures having an importance index of less than 3 (considered as of medium importance) were removed. Accordingly, only 53 measures were used as input for factor analysis as shown in Table A3 in the Appendix.Correlation coefficient examinationTable5 Spearman rank correlation coefficient of ten example criteriaCriteriaFinancial ratios  Banking arrangementCredit Procureratings ment plansDelivery controlSubcontractor controlProject	Project	Project	Abilityplanning execution monitoring to adjust a projectFinancial ratiosBanking arrangementCredit ratingsProcurement plansDelivery controlSubcontractor controlProject planningProject executionProject monitoringAbility to adjust a project10.1450.386**0.1270.1230.209*0.1680.0330.0420.09210.607** 0.2190.298**0.1870.1600.1370.1610.309**10.247**0.473**0.416**0.337**0.214*0.234*0.256*10.349**0.479**0.356**0.420**0.415**0.369**10.540**0.234*0.225*0.350**0.348**10.324**0.316**0.336**0.356**10.484**0.570**0.459**10.561**0.510**1 0.597**1*at the 5% level of significance; **at the 1% level of significance.The coefficient values indicated that all measures were correlated (Table 5) and testing indicated that the data were appropriate for using factor analysis. The tests were (1) the Kaiser-Meyer-Olkin (KMO) measure of sampling adequacy and (2) Bartlett’s test of sphericity. The KMO measure of 0.897 indicated that the data were adequate for using factor analysis. Also, the Bartlett’stest indicated that relationships amongst measures were suitable for running factor analysis.Factor extractionThe Principal Components were used to extract the number of measures. What the Principal Components does is to combine many correlated measures into a small number of components, namely:• the first component, which contains the maximum information in all the measures. This component has the largest variance that can explain the problem most effectively; and• the second component, which is independent of the first component, and contains as much of the remaining information in all the measures as possible, and so on.The result from examining the greater-than-one eigenvalues of the principal components suggested 12 components to retain as shown in Table A3 in the Appendix. Each row of the table contained factor loadings that indicated which measures belong to each component. The values of factor loadings were still not clear in indicating which measures should belong to which components because the values of factor loadings of many measures on each component were close. In order to develop a clear pattern, a modification of the factor loadings by rotating the principal components was necessary.  Another important result of this step is the total variance explained by each component. Table 6 summarizes the result. The 12 components together accounted for 75% of variance of all the measures. The first component explained 39% of variance of all the measures whilst that of the last component explained only 2%.Factor rotationThe rotation of the components was performed to adjustComponentExtraction sums of squared loadings (eigenvalues)Rotation sums of squared loadingsTotalPercentage of varianceCumulative percentageTotalPercentage of varianceCumulative percentage12345678910111220.5533.815 2.307 2.066 1.934 1.762 1.525 1.358 1.265 1.103 1.0701.01739744433322223946505458616467697173755.952 5.494 4.404 4.067 3.819 3.292 2.609 2.550 2.546 2.060 1.5781.40111108876555433112129374450556065697275Table6 Total variance explainedthe values of factor loadings so that the new values were closer to −1, +1 or 0. These new values make the grouping of measures easier if each variable has a high factor loading (close to −1 or +1) on a single component, but small factor loadings (close to 0) on the other components.  The orthogonal rotation using the varimax method was performed. This rotation made it easier to clearly identify which measures belong to which components. Retaining 12 components was still suggested; the results are shown in Table 6. However, the prior theory (i.e. the theory of hierarchy, multilevel, systems) being applied to the problem suggests that the selection criteria should be selected according to existing organizational units of contractors. Based on a combination of this and the prior theory, nine components were adopted and named as shown in Table 7.  Also in Table 7, the percentage of variance explained, factor loadings and their normalized weights of relative importance are summarized. The total percentage of variance of the nine criteria was 69%, indicated as acceptable intercorrelation. The criteria ‘engineering/ construction’ accounted for the most variance (39%) followed by ‘procurement/contract’ accounting for 7%. Surprisingly, ‘financial strength’ accounted for only 3% of the variance. One possible reason is that most contractors can use outsourcing funds to run their businesses. The structure of a common set of contractor ability criteria with their normalized weights of relative importance is shown in Figure 1.ConclusionsTable7 Percentage of variance, factor loading and normalized weightsCriteria and measuresPercentage of varianceFactor loadingNormalized weight (%)(1) Engineering/constructionProject planningProject executionProject monitoringAbility to adjust a project(2) Procurement/contractProcurement plansDelivery controlSubcontractor control(3) Human resources Personnel planningPersonnel developmentPersonnel maintenance(4) Project managersProject management experienceCommunication skillsAdaptability(5) Quality management systems Quality system implementationQuality system audits(6) Health and safetyOccupational health and safety(7) Financial strength Financial ratiosBanking arrangementCredit ratings(8) Plant/equipmentPlant/equipment acquisitionPlant/equipment maintenance(9) Public relationsPerformance39744433322.790 1.198 1.633 1.2531.245 0.711 3.9540.378 1.479 1.7470.602 1.899 1.5000.600 2.3030.7020.476 2.185 0.5701.480 0.2551.29857411724181021126761141486154837621794100 4156718485153100This study attempts to find a common set of contractor ability criteria for government and private sectors, which includes the physical property of contractors (i.e. organizational units of contractors). Three main analyses focusing on the degree of importance of criteria and measures were performed. The first analysis determined similarities and differences in the selection of criteria between government and private sectors using the comparison of importance index (mean/STD) and using the Mann Whitney U method to test hypotheses on mean differences of criteria and measures. The results revealed that both government and private sectors considered similar criteria as they evaluated contractor ability, which infer that if the criteria are developed consistent with organizational units of contractors, types of clients do not affect the selection of criteria. This then suggests that a common set of contractor ability criteria can be developed by applying factor analysis. The second analysis examined relationships between all criteria and measures, which is aimed at validation of them. Overall, the result showed that criteria and measures were correlated. In addition, the observation of correlations revealed that the members (measures) should be grouped into clusters because the members of a cluster correlate highly with one another and correlate much less with the members of other clusters. This again provides persuasion to apply factor analysis. The third analysis applied factor analysis to group to highly correlated measures together. As a result, a common set of contractor ability criteria have been developed, namely, ‘engineering/ construction’, ‘procurement/contract’, ‘project managers’, ‘human resources’, ‘quality management systems’,‘health and safety’, ‘plant/equipment’, ‘financial strength’ and ‘public relations’. The theory of hierarchy, multilevel, systems led us to infer that the contractor ability criteria should be developed to correspond with existing organizational units of contractors. The results of the factor analysis confirmed this inference. One possible reason is that a common characteristic of all contractors is the existence of their organizational units, which, in general, structure an organization. The commonality then lead to the development of a common set of contractor ability criteria. Although the differences of organizational units between contractors may exist, similar necessary functions of contractors are performed to operate their businesses. Thus, this reason is still valid. Lastly, the results of this paper have provided a starting

position for development of a realistic working model in tender evaluation.AcknowledgementsThe authors appreciate the Thai construction industry participants’ attempts to complete the questionnaire. Also, the authors wish to thank the Physical Infrastructure Centre, Queensland University of Technology for supporting travelling expenses to gather the data in Thailand. Our thanks are also extended to the anonymous reviewers for their invaluable comments.ReferencesAaker, D.A., Kumar, V. and Day, G.S. (1998) Marketing research, 6th edn, John Wiley & Sons, New York. Babbie, E. (1989) The Practice of Social Research, 5th edn, Wadsworth Publishing, Belmont, CA. BMA Standards for Contractor Registration, Thai (1997) Bangkok Metropolitan Administration.CIDA (1993) The Australian Construction Industry Prequalification Criteria for Contractors and Subcontractors,  CIDA.DARD Standards for Contractor Registration, Thai (1999) The Department of Accelerated Rural Development.Dirickx, Y.M.I. and Jennergren, L.P. (1979) Systems Analysis by Multilevel Methods, John Wiley & Sons, Bognor Regis.DoH Standards for Contractor Registration, Thai, The Department of Highway.Hatush, Z. and Skitmore M. (1997) Criteria for contractor selection. Construction Management and Economics, 15(1), 19–38.Holt, G.D., Olomolaiye, P.O. and Harris, F.C. (1994) Factors influencing UK construction clients’ choice of contractor. Building and Environment, 29(2), 241–8.Keller, G. and Warrack, B. (1997) Statistics for Management and Economics, Duxbury Press, Belment, CA.Lehmann, D.R. (1989) Market Research and Analysis, 3rd edn, Irwin, Homewood, IL.Liston, J. (1994) Prequalification of contractors, Series: Research report 94-10, Physical Infrastructure Centre, Brisbane,QUT.Liston, J. (1999) Contracts Administration: the lecture notes, Brisbane, QUT.Mesarovic, M.D., Macko, D. and Takahara, Y. (1970) Theory of Hierarchy, Multilevel, Systems, Academic Press, New York.Nunnally, J.C. (1967) Psychometric Theory, McGraw-Hill, New York.Nunnally, J.C. (1978) Psychometric Theory, 2nd edn, McGraw-Hill, New York.Pongpeng, J. (2002) Multicriteria and multidecision makers in tender evaluation, unpublished PhD thesis, School of Civil Engineering, Queensland University of Technology.PWD Standards for Contractor Registration, Thai (1994) The Public Works Department.RID Standards for Contractor Registration, Thai, The Royal Irrigation Department.Russell, J.S. (1996) Constructor Prequalification: Choosing the Best Constructor and Avoiding Constructor Failure, ASCE Press, New York.Russell, J.S. and Skibniewski, M.J. (1988) Decision criteria in contractor prequalification. Journal of Management in Engineering, ASCE, 4(2), 148–64.Russell, J.S. and Skibniewski, M.J. (1990) Qualifier-1: contractor prequalification model. Journal of Computing in Civil Engineering, ASCE, 4(1), 77–90. Russell, J.S., Hancher, D.E. and Skibniewski, M.J. (1992) Contractor prequalification data for construction owners. Construction Management and Economics, 10(2), 117–35.Siegel, S. and Castellan, N.J.Jr (1988) Nonparametric Statistics for the Behavioral Sciences,  McGraw-Hill, Singapore. SPSS training (1998) SPSS training series, by IT services in 2001, QUT.Note1.	All values were converted to $A using 23 Bahts/ Dollar.
AppendixMaster plans      5.22            5.06              5.57      1      1                   3Continuously reporting      4.93            4.93              4.91      2      3           14A list of plant/equipment      4.82            4.67              4.99      3      5       	  8Past performance      4.82            5.06              4.62      4      2           20Problem-solving skills      4.80            4.78              4.95      5      4           10Resource plans      4.67            4.55              4.91      6      7           13Weekly actions      4.59            4.56              4.72      7      6           18Management of conflict      4.47            4.28              5.01      8      9      	   7Technical ability      4.44            3.78              6.34      9    20            1Detailed plans      4.43            4.07              5.13   10    12    	  6Receipt of goods      4.34            4.20              4.55   11    10          24Warehouse procedures      4.29            4.07              4.60   12    13          21Methods of reviewing drawing   and change orders   4.29            4.06              4.80   13    14          17Previous and current position      4.25            3.76              4.93   14    16          11Budgeting      4.17            3.57              6.06   15    26          2Monthly actions      4.16            4.33              3.99   16      8   	  38Analysis skills      4.11            3.65              5.18   17    22             5Observation skills      4.04            3.52              5.36   18    29             4Distribution procedures      4.03            3.70              4.49   19     21           26Analysed reporting      4.01            3.97              4.07   20    15           36Tolerance for ambiguity and              3.99 changes             3.60              4.81   21     25           16Table A1	Criterion comparison of importance index and ranking order across sectorsCriteriaImportance index (Mean/STD)Ranking orderOverallGovernmentPrivateOverallGovernmentPrivateProject planningProject monitoringProject management experienceAbility to adjust a projectPerformanceProject executionPersonnel planningDelivery controlPlant/equipment acquisitionAdaptabilityHealth and safetyFinancial ratiosSubcontractor controlQuality system auditsPlant/equipment maintenanceCommunication skillsBanking arrangementPersonnel maintenanceCredit ratingsProcurement plansPersonnel developmentQuality system selectionQuality system implementation5.81 5.70 5.45 4.73 4.69 4.57 4.49 4.37 4.16 4.05 4.01 3.87 3.78 3.76 3.72 3.67 3.64 3.57 3.55 3.51 3.32 3.213.216.07 6.07 5.27 4.78 5.09 4.51 4.41 4.11 4.05 3.77 3.56 3.26 3.09 3.44 3.53 3.44 3.68 3.35 3.35 3.15 3.01 2.942.985.53 5.25 5.74 4.70 4.27 4.79 4.45 4.78 4.31 4.65 4.79 5.15 5.65 4.32 4.04 4.18 3.57 3.98 3.81 4.23 3.94 3.643.6012345678 9 101112131415161718192021222312354678 9 1012182015131411171619212322341914611 8 1310 75 2 12171623182015192122Table A2	Measure comparison of importance index and ranking order across sectorsMeasure Table A2	(cont’d)Balance ability between conserving               3.97 and challenging traditional operations or behaviours3.61      4.46             22          23           27A line of credit to the contractor                 3.93 from the bank3.87      3.94             23          17           43Persuasive skills	        	   3.873.49      4.59             24          31           23Social reputation of contractor	               3.853.82      3.83             25          19           44Material schedule	               3.833.50      4.49             26          30           25A personnel chart	               3.823.84      3.76             27          18           47Current performance	               3.794.16      3.41             28          11           50Communication of the plans to             3.77 involved people3.32      4.95             29          35            9A plan of renting or leasing              	        3.74 plant/equipment3.60      3.97             30          24           41Communication line	               3.693.46      4.25             31          32           30Conditions in bank guarantee	               3.683.44      4.19             32          33           32In-house training	               3.633.24      4.32             33          36           29Promotion	               3.633.34      4.08             34          34           34Documented processes being                      3.63 followed by the contractor3.53      3.76             35          28           48Contingency plans	               3.623.19      4.86             36          37           15Documented process in place ready              3.62 to address standard elements3.53      3.82             37          27           45Interaction between the contractor              3.60 and subcontractors3.05      4.72             38          48           19General condition of subcontractors 	    3.593.06      4.92             39          45           12Competitive incomes/welfare	               3.573.16      4.36             40          38           28Documented processes being                      3.51 effective and suitable3.16      4.15             41          40           33Health and safety plan	               3.483.16      4.08             42          39           35Supervisor coaching	               3.433.12      4.03             43          42           37Special conditions of subcontractors          3.412.90      4.60             44          54           22Health and safety control	              3.403.06      3.95             45          44           42Subcontractor schedule	               3.403.00      4.22             46          49           31Average length of time that the                  3.39 contractor pays subs/suppliers3.15      3.97             47          41           40Progressive steps in implementing               3.38 a quality system3.09      3.98             48          43           39Backing preparation from that bank	    3.282.99      3.77             49          50           46Programmed maintenance	               3.162.94      3.51             50          52           49Financial leverage ratio	              3.093.05      3.16             51          47           54A plan of renting or leasing                       3.05 plant/equipment3.06      3.03             52          46           60Length of time with that bank	              3.012.95      3.06             53          51           58Working capital ratio	              2.972.81      3.24             54          56           52Spare parts stocking	              2.972.91      3.05             55          53           59Asset turn over ratio	              2.962.77      3.29             56          58           51Collateral for security by the bank              2.952.85      3.08             57          55           56Gross profit	               2.852.69      3.21             58          60           53Current banking organization	               2.842.71      3.07             59          59           57Quick asset ratio	               2.822.60      3.13             60          61           55Interest rate charged by the bank	              2.762.80      2.75             61          57           62ISO 9000 series	               2.712.54      3.03             62          62           61AS 3900 series	               1.861.85      1.86             63          63           63268	Pongpeng and ListonContractor ability criteria	269