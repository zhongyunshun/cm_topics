Multi-criteria evaluation model for the selection of architectural consultantsFranco K. T. Cheung , Judy Leung Fung Kuen & Martin SkitmoreTo cite this article: Franco K. T. Cheung , Judy Leung Fung Kuen & Martin Skitmore (2002)Multi-criteria evaluation model for the selection of architectural consultants, ConstructionManagement & Economics, 20:7, 569-580, DOI: 10.1080/01446190210159818To link to this article:  https://doi.org/10.1080/01446190210159818Full Terms & Conditions of access and use can be found at https://www.tandfonline.com/action/journalInformation?journalCode=rcme20
Construction Management and Economics (2002) 20, 569–580	Multi-criteria evaluation model for the selection of architectural consultants FRANCO K. T. CHEUNG1, JUDY LEUNG FUNG KUEN1 AND MARTIN SKITMORE2*1Department of Building and Construction, City University of Hong Kong2School of Construction Management and Property, Queensland University of Technology, Gardens Point, Brisbane, Queensland 4001, AustraliaReceived 17 August 2001; accepted 24 May 2002The selection of a competent architect is vital to the success of a development. Like in many developed countries, developers in Hong Kong select architects based on a set of criteria. Price is not the only consideration in the process, and decisions rely heavily on subjective judgement. By conducting a questionnaire survey, the research reported here identi ed the common criteria for selection and their relative importance for an objective selection. This involved the use of an evaluation method called the analytical hierarchy process (AHP). Survey data from projects with similar characteristics were used to compute the criteria weights. Multi-criteria models for seven out of 27 categories of project were built with reference to the computed weights derived from the survey. In addition, a computer program, called the Architectural Consultant Selection System (ACSS), was designed to illustrate a logical approach for the evaluation of prospective consultant architects based on the models constructed.Keywords: Selection criteria, analytical hierarchy process, consultant architect
IntroductionA good design provided by the architect not only leads to pleasing structures and facilities but also determines the social, cultural and economic quality of the built environment now and in the future. Furthermore, the secret to a successful project lies in the professional, business, and personal relationships between the owner and the architect. Therefore, selecting an architect is one of the most important decisions that the client makes when undertaking a building project. The better the client’s procedure for selecting an architect, the better the client will like the results of his or her construction project.*Author for correspondence. e-mail: rm.skitmore@qut.edu.auConstruction Management and EconomicsISSN 0144-6193 print/ISSN 1466-433X online © 2002 Taylor & Francis Ltd http://www.tandf.co.uk/journalsDOI: 10.1080/01446190210159818  Different architect selection processes have been developed for different kinds of client. For example, typically, public sector clients require more competitive procedures than the private sector (Molenaar et al., 1998). The Architectural Institute of British Columbia (AIBC, 1998) divided these selection processes into two groups: direct selection (where a single architect or architectural practice is considered and approached on the basis of reputation, personal acquaintance or some personal recommendation), or comparative selection (where several candidates are considered and ranked in some way). This is a favoured approach because it can generate a broad search for the best solution to a particular building opportunity (Haviland, 2000). One form of comparative selection is the design competition, as it bene ts from available state of the art knowledge as well as generating prototypical ideas (AIBC, 1998). Most commonly, comparative selection involves the consideration of the price to be charged for the service – an aspect that has been considered in detail by the Construction Industry Council (CIC, 1998), who list out  ve basic methods of selection in which price plays a part. In fact, price is a central issue today, with selection procedures being seen as comprising a continuum ranging between price and quality (Molenaar et al., 1998).  The advantage of price as a selection criterion is, of course, in its objectivity and transparency, and architects are increasingly being selected for projects solely on basis of the price to be charged for their services (Dwight, 2000), in exactly the way the majority of construction contractors are appointed. However, many commentators have argued that this practice is not appropriate for the provision of services (Gronroos, 1984; Latham, 1994; AIBC, 1998), and that any form of price competition drives fee levels down, thus reducing the quality of services involved (Day, 1998; ACEC, 2000). What is needed, it seems, is for the selection to be based predominantly on quali cations and competence (CIC, 1998). The two-envelope system attempts to do this but is said to fail because it requires a fee bid to be prepared when the scope and nature of the services required are not well de ned (Peck, 1998). Perhaps the most promising method to date is ‘quality based selection’ (QBS), which is a process that enables the project owner to obtain the services of a highly quali ed design professional at a fair and reasonable cost (CEC/PA, 2000). This is said to be the most widely endorsed legal method for selecting a design professional by overseas public owners (CEC/DE, 2000) and is recommended by the Australian Council of Building Design, the Architects Council of Europe (ACE), Association of Japanese Consulting Engineers and the American Public Works Association and various other organizations around the world (CIC, 1998). Although the recently developed selection processes have attempted to consider more criteria, the basis for making decision remains judgmental.  The research described in this paper was aimed at (1) describing the nature of architect selection systems in Hong Kong, (2) identifying the criteria needed for architect selection in Hong Kong, and (3) the development of a new selection system through the application of a multi-criteria evaluation model based on the ‘analytical hierarchy process’, or AHP (Saaty, 1980). To help accomplish these aims, it was necessary to carry out a postal questionnaire survey, by which it was shown that, in Hong Kong, public sector departments usually have their own selection systems but that there are no standardized procedures developed in private market. In both the public and private sectors, the systems used are rather subjective and lack a systematic way to evaluate the architectural consultants. Thus, the system proposed here seeks to improve the objectivity in the selection process. The survey is used to show that the selection criteria in the literature are commonly used in Hong Kong. Based on a selection of these under a classi cation containing four critical factors, a theoretical model was developed. The logic of the model was used further to produce a computer evaluation program, which is used here to demonstrate how an objective decision may be made.Model designSelection criteriaTable 1 summarizes the selection criteria used/ proposed by 10 different organizations/parties and grouped under similar characteristics. Of these, 12 were selected as being applicable in Hong Kong, as follows:Background of  rmReputationTechnical competence/quali cationExperience with similar projectPast performance Cost controlQuality of workTime controlCapacity to accomplish the work Present workloadAvailability of quali ed personnelProfessional quali cation/experienceProject approachApproaches to time scheduleApproaches to qualityDesign approach/methodology  The ‘consultant fee’, being one of the factors thought most likely to be considered by clients in Hong Kong, was added as a further criterion.Factors affecting criteria weightsDifferent clients have different objectives. For example, public organizations are likely to concentrate more on serving the public interest than making pro t when initiating a development, while private developers are more likely to be concerned with the  nancial bene ts to be gained. Hence, the nature of the client is likely to affect the weights of the evaluation criteria. For example, the public sector may place a greater emphasis on the design approach, while the private developer may be more concerned with the consultants’ fees. For similar reasons, the size of the organization is also likely to affect the criteria weights, as the organizations’ objectives are affected by their size. Moreover, often the size of organization is related to the size of the project.  In Hong Kong, the most common types of development comprise residential buildings, commercial buildings, mixed residential and commercial buildings, and other public facilities such as schools. The type of project is likely to be a critical factor affecting the weights of the evaluation criteria, because different project categories place different requirements on the design team. For example, residential building designs are quite similar in Hong Kong and most design  rms are able to do thisTable 1	Summary of evaluation criteria suggested by professional organizationsSelection CriteriaProfessional organizationsOf ce ofProfessionalAmerican Day	CICZorn	New	Architect	Consulting	ConsultingFederalEngineersInstitute	(1998) (1998)(1999) Hampshire	Engineer	Engineers	EngineersProcure-OntarioofQuali cations Contract	Council	Councilment(1997)ArchitectsBasedCoordination of	ofPolicy(AIA)Selection(2000)Pennsylvania Illinois(OFPP)(1997)Coalition(CEC/PA)(CEC/IL)(1998)(1999)(2000)(2000)Firms’ backgroundFirms’ quali cationslReputationlllFinancial ll  stability Technicallllllcompetence/  quali cation AwardlExperiencelllllllllwith similar projectNo. oflsimilar projects completedPast performance Cost controllllllQuality of workllllTime controlllllCapacity to accomplish the workPhysical resourcesllCurrent no. oflcontractsPresent workloadlllllAvailability ofllll  quali ed personnel Firms’ sizellProfessionalllllllquali cations/ experienceProject approach Approaches to lllltime scheduleCost control (on lschedule)Approaches to lllqualityGrasp of project requirementllkind of work. However, some commercial developments, such as large-scale shopping malls or hotels, require much more specialized treatment from designers.  The size of the project also is likely to affect the weights of the evaluation criteria. Clients in Hong Kong do not allow small-size companies to undertake large-scale projects. In such a situation, the current workload and availability of quali ed staff are going to be very important aspects affecting the selection process.Use of the analytical hierarchy process (AHP)The selection of architectural consultants is a multicriteria problem, i.e. a situation in which one has a set of criteria to consider on a set of alternatives, in order to determine the best alternative. There are many different types of technique and theory for this, including decision-analysis models (based on multi-attribute utility theory) and multi-criteria decision-analysis techniques. However, most of the criteria here are qualitative in nature and often can be represented only by subjective judgement in linguistic format. Therefore, a multi-attribute evaluation model based on the concept of the analytical hierarchy process (Saaty, 1980) was introduced. In the process, perceptions, feelings, judgments and memories are organized in a hierarchy and are compared pairwise to determine their relative magnitudes that in uence decision results. AHP arranges these dimensions in a network structure that provides a framework for breaking down a problem (e.g. selection of architect suggested in this paper) into its smaller constituent parts (Saaty, 2000). It is a ‘decision-aiding tool for dealing with complex and multi-criteria decisions’ (Partovi, 1992) and has been used in certain construction industry contexts: for the selection of projects (Korpela and Tuominen, 1997), selection of project proposals (Mohanty, 1992; Mathur and Deshpande, 1995), selection of procurement method (Cheung et al., 2001) selection of contractors (Mustafa and Ryan, 1990; Assaf and Jannadi, 1994; Kong and Cheung, 1996; Fong and Choi, 2000; Al-Harbi, 2001).Development of the modelsAHP goes through three stages: (1) constructing the hierarchy for criteria and subcriteria, (2) comparing the weight of criteria and subcriteria, and (3) evaluating the alternatives by computation of the relative weights of criteria and subcriteria.  A  ve-level hierarchy is presented in Figure 1. The top level is the selection goal. The second level is the  ve main criteria, i.e. ‘ rm’s background’, ‘past performance’, ‘capacity to accomplish the work’, ‘project approach’ and ‘consultant fee’. The third level comprises the subcriteria expanding these  ve issues. After Liberatore et al. (1992), the fourth level assigns a rating to each subcriterion for every alternative, instead of the normal pairwise comparisons, by means of a  ve-point rating scale that codes as outstanding (O), good (G), average (A), fair (F) and poor (P), with the priority weights of these  ve scales (i.e. O, G, A, F, P) being established using pairwise comparisons.  Since it was assumed that the relative importance of the evaluation criteria might be affected by ‘nature of client’, ‘size of organization’, ‘type of project’ and ‘sum of project’, the structure of the theoretical evaluation model was divided into 27 categories as shown in Figure 2. To test this assumption, the results were categorized accordingly. Figure 2 shows 27 categories (from group 1 to group 27) classi ed under different levels. In order to resolve the issue, the data were classi ed into groups with similar characteristics. The  rst level is ‘nature of client’, which includes the public, semipublic and private sectors. This is classi ed into three types of  rm size: ‘under 75’, ‘75 to under 150’ and ‘150 or above’. These are then subdivided into the four types of project usually found in the Hong Kong construction market: residential, commercial, residential and commercial mix and other public facilities development. Following this is the project size, categorized into ‘below HK$100 million’, ‘between HK$100 million and HK$500 million’ and ‘above HK$500 million’. Since public facilities comprise only a small portion of all the developments, and in order to make the structure more clear, the level under public facility is indicated by just a dotted line.Evaluation of criteriaBased on the developed hierarchy and the project classi cation, a questionnaire was set out to collect data for evaluating the weight of the identi ed criteria. A total of 259 questionnaires were mailed to a random sample of public, semi-public and private clients obtained from the list of the real estate developers association of Hong Kong. Fifty-seven questionnaires were returned. Of these, 53 were fully completed, representing a 19.5% usable response rate. In determining the weights of the selection criteria, AHP provides a consistency check, where a sample with a consistency ratio less than 0.1 would be rejected. Thirty-six sets of sample data were found to be consistent. Among them, 35 sets came from the private sector and only one from the public sector, therefore only those results from the private sector were categorized. Only seven groups of data were available from the survey: groups 5, 11, 15, 21, 22, 23 and 27. The two-tailed t-distribution test is used to exclude samples that contain inconsistent weights. The Appendix describes the questionnaire survey and the allocation of weight in detail.General modelsGroup 5Group 5 comprised seven responses. One of these (sample 3) was signi cantly different from the sample mean so this was considered to be a special case that should be excluded from the model. After its removal,

Figure 2 Proposed classi cation of projectsa consistent weight was found for the 13 evaluation criteria within this category.Group 21This group also comprised seven responses. Two of these (samples 12 and 13) were signi cantly different from the sample mean, so these samples were removed. Since sample 12 had seven criteria outside the con dence interval, it was removed  rst. After excluding sample 12, there were only two samples with four weights out of 78 outside the interval, and this was considered to be acceptable.Group 23Group 23 comprised eight responses. Sample 34 had the most ( ve) signi cantly different criteria and was removed  rst. The next to be removed was sample 31. After removing these two samples, there was still one sample with one criterion outside the interval and this was also excluded in this group.Table 2 Summary of the sample mean of global priority weight of the seven groupsCriterionGroup5212327111522Reputation0.0050.0050.0220.0050.0730.0280.024Technical competence/quali cation0.0320.0260.0120.0270.0720.0280.194Experience with similar project0.0130.0230.0090.0250.0160.0830.088Cost control0.0300.0250.0210.0230.0160.0750.083Quality of work0.0350.1190.0580.1130.0570.0750.083Time control0.0460.0620.0190.0550.0560.0750.083Present workload0.0380.1330.0340.1230.1050.0960.037Availability of quali ed personnel0.1210.0600.1210.0620.0570.0960.037Professional quali cation/experience0.4000.1740.2990.1660.1800.0960.037Approaches to time schedule0.0670.0120.0230.0150.0710.0600.050Approaches to quality0.0450.0370.1840.0420.0380.0600.050Design approach/methodology0.0160.0740.0730.0860.1910.1790.050Consultant fee0.1520.2500.1140.2590.0690.0510.187Group 27Group 27 comprised nine sets of responses. All of these had at least one signi cantly different weight. After removing samples 18 and 19, only one sample had all criteria within the interval, so removal of sample was still required. Samples 23, 24 and 26 were also removed by trial and error.Groups 11, 15 and 22There were two responses in group 11 and one in each of groups 15 and 22. Since the sample sizes of groups 11, 15 and 22 were too small, the same method could not be used to test whether the weights of the evaluation criteria with these groups were distributed with the same mean.Remaining groupsTable 2 summarizes the sample means of the seven groups after this procedure. Due to the small sample sizes in grous 11, 15 and 22, the sample mean of these three groups is less reliable. Therefore, these three groups were then excluded. Figure 3 summarizes the results for the remaining groups.Figure 3 Summary of the sample mean for groups 5, 21,23 and 27  In Figure 3, within groups 5, 21, 23 and 27 the criterion ‘professional quali cation/experience’ had a relatively high weight. This may be because the quality of the design is usually dependent on the ability of a single person in the organization, and therefore the quali cation or experience of that person is a key issue. Moreover, property development is a business investment, focusing on making a pro t, and reducing development costs is one way to increase project returns. Consequently, developers have a particular interest in the fee proposed by the consultants. ‘Reputation’, on the other hand, had relatively low weights among the 13 evaluation criteria, suggesting that potential design  rms selected for the  nal decision have already been screened by some pre-quali cation process, making it of relatively low importance at this stage.  It was noted that groups 21 and 27 were very similar, and this was con rmed by a t-test. On the other hand, the weights of the 13 evaluation criteria for groups 5 and 23 are quite similar. Both have the same project type and value classi cation but differ in  rm size (group 5 is a small developing  rm while group 23 is a large  rm). However, the weights of the 13 evaluation criteria for these two groups are quite similar, suggesting that the size of the developer has little in uence on the criteria weights in this case.Application of the multi-criteria evaluation modelTo show how multi-criteria evaluation could be applied in a simple and ef cient way, a computer program called the ‘architectural consultant selection system’ (ACSS) was developed based on the criteria weights of the seven groups, and written in Delphi 4.0™. ACSS aims at providing an ef cient, consistent and objectiveTable 3 Multi-criteria evaluation result extracted from ACSSProject particulars1. Nature of client2. Firm size3. Project type4. Contract sumPrivate<75 employee architectural  rms 6CommercialHK$100–500 millionGroup 5 modelEvaluation of architectsCriteria	GPW for	Firm A	Firm B	Firm C	group 5	Input ratingSystemInput ratingSystemInput ratingSystemgeneratedgeneratedgeneratedscorescorescore1. Reputation0.005outstanding0.500fair0.125fair0.1252. Technical competence/0.032outstanding3.200poor0.000average1.600quali cation3. Experience with 0.013good0.975poor0.000average0.650similar4. Cost control0.030outstanding3.000poor0.000poor0.0005. Quality of work0.035good2.625outstanding3.500outstanding3.5006. Time control0.046outstanding4.600poor0.000outstanding4.6007. Present workload0.038poor0.000fair0.950good2.8508. Availability of0.121fair3.025average6.050average6.050quali ed personnel9. Professional quali cation/0.400outstanding40.000fair10.000good30.000experience10. Approaches to0.045fair1.125 outstanding4.500good3.375time schedule11. Approaches to0.045fair1.125outstanding4.500good3.37512. Design approach/0.016poor0.000good1.200poor0.000methodology13. Consultant fee10.152good11.400outstanding15.200outstanding15.200Total weighted score:75.47541.52567.950under evaluation.method for selection of architects. The evaluation process using ACSS contains four steps: (1) determination of project particulars, (2) comparison of fee, (3) assessment of performance and (4) computation of score.Determination of project particularsThe  rst step a client has to consider in the selection of an architect for a particular project is the characteristic of the project. The program allows clients to choose the particulars of a project, and their choice would determine which group the project belongs to.Comparison of consultant feesDifferent from the other criteria identi ed in the next step, the consultant fee proposed by an architect is a measurable criterion. In the program, the rating for ‘consultant fee’ is measured by the ratio of the actual amount of the lowest fee to the fee proposed by an architect under evaluation.Assessment of performanceThe most important task in the selection process is to evaluate the performance of architects. A  ve-point rating scale named as outstanding (O), good (G), average (A), fair (F) and poor (P) with corresponding ratings of 1.000, 0.500, 0.250, 0.125 and 0.063, respectively, was adopted.Computation of scoreAfter rating the performance, the programme would automatically calculate the score. Table 3 shows an example of the multi-criteria evaluation result extracted from ACSS for a selection from among three architects in a group 5 project. The  nal scores were computed by adding the normalized weights for the selected ratings of each subcriterion multiplied by the global priority weight of the subcriterion itself.  Under the new system of ACSS, the decision-makers or the evaluators need only to refer to the hierarchy in Figure 1 and assess the performance of the architects according to the steps suggested to make an objective selection.ConclusionsTraditionally, building clients appoint various design consultants, such as architects, structural engineers, building service engineers, etc., to provide professional services for the management of the whole project. During the design and construction of the projects, the architect plays a major role and his or her selection is therefore one of the most important decisions the client makes. As the survey has shown, these evaluations are currently conducted in a rather subjective manner, and it is likely that the process will bene t from a more objective method of evaluation. Therefore, a multicriteria evaluation model has been developed to tackle the task of interpreting subjective judgement in a logical and systematic manner. Based on the selected criteria and four critical factors, this theoretical multicriteria model uses the concept of the ‘analytical hierarchy process’ (AHP). In order to modify this theoretical model to a general model that may be applied to the actual situation in Hong Kong, the weight of each criterion was established by means of a questionnaire survey. By applying the methodology of AHP to the collected questionnaires, 36 sets with a consistency ratio of less than 0.1 were used, with 35 of these coming from the private sector. These were classi ed into 27 categories for the seven groups of data.  With the exception of groups 11, 15 and 22, which were too small, particular cases in each group were excluded by using a two-tailed t-distribution test. The  nal criteria weights for these seven groups are shown in Table 2. It was also shown that the criteria set identi ed in the literature review are commonly used in the selection of architectural consultants in Hong Kong, which provides some validation of the model. Furthermore, the  nal criteria weights of the seven groups were used to construct a computer program, ‘ACSS’. The program is suf cient to show the simplicity and objectivity of the use of the multi-criteria approach to select architects.  The study also identi ed four factors that in uence decision makers in assigning the weights to the evaluation criteria. In the actual market situation, it is expected that the developing organization would consider other aspects in addition to these four factors. Hence, further study is necessary to derive a comprehensive set of in uencing factors for the selection of architectural consultants. In addition, the evaluation model was developed for the private sector with only three of the seven groups being investigated, suggesting ample scope for further investigation.AcknowledgementsThe guidance and valuable suggestions of Mr. Paul Ho of the Division of Building Science and Technology, City University of Hong Kong are gratefully acknowledged.ReferencesACEC (2000) Bidding is not the solution: case studies in bidding. American Consulting Engineers Council, available at http://www.acec.org/programs/bidding.htmAIA (1997) Choosing an Architect, Cool Fire Technology. American Institute of Architects, available at http:www. cftech.com/BrainBank/CORPORATEADMINISTRATION/ChoosAnArchit.htmlAIBC (1998) How to  nd, select and engage an architect. Architectural Institute of British Columbia, available at http://www.aibc.bc.ca/public/seeking_an_arch/selecting.htmlAl-Harbi, K. M. (2001) Application of the AHP in project management. International Journal of Project Management, 19(1), 19–27.Architect Engineer Contract Coordination (2000) A-E quali cation Factors Explained. Architect Engineer Contract Coordination, available at https://www.nwp.usace.army.mil/ec/ts/ae/Assaf, S. and Jannadi, O. M. (1994) A multi-criterion decision-making model for contractor prequali cation selection. Building Research and Information, 22(6), 332–5.CEC/DE (2000) How to select an engineer. Consulting Engineers Council of Delaware, available at http://www. cecde.org/qbs.htmlCEC/IL (2000) Selecting a Consulting Engineer. Consulting Engineers Council of Illinois, available at http://www/ cec-il.org/howsel.htmlCEC/PA (2000) Selecting the right consulting engineer. Consulting Engineers Council of Pennsylvania, available at http://www.cecpa.org/selecting_a_ce.htmCheung, S. O., Lam, T. I., Leung, M. Y. and Wan Y. W. (2001) An analytical hierarchy process based procurement selection method. Construction Management and Economics, 19(1), 427–37.CIC (1998) A Guide to Quality Based Selection of Consultants, Construction Industry Council, London.Day, W. (1998) Performance over price. American School & University, available at http://www.asumag.com/magazine/Archives/0898profsvcs.htmlDwight, B. (2000) The low bid heart surgeon. Consulting Engineers Council of Minnesota, available at http://www. cecm.org/low_bid_heart_surgeon.htmFong, S. W. and Choi, S. K. Y. (2000) Final contractor selection using the analytical hierarchy process. Construction Management and Economics, 18(5), 547–57.Gronroos, C. (1984) Strategic Management and Marketing in the Service Sector, Swedish School of Economics and Business Administration, Helsinki.Haviland, D. (2000) You and your architect. American Institute of Architects, available at http://www.aiapvc.org/ yourarch.htmKong, W. K. and Cheung, S. M. (1996) A multi-attribute tender evaluation model. In Proceedings of CIB W89, Beijing, 21–24 October.Korpela, J. and Tuominen, M. (1997) Group decision support for analysing logistics development projects. Proceedings of the Hawaii International Conference on System Sciences, 30(2), 493–504Latham, M. (1994) Constructing the Team, HMSO, London.Liberatore, M. J., Nydick, R. L. and Sanchez, P. M. (1992) The evaluation of research papers. Interfaces, 22(2), 92–100.Mathur, U. P. and Deshpande, V. B. (1995) Decision making in value engineering using AHP, in Value Engineering in Project Management Krishnan, P. and Saxena, K. R. (eds), Association of Consulting Civil Engineers, IBH, New Delhi, pp. 125–36.Mohanty, R. P. (1992) Project selection by a multiple-criteria decision-making method: an example from a developing country. Project Management, 10(1), 31–8.Molenaar, K., Zimring, C. and Augenbroe, G. (1998) A guide to project delivery for federal buildings. Georgia Institute of Technology, available at http://cem.ce.gatech.edu/GSA/Mustafa, M. A and Ryan, T. C. (1990) Decision support for bid evaluation. Project Management, 8(4), 230–5.New Hampshire Quali cations Based Selection Coalition (1999) The QBS Process. New Hampshire Quali cations Based Selection Coalition, available at http://www.nhqbs. org/process.htmlOFPP (1998) A Guide to Best Practices for Performance-Based Service Contracting. Of ce of Federal Procurement Policy.Partovi, F. Y. (1992) Determining what to benchmark: an analytical hierarchy process approach. International Journal of Operations Production, 14(6), 25–39.Peck, M. (1998) NSW two-envelope system not the solution. Royal Australian Institute of Architects, available at http://www.raia.com.au/media/html/pr23jan98.htmProfessional Engineers Ontario (1997) Guideline for Professional Engineers Providing Project Management Services. Professional Engineers Ontario, available at http://www. peo.on.ca/offering/managem_guide.htmSaaty, T. L. (1980) The Analytic Process: Planning, Priority Setting, Resources Allocation, McGraw-Hill, Maidenhead.Saaty, T. L. (2000) Fundamentals of Decision Making and Priority Theory with the Analytic Hierarchy Process, Vol. VI, University of Pittsburgh.Zorn R. L. (1999) The Right Architect for the Right Job. School of Planning & Management, available at http://www. spmmag.com/articles/1999_04_April/article195.html
Appendix: Questionnaire survey and allocation of weightsQuestionnaire surveyThe questionnaire was structured into two parts to obtain (I) background information about the respondents, and (II) weights of the evaluation criteria. Part I comprised  ve questions. The  rst two questions were designed to obtain general information about the nature and size of the respondent  rms. Question (3) was designed to identify the selection criteria considered by the respondents and questions (4) and (5) were used to collect comments on the selection systems used by the respondents. Part II comprised eight questions, relating to the respondents’ real, past or present, projects. Questions (1) and (2) in part II sought brief information on the selected projects, in terms of type and value. Questions (3–7) concern the relative importance of  ve criteria: ‘ rm’s background’, ‘past performance’, ‘capacity to accomplish the work’, ‘project approach’ and ‘consultant fee’, and their subcriteria. Question (8) was used to seek opportunities for further data collection.  Background information concerning the respondents comprised  ve areas: the nature and size of their organizations, the criteria used for the selection of architectural consultants, the degree of satisfaction with the selected architectural  rms and opinions on the selection systems used.Intensity of importanceDe nitionExplanation1Equal importanceTwo activities contribute equally to the objective3Moderate importanceExperience and judgement slightly favour one activity over another5Strong importanceExperience and judgement strongly favour one activity over another7Very strong or An activity is favoured very strongly over another;demonstrated importanceits dominance demonstrated in practice9Extreme importanceThe evidence favouring one activity over another is of the highest possible order of af rmation2, 4, 6, 8Intermediate valuesWhen a compromise is neededReciprocals ofIf activity i has one of the above nonzero numbers assigned to it when compared with activity j, then j has the reciprocal value when compared with iA reasonable assumptionRationalsRations arising from If consistency were to be forced by obtaining nthe scalenumerical values to span the matrix  Of the respondents, 94% were from the private sector, with only 4% from the public sector and 2% from the semi-public sector. The reason for the low Table A1 The fundamental scale as used by Satty (2000)response rate from these two latter sectors is that most of the development carried out by the public sector is handled by just two departments, the Hong Kong Housing Department and the Architectural Services Department (ASD).  Most (71.7%) of the respondents were from large  rms with 150 or more employees. Of these, 35 were from the private sector, two were from the public sector and one from the semi-public sector. Only 10 responses (18.9%) came from small  rms, and approximately 10% of the responses were received from medium-size  rms. This is to be expected, due to the Hong Kong property market being in recession since the end of 1997, resulting in only the larger developers being able to maintain their numbers of projects.  Of the  ve criteria, ‘ rm’s background’ was used by all respondents, and ‘consultant fee’ was the least important, being used by only 79.2% of respondents. Four additional criteria were suggested by the respondents: ‘previous working relationship with the client’, ‘innovative design’, ‘take ownership of the project’ and ‘which key staff to be assigned’.  Only two thirds of the respondents were satis ed with the performance of selected architects, with 15.1% sometimes satis ed and 13.2% never satis ed; 5.7% respondents made no comment.  Most (83%) respondents thought their own selection systems to be systematic.  Among the 53 sets of data, there were 22 sets (41.5%) relating to commercial buildings, with 15 (28.3%) and 14 (26.4%) sets related to residential buildings, and mixed residential and commercial buildings,Table A2 Pairwise comparison judgement matrix (PCJM) for  ve-point rating scaleO13579G1/31357A1/51/3135F1/71/51/313P1/91/71/51/31	O	G	A	F	Prespectively, and only two sets (3.8%) related to public facilities. Nearly half of the projects had a contract sum between HK$100 million and HK$500 million, which is quite large for Hong Kong. Two projects were below HK$100 million, with the remaining projects above HK$500 million. As mentioned above, most of the respondents were from large  rms, which explains the preponderance of larger projects.Allocation of weightsThe questionnaire survey responses were used to generate priority weights for the criteria and subcriteria. However, the priority weights of the rating scales in level 4 could not be covered by the questionnaire as the priority weights for the rating scale of each criterion can be different. For example, the relative value of an ‘outstanding’ versus a ‘good’ rating can be different for different criteria. Hence, a potential complication arises if the respondents are to be asked to compare the rating scales for all of the 12 subcriteria as this is very tedious and time consuming. Since making such  ne judgements would be both dif cult and impractical, one set of ‘local’ weights for the  ve-point rating scale was used. The priority weights of the rating scale were established by assuming the difference in relative importance between two adjacent scales with respect to a particular scale is a constant factor of 2.  The pairwise comparison judgements were made with respect to the attributes of one level of hierarchy given the attribute of the next higher level of hierarchy, from the main criteria to the subcriteria. The relative importance of criteria was determined by comparing it with the others using a nine-point scale, as shown in Table A1, which indicates the level of relative importance from equal, moderate, strong, very strong to extreme by 1, 3, 5, 7 and 9, respectively. The intermediate values between two adjacent arguments are represented by 2, 4, 6 and 8.  The pairwise comparison judgement matrix (PCJM) for the rating scales obtained this way is shown in Table A2. This matrix was translated into the largest eigenvalue problem and solved to obtain the normalized priority weights (using ExpertChoice™).  The normalized priority weights (local priority) of the elements in the matrix were then obtained by solving the pairwise comparison judgement matrices (PCJM) obtained from the questionnaire responses, producing a total of  ve sets of PCJMs. This involved three steps: (1) adding the values in each column; (2) dividing each value by its column sum to obtain the normalized matrix; and (3) averaging over the rows by adding the values in each row of the normalized matrix and dividing the rows by the number of entries to obtain the normalized priority weight. The normalized priority weights (local priority weight, LPW) of all the main criteria and subcriteria were next combined together with all successive hierarchical levels to obtain a global composite priority vector. The evaluation model was then built up with each of the critical selection criteria assigned with a global priority weight (GPW) obtained by multiplying the LPW of a particular subcriterion with the LPW of its parent criteria. For example, the LPW of the subcriterion ‘reputation’ is 0.093 and the GPW of its main criterion ‘ rm’s background’ is 0.054, so the GPW of ‘reputation’ is 0.054 3 0.093 = 0.005.  To eliminate the possible inconsistency revealed in the criteria weights, the values of the consistency ratio are determined to justify the judgement made by the respondents. Following Saaty (1980), those with a consistency ratio greater than 0.1 were rejected from the analysis. Thirty-six sets questionnaires had a consistency ratio of all PCJM below 0.1, and 17 sets had more than one consistency ratio of the PCJM greater than 0.1. Following Saaty (1980), those with a consistency ratio greater than 0.1 were rejected from the analysis. t-Tests were used to establish whether the weights of the evaluation criteria among the remaining 36 data sets were distributed with the same mean, and it was found that most of the sample weights for these 13 evaluation criteria in the 36 data sets were not distributed with the same mean. There are two possible explanations for this result. First, each set of data may have its own characteristics and be independent of others, so it cannot be viewed as a whole. The second possibility is that the data with similar weightings may analyse with other groups of data that have large differences between them. However, the  rst explanation is less likely because some of the data, such as ‘project type’ and ‘contract sum’, have the same characteristics as others, so there should exist some common pattern for assigning the priority weights.  The results of the survey were given in the section on general models.1 The input rating for ‘consultant fee’ is measured by the ratio of the actual amount of the lowest fee to the fee proposed by an architect------------------------------------------------------------------------------------------------------------------------------------------------------570	Cheung et al.Model for selection of architectural consultants	571