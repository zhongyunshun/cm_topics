See discussions, stats, and author profiles for this publication at: https://www.researchgate.net/publication/354600011
Characterizing Interview-Based Studies in Construction Management Research: Analysis of Empirical Literature Evidences
Conference Paper · August 2021

CITATIONS	READS
4	1,129
1 author:
Seng Hansen
President University, Bekasi
81 PUBLICATIONS   609 CITATIONS   
SEE PROFILE
All content following this page was uploaded by Seng Hansen on 15 September 2021.
The user has requested enhancement of the downloaded file.
    
 
CHARACTERIZING INTERVIEW-BASED STUDIES IN 
CONSTRUCTION MANAGEMENT RESEARCH: ANALYSIS OF EMPIRICAL LITERATURE EVIDENCES 
  
Seng Hansen1* 
 
1Construction Engineering and Management Program, Universitas Agung Podomoro, 
Jakarta  
 
*Corresponding author: seng.hansen@gmail.com 
 
 
Abstract. It has become more common in construction management research to use interview technique to gather qualitative data on practitioner opinions, attitudes, skills and best practices. This data is then analyzed using various qualitative analyses to produce findings and implications. However, one of the main problems raised in this study is the lack of standards and guidelines in conducting interview technique. Some of the issues are the lack of interview size justifications, the absence of criteria in selecting interviewees, and the lack of explanation regarding the analysis type conducted. These may cause weak interview data and lack of reliability of interview results. An empirical survey of 223 relevant papers was done to investigate this problem. This study reviews the gathered literature and presents descriptive statistics to characterize interview technique in construction management field. The discussions offer identification of interview characteristics in construction management research, explanation of factors influencing the data quality and saturation, and elucidation of factors influencing the analysis quality. Finally, a straightforward guideline to assist researchers in determining interview size in their studies is proposed.  
Keywords: Construction management research, Data saturation, Empirical review, Interviews. 
1.  INTRODUCTION  
    Interview technique has often been used as one of the data collection methods in construction management research. It is considered as a qualitative method since it is characterized by an in-depth and holistic observation of a unique phenomenon. In practice, it involves at least two people who are the interviewer and the interviewee (Hofisi, Hofisi & Mago, 2014). The data obtained tends to be qualitative rather than quantitative (Galvin, 2015).  
    The popularity of interview as a data collection technique has substantially increased in recent years. The main value of interview technique is the richness in detail of the collected data. Construction management research can benefit from using interview technique to obtain a more realistic view of the phenomenon under investigation that cannot be understood using numerical data. It is descriptive in nature which allows the researcher to describe existing phenomena and situations. However, there have been several criticisms given in previous studies. These criticisms are mainly related to the lack of standards and guidelines in interview technique, data collection and analysis are often cost and time consuming, highly dependent on the researcher’s ability to collect and analyze the data, lack of consistency and reliability, and ethical issues since it involves human subjects (Alshenqeeti, 2014; Bogner & Menz, 2009; Hofisi, Hofisi & Mago, 2014). 
    The lack of standards and guidelines is also related to determining sample size and expert justifications in interview technique. Generally, samples in qualitative research tend to be small in order to support the depth of case-oriented analysis. Additionally, interview samples are purposively selected by virtue of their capacity to provide relevant information (Vasilelou et al. 2018). Some researchers have tried to establish the recommended number of interviews. For instance, Guest, Bunce & Johnson (2006) recommend at least 12 interviews while Kwok & Lau (2018) and Yang & Shen (2015) suggest a range from 10 to 20 interviews. Therefore, it is quite problematic to determine the interview size prior data collection. On the other hand, analysis of interview data is very dependent on the skills of the researchers involved which may result in the inconsistent findings of similar studies (lack of reliability).  
    This paper aims to investigate these problems from a statistical point of view through a systematic analysis of empirical literature evidence. An extensive literature over a 20-year period from Journal of Construction Engineering and Management (JCEM) and Media Komunikasi Teknik Sipil (MKTS) was used as the scope of this study. JCEM was chosen because it is a top global journal in the construction management field which has been publishing empirical studies online since 1983. Meanwhile, MKTS was chosen as a comparison from Indonesia. There has been no previous study that empirically discusses interview technique of both publications. This study contributes for future construction management research considering the increased popularity of interview technique. 
 
2.  RESEARCH METHODS/METHODOLOGY 
    This paper adopts empirical literature study to gain insights from literature evidences. According to Bettis et al. (2014), empirical studies can be purely exploratory using graphical and statistical approaches. In this paper, a systematic literature review was used to analyze the empirical literature evidences focusing on identifying and characterizing interview technique in construction management research. Table 1 presents the systematic literature review strategies as prescribed by Chan & Owusu (2017) and Hansen, Rostiyanti & Rif’at (2020). 
Table 1. Systematic literature review strategies 
No Strategies 1 Targeting literature sources:  
JCEM and MKTS are used to represent international and national academic journal in the construction management field. Both are top referred journals and have frequently published online high-quality construction management papers since 1983 (JCEM) and 2003 (MKTS). In doing so, both journals use a transparent peer-reviewed procedure.  2 
 Searching for related literature: 
The search engine in JCEM was located and an advanced search was performed to narrow down the search so that only related articles will be retrieved. All papers containing the word “interview” related to the topic of “construction management” published within the last 20 years (from 2000 to July 23, 2019) were extracted from the JCEM virtual library. A total of 299 articles were retrieved. Similarly, the search engine in MKTS was used to find all papers containing the word “wawancara” or “interview”. Six articles were retrieved. 3 Selecting relevant publications: 
Once the related papers were available, a visual examination through reading the abstracts and skimming the contents was performed to identify relevant publications in this study. For that, the following selection criteria are used to include or exclude the retrieved articles: (1) interview technique is used as a method of data collection and/or validation, (2) interview technique which is referred to only as a reference (as in the literature review section) was excluded, (3) all types of data was included (i.e. studies that quantified their qualitative interview data was included), and (4) studies that did not provide the exact number of interview size was included as well. As the result, a total of 223 articles were selected for analysis. 4 
 Analyzing the content: 
Thematic content analysis was performed to analyze the content of selected publications. Some themes observed in this study include: year of publication, number of interviews, number of interviewees, interview type, interview format, interview technique, average interview duration, and research approach. After each article was analyzed and coded according to the theme, descriptive statistics are used to explain certain characteristics of interview technique. 5 Discussing and presenting the findings: 
As part of data presentation, figures and tables are used to illustrate the characteristics of interview technique. All findings and implications were discussed and presented in the ‘Results and Discussion’ section. 	3. 	RESULTS AND DISCUSSION  
     There are two types of findings in this study, namely descriptive and statistical. Descriptive findings describe qualitatively various issues related to interview technique as a method of data collection and/or validation. This includes some key descriptions of interview technique, data saturation statements, expert justifications, and other characteristics. Basic statistics are then used to illustrate relationships between the existing characteristics which at the same time strengthened the descriptive findings. The results are grouped and discussed in the following four subsections. 
 
3.1 Characteristics of the Interview Technique 
    The result of this study shows a positive trend in the use of interview technique in construction management research. This study reviewed the number of publications of JCEM for 20-year period which can be seen in Figure 1 (with dotted line indicating the increasing trend). On the other hand, the use of interview technique in MKTS has not been intensified over the years. There are only six articles that employed this technique. 

Figure 1. Number of studies over 20-year period 
    The number of interviews and interviewees can also be grouped to identify which groups are most often found in this study. Number of interviews and number of interviewees are distinguished because at the time of analysis, several situations were found where the number of interviews was not always the same as the number of interviewees. For example, Zhou, Fang & Mohamed (2011) interviewed four experts but in two groups. Kale (2009) interviewed three experts but in four series of interviews. Thus, it can be concluded that there are four types of interviews: 
(1) single interview. The interview is conducted in a one-to-one basis, meaning one interview reflects one interviewee. This is the most common type found in this study. 
(2) group interview. An interview is conducted with many interviewees at the same time. Examples can be found in Zhou, Fang & Mohamed (2011) and Chen & Fong (2013). 
(3) interview rounds. An interviewee can be involved in more than one interview. This usually happens when the involvement of an interviewee is needed more than once. An example of this type can be found in Shapira & Goldenberg (2007). 
(4) unclear number of interviews/interviewees. In this case, the number of interviews and/or interviewees are not clearly stated in the publication. Researchers only explain that they have conducted interviews with several experts as representatives of groups or populations. Examples can be found in Arriagada & Alarcón (2014) and Ozorhon & Oral (2017). 
    The groupings of number of studies to number of interviews is illustrated in Figure 2. From 217 JCEM papers, as many as 67 papers (30.9%) did not clearly provide number of interviews. It shows that the majority of researchers use small to medium interview size in their studies. While there is no agreement regarding the category of sample size in interview technique, this study considers number of interviews less than 10 as small size, between 10 to 20 as medium size, and above 20 as large size based on the distribution of number of studies to the interview range. 

Figure 2. The grouping of number of interviews 
    Basic descriptive statistics for JCEM papers are displayed in Table 2. It was found that the mean value of interview number is 28.1. The smallest sample of interviews in the studied papers was 1 and the largest was 860. Based on the analysis, small size interviews are commonly found in in-depth interviews while large size interviews are found in shallow interviews. Interestingly, the median of interview and interviewee numbers is 12. This corresponds to the opinion of Guest, Bunce & Johnson (2006) who concluded that data saturation was reached within the number of 12 interviews. Table 2. Descriptive statistics of JCEM papers 
Sample size of studies No. of interviews (n=150) Mean 28.1 SD 74.9 Min number 1 Max number 860 Median 12     This study also succeeded in identifying two purposes of conducting interview technique in JCEM: as primary method and as secondary method. Interview as primary method occurs when interview is used as the main approach in collecting data by researchers. Usually this can be easily identified if an interview procedure is provided in the ‘Methods’ section of the publication. Meanwhile, interview as secondary method occurs when it is not used as the main method of data collection but rather as a complementary method. There are two situations: (1) interview is used as an initial technique to assist researchers in survey design (e.g. Tabish & Jha, 2018), and (2) interview is used after the main technique as a way to validate the findings (e.g. Aljassmi & Han, 2013). It was found that the majority of studied papers (59.9%) used interviews as a secondary method. On the other hand, this study cannot provide descriptive statistics for MKTS papers due to lack of details available in the publications. 
 
3.2 Factors Influencing Data Quality and Data Saturation 
    Other characteristics can be grouped based on their similarities, i.e. as factors influencing data quality and data saturation. Both data quality and data saturation are very closely related. In fact, data saturation has become a central issue when conducting interview technique since it affects the quality of data produced. It is defined as ‘the point at which no new relevant information is forthcoming, even if more people are interviewed’ (Galvin, 2015). While this issue is crucial, most of the studied articles however did not provide justifications on how they achieved data saturation or whether they had reached it. Only few papers provided certain statements which may lead to the conclusion of them having reach data saturation (as shown in Table 3). 
Table 3. Papers containing data saturation statement 
References Quotes Orozco et al. (2014) “Given the similar answers of these individuals, no additional responses were necessary.” Dehghan & Ruwnapura (2014) “The interviews continued until no new information could be extracted and information saturation was reached.” Lim, Schultmann & Ofori (2010) “Therefore, samples may be small as long as “saturation” occurs: this is when no new information emerges that is important for the study.” Kim et al. (2019) “In particular, the research team performed expert interviews one-byone until information saturation was observed in the same manner as in previous interview-driven studies.”     The results of extensive empirical literature analysis provide several factors influencing the data saturation. In general, data saturation can be quickly reached in studies with a narrower scope than those with a broader research scope. For instance, a study on BIM education for CEM students (Sacks & Pikas, 2013) is narrower in scope than a project wanting to formulate fuzzy enterprise risk management maturity model for construction firms (Zhao, Hwang & Low, 2013).  
    On the other hand, interview size greatly affects data saturation. Therefore, it is important to justify the size of interviews in the study, especially considering that almost all research has limitations regarding time and cost to invest in data gathering. In general, the larger interview size conducted, the more data collected and can be coded which will improve the data quality. While it is important, most of the JCEM studied papers did not provide an interview size justification in their study (94.9%). The remaining provides three types of justifications as shown in Table 4. Similarly, all MKTS papers did not provide an interview size justification. 
Table 4. Interview size justifications in JCEM 
Type of justification Freq. % A % B Data saturation 4 1.8% 36.4% Rules of thumb 4 1.8% 36.4% Pragmatic reasons 3 1.4% 27.3% Unjustified studies 206 94.9% - Total 217 100% 100% %A: percentage from total number of studies,  
%B: percentage excluding unjustified studies 
    Achieving data saturation is one of the two most common interview size justifications besides the rule of thumb. Here, the researchers explained that their interviews were carried out until data saturation is reached. Examples of papers use data saturation as interview size justification include Deghan & Ruwnapura (2014), Orozco et al. (2014), and Kim et al. (2019). 
    On the other hand, rules of thumb have been commonly used for interview size justification. It is based on previous studies recommendations which reflected the achievement of data saturation from similar past research experience. For example, a recommendation range from 10 to 20 interviews given by Kwok & Lau (2018) and Yang & Shen (2015) has been followed by Bahadorestani, Karlsen & Farimani (2019), and recommendation exceeds 12 interviews as suggested by Guest, Bunce & Johnson (2006) has been followed by Nguyen (2019).  
    Three studies have used pragmatic reasons to justify their interview size. Menches & Hanna (2006) for example, argue that the interview size will largely depend on the available budget since they were conducting face-to-face interviews and cost was a significant factor in the sampling methodology. Guo et al. (2017) reason that interview size in their study was determined based on the consideration that any information provided by an interviewee must be supported or verified by another. Meanwhile, determination of interview size based on representation of interviewee for each of different population in the study was adopted by Raoufi & Fayek (2018).   
    The interview duration can also affect data quality and saturation. In general, the interview duration indicates the richness of data can be collected. It depends on many other factors such as the type of interview, the number of interview questions being asked, and the availability of interviewee’s time. It is generally expressed in terms of average duration (e.g. the average interview duration was approximately 1.5 h in Deghan & Ruwnapura’s 2014 study) or duration range (e.g. interviews lasted between 20 and 45 minutes in O’Connor & Mock’s 2019 study). Although it is important to describe the quality of the obtained data, not many researchers clearly state the interview duration in their papers. The analysis of this study showed that 88.5% of JCEM papers did not express the interview duration while the remaining 25 papers that expressed interview duration can be grouped into three categories: those with duration less than 1 hour (11 papers or 44%), duration between 1 to 2 hours (9 papers or 36%), and duration more than 2 hours (5 papers or 20%). On the other, all MKTS papers did not express the interview duration. 
    Interview format which can be grouped into three types (unstructured, semistructured, and structured interviews) also influences data quality and saturation. The difference between these three types lies in the flexibility of interviewers in asking questions (flexible/prompt) and the freedom of interviewees in giving responses. For instance, in the case of semi-structured interviews, the interviewer may have a list of interview questions but he can act promptly by asking probe questions adjusting the interviewee’s response. Likewise, interviewee can provide responses freely, on and around the topic area, which may allow new ideas and insights. In this study, it was found that as many as 65% of JCEM papers did not express their interview format while the remaining 76 papers can be divided into unstructured, semi-structured and structured interviews with 3.9%, 65.8% and 30.3% respectively. Thus, semi-structured interviews are the most common interview format in construction management research. 
    The diversity of interviewees may affect the data quality as well. It can be divided into two: homogenous and heterogenous. Homogenous means that the interviewees have similar characteristics whereas interviewees with dissimilar characteristics are grouped as heterogenous. In general, the more heterogenous the more diverse the given responses, meaning that achieving data saturation may take longer period. Similarly, the more homogenous the interviewee, the sooner data saturation will occur (Bonde, 2013). Figure 3 displays typical data saturation patterns from interviewees diversity perspective. In case of homogenous interviewees, the data saturation is reached earlier since the majority of information comes from initial interviews with less and less new information being revealed by later interviews. Meanwhile, in case of heterogenous interviewees, the wide diversity will provide more new insights and hence making the data saturation is reached later than homogenous interviewees. 

 
Figure 3. Data saturation pattern 
Interviewee type is one of the important factors that influence data quality and saturation. For instance, interview sampling is generally done purposively where interviewees are chosen because of their expertise. Thus, it is crucial to have expert justifications as criteria in selecting interviewees. This study has successfully identified eleven expert criteria as shown in Table 5. While providing expert justification is essential to ensure data quality, it was found that very few researchers (only 11 of JCEM papers) provided justifications in the selection of expert interviewees. Table 5. Expert justifications 
Expert criteria n % Practical experience 11 28.2% Educational background 5 12.8% Certification/accreditation 4 10.3% Other competencies/skills 3 7.7% Trainings and activities 2 5.1% Membership 1 2.6% Publications 1 2.6% Perceived knowledge 4 10.3% Position within organization 3 7.7% Ability to communicate knowledge 2 5.1% Practical considerations 3 7.7%     It appears that practical experience is the main criterion in justifying one’s expertise. This can be assessed from two aspects: how far the direct involvement of the interviewee on the research topic and how long the interviewee has related experience in the field. For instance, Zhang & El-Gohary (2016) mentioned that an expert must be experienced in the AEC (architectural, engineering and construction) domain, while Patel & Jha (2017) stated that an expert must have at least 10 years of professional experience in construction safety. This study found that majority of these eleven papers requires at least 10 years of practical experience.  
    Educational background relates to the required degrees in relevant fields. For instance, an expert must have a Master or a Ph.D. degree in the field of project management (Bahadorestani, Karlsen & Farimani, 2019). A person can also be called an expert if he already has a certificate of expertise or accredited in a particular field. For instance, an expert must be a practitioner who is accredited mediator/arbitrator of the recognized professional bodies (Chan, Suen & Chan, 2006). Other competencies relate to other personal skills required in the relevant studies, such as having awareness of knowledge modeling (Zhang & El-Gohary, 2016) or hold BIM-related roles within their organizations (Akintola, Venkatachalam & Root, 2017).  
    Some studies also required experts to have certain trainings or activities, such as at least 2 weeks of OHS related training, invited to present at a conference, etc. (Patel & Jha, 2017). Expertise can also be judged by the membership of the interviewees in a recognized professional body as well as the number of publications produced by the interviewees (Patel & Jha, 2017). Some studies may not require relevant educational background of interviewees as long as they have relevant knowledge. For instance, Chan, Suen & Chan (2006) considered experts are those who exhibit a good understanding of the alternative dispute resolution.  
    Most importantly, experts must be able to communicate their knowledge while voluntarily being interviewed (Brockman, 2014; Akintola, Venkatachalam & Root, 2017). Thus, the quality of interview data obtained also depends on enthusiasm and willingness of interviewees to share their knowledge and opinions. Some studies may require experts to be those with certain job positions within their organizations (Le et al. 2014; Akintola, Venkatachalam & Root, 2017). This is closely related to interviewees’ roles which makes it easy for them to access certain information needed for the research. Meanwhile, practical considerations may include a selection of interviewees which considers the diversity of expertise and geographical location of the experts (Le et al. 2014).  
    Judging from the readiness of the researchers/interviewers, data quality and saturation depend on the researcher’s skills and expertise when conducting interviews. 
This includes having adequate knowledge and technical background on the research topic, readiness in conducting interviews (such as having interview protocol, listing appropriate interview questions, etc.) as well as the quality of interview dialogue (whether interview dialogue runs smoothly/not and strong/weak). In short, the more experienced researchers are with the subject of investigation, the fewer interviews are required to reach data saturation. In addition, research limitations such as time and budget allowance to conduct the studies can also affect the number of interviews that can be conducted which ultimately influences the achievement of data saturation. Finally, external factors such as requirements by the research funding board and interventions by supervisors may also influence the quality of data and achievement of data saturation. 
 
3.3 Factors Influencing Analysis Quality 
    Another important aspect to consider when using interview technique is the quality of interview analysis. As a technique in qualitative research, interview data analysis tends to be subjective and relies heavily on the expertise of the researchers conducting the analysis. Here, the more expert a researcher, the better the analysis quality produced. If the researchers are familiar with the subject of the phenomena under study or have had previous similar studies experience, it is easier for them to carry out comprehensive qualitative analysis and reached data saturation.  
    The data type also influence the analysis quality conducted. While interview is a qualitative technique, the obtained data can be analyzed and produced quantitative findings. In this study, it should be noted that some of the studied papers have provided interview results combining both qualitative and quantitative findings. These quantitative findings may be measurement of codes frequency or descriptive statistics of particular issues (e.g. interviewees’ profiles as in Yang et al. 2010 and Zhao et al. 2015).  
    Furthermore, analysis quality can also be influenced by the type of analysis conducted. There are three types of qualitative analysis commonly used: content analysis, coding analysis and discourse analysis. Content analysis is a technique for making replicable and valid inferences to the contexts of their use (Krippendorff, 2012). It enables a systematic process to examine the content of interview transcripts. Qualitative data is reduced to concepts describing the research phenomena by creating categories, conceptual systems, or conceptual maps (Elo et al. 2014). Examples of the studied papers that use content analysis are Taylor (2007) and Zhao, Hwang & Low (2014).  
    Similar to it, coding analysis also known as thematic coding analysis is a commonly data analysis approach which emphasizes the codification aspect of the data to find explicit and implicit patterns and relationships of the studied phenomena. Examples of the studied papers using coding analysis are Blacud et al. (2009) and Jeelani, Albert & Gambatese (2017). Meanwhile, discourse analysis involves detailed investigation of statements and arguments that are regularly uttered by interviewees. None of the studied papers used this type of analysis. 
    Furthermore, the analysis quality is also determined by the ability of its results to be triangulated with other findings. This is commonly found in mixed method studies. For instance, Tabish & Jha (2018) used face-to-face interviews as an initial method to develop questionnaire. The results of interviews were used to modify the questionnaire before it was distributed to the main respondents. Similarly, Tao et al. (2017) used interviews to solicit the experts’ opinions before focus groups and questionnaire surveys were conducted.   
    Currently, there are many qualitative analysis software available to support interview data analysis such as NVIVO, MAXQDA, ATLAS.ti, etc. These software helps researchers to process interview transcripts by providing a wide range of features to conduct content analysis, discourse analysis or coding analysis. However, only few of the studied papers have expressed the use of these support tools in their studies. These includes Lee et al. (2011), Brockman (2014), Chan et al. (2016), and Jeelani, Albert & Gambatese (2017) who used various versions of NVIVO software package.  
    Both factors influencing data quality and saturation as well as factors influencing analysis quality will ultimately affect the reliability of interview results. Therefore, it is crucial for researchers who use interview technique as a qualitative method to understand the factors above. 
 
3.4 A Structured Guideline in Determining Interview Size 
    In this study, the author develops a structured guideline in determining interview size. Interview size determination is still a major and challenging issue in construction management research. Therefore, based on the characteristics and factors that have been identified above, this study proposes a structured matrix as shown in Table 6. It divides interviews based on their sizes into small, medium and large interviews. There are eight key qualifiers as benchmarks in determining the recommended interview size. Researchers can use this matrix to determine the recommended interview size based on the dominant group of identified key qualifiers. 
Table 6. Interview size guideline 
Key Qualifiers Size Small Medium Large Number of interviews less than 10 10 ≤ x < 20 more than 20 Research scope recommended for narrow/focus research scope in between recommended for broad/complex research scope Research limitations research 
resources are 
constrained by time, cost and other factors research may be 
limited by one factor no limitation Interview format recommended for unstructured and semi-structured interview formats recommended for unstructured and semi-structured interview formats recommended for semi-structured and structured interview formats Diversity of interviewees likely for 
homogenous 
target interviewees in between likely for 
heterogenous target interviewees Interviewee’s expertise target interviewees 
possess high level of expertise in between target interviewees 
possess low level of expertise Researcher’s expertise more experienced researchers 
require fewer interviews in between less experienced researchers 
require more interviews Research characteristics the phenomenon 
under investigation is unique in between the phenomenon 
under investigation 
is comparable to others     An illustration to use the above matrix is provided as follows. A Ph.D. student raises the topic of construction project risk assessment from various perspectives (in between narrow and broad research scope) as his dissertation. He plans to interview several professionals from contractors, owners, and consultants (heterogenous and experts). He decides to conduct semi-structured and face-to-face interviews (cost becomes a significant factor in the data collection process). Considering these conditions, a medium size interview is recommended.  
    Another example of the compatibility of this matrix with previous research can be found in Vaughan et al. (2013) study. They investigated the cost-benefit analysis of construction information management system implementation (narrow) from data collected over a 6-month period (limited). The target interviewees were members of a project team (homogenous) with average experience of 13.8 years (high level of expertise). The study is unique by developing a framework to assess costs and benefits of innovative construction information management system. Thus, they have employed five expert interviewees which is considered as a small interview size.  
    Finally, the author realizes that determining the sample size in interview technique will depend on many factors other than those identified as key qualifiers above. Interview as one of data collection technique is investigative and explorative towards a phenomenon so that the reliability of the results is very dependent on the quality of the data collected and the analysis conducted. 
 
CONCLUSION  
    This empirical literature study focused on publications that used interview technique as part of their data collection and/or validation method. A total of 223 papers published since 2000 was used as sample in this study. Through a comprehensive analysis, the characteristics of interview technique was evaluated. Results show that the use of interview technique in construction management research globally has increased substantially over the past two decades. Meanwhile, its use in Indonesian context must still be promoted. 
    In summary, this study recommended future studies using interview technique to consider the following: (1) provide clear expert justifications, including the required practical experience, educational background, certifications, and other competencies, (2) provide clear interview size justifications, (3) provide interview purpose, type, format, duration, and limitations (if any), (4) provide the profiles of interviewees, (5) provide the type of analysis conducted and support tools used for the analysis (if any), and (6) provide a summary of interview key responses and results. 
    This study has three main contributions. Firstly, through an empirical literature study it presents the key characteristics of interview technique as found in JCEM & MKTS publications. The identification of these characteristics is crucial to better understand the nature of interview technique in construction management field. Secondly, it has identified several factors influencing data quality and saturation as well as analysis quality. Understanding these factors is crucial to produce reliable interview results. Lastly, this study presents a structured guideline in determining interview size. This structured guideline is derived from an assessment of 223 papers and can be used to assist further research using interview technique as part of their data collection and/or validation. 
 
REFERENCES 
Akintola, A., Venkatachalam, S., & Root, D. (2017). “New BIM roles’ legitimacy and changing power dynamics on BIM-enabled projects.” Journal of Construction Engineering and Management, 143(9), 04017066. 
Aljassmi, H., & Han, S. (2013). “Analysis of causes of construction defects using fault trees and risk importance measures.” Journal of Construction Engineering and Management, 139(7), 870-880. 
Alshenqeeti, H. (2014). “Interviewing as a data collection method: a critical review.” English Linguistics Research, 3(1), 39-45. 
Arriagada, R. E., & Alarcón, L. F. (2014). “Knowledge management and maturation model in construction companies.” Journal of Construction Engineering and Management, 140(4), B4013006. 
Bahadorestani, A., Karlsen, J. T., & Farimani, N. M. (2019). “A comprehensive stakeholdertypology model based on salience attributes in construction projects.” Journal of Construction Engineering and Management, 145(9), 04019048. 
Bettis, R., Gambardella, A., Helfat, C., & Mitchell, W. (2014). “Quantitative empirical analysis in strategic management.” Strategic Management Journal, 35, 949-953.  
Blacud, N. A., Bogus, S. M., Diekmann, J. E., & Molenaar, K. R. (2009). “Sensitivity of construction activities under design uncertainty.” Journal of Construction Engineering and Management, 135(3), 199-206. 
Bogner, A., & Menz, W. (2009). “The theory-generating expert interview: epistemological interest, forms of knowledge, interaction.” In: Bogner, A., Litlig, B., & Menz, W. (editors). Interviewing experts. Plagrave Macmillan, New York. 
Bonde, D. (2013). Qualitative interviews: when enough is enough. Research by Design, Australia. (online) available at: www.researchbydesign.com.au (accessed 30.03.20). Brockman, J. L. (2014). “Interpersonal conflict in construction: cost, cause, and consequence.” Journal of Construction Engineering and Management, 140(2), 04013050. 
Chan, A. P. C., Javed, A. A., Lyu, S., Hon, C. K. H., & Wong, F. K. W. (2016). “Strategies for improving safety and health of ethnic minority construction workers.” Journal of Construction Engineering and Management, 142(9), 05016007. 
Chan, A. P. C., & Owusu, E. K. (2017). “Corruption forms in the construction industry: literature review.” Journal of Construction Engineering and Management, 143(8), 04017057. 
Chan, E. H. W., Suen, H. C. H., & Chan, C. K. L. (2006). “MAUT-based dispute resolution selection model prototype for international construction projects.” Journal of Construction Engineering 
and Management, 132(5), 444-451. 
Chen, L., & Fong, P. S. W. (2013). “Visualizing evolution of knowledge management capability in construction firms.” Journal of Construction Engineering and Management, 139(7), 839-851. 
Dehghan, R., & Ruwnapura, J. Y. (2014). “Model of trade-off between overlapping and rework of design activities.” Journal of Construction Engineering and Management, 140(2), 04013043. 
Elo, S., Kääriäinen, M., Kanste, O., Pölkki, T., Ultriainen, K., & Kyngäs, H. (2014). “Qualitative content analysis: a focus on trustworthiness.” SAGE Open, January-March 2014, 1-10. 
Galvin, R. (2015). “How many interviews are enough? Do qualitative interviews in building energy consumption research produce reliable knowledge?” Journal of Building Engineering, 1, 212. 
Guest, G., Bunce, A., & Johnson, L. (2006). “How many interviews are enough? An experiment with data saturation and variability.” Field Methods, 18(1), 59-82.  
Guo, B. H. W., Yiu, T. W., González, V. A., & Goh, Y. M. (2017). “Using a pressure-state-practice model to develop safety leading indicators for construction projects.” Journal of Construction Engineering and Management, 143(2), 04016092. 
Hansen, S., Rostiyanti, S. F., & Rif’at, A. (2020). “Causes, effects, and mitigations framework of contract change orders: lessons learned from GBK Aquatic Stadium Project.” Journal of Legal Affairs and Dispute Resolution in Engineering and Construction, 12(1), 05019008. 
Hofisi, C., Hofisi, M., & Mago, S. (2014). “Critiquing interviewing as a data collection method.” Mediterranean Journal of Social Sciences, 5(16), 60-64. 
Jeelani, I., Albert, A., & Gambatese, J. A. (2017). “Why do construction hazards remain unrecognized at the work interface?” Journal of Construction Engineering and Management, 143(5), 04016128. 
Jung, W., Han, S. H., Park, H., & Kim, D. Y. (2010). “Empirical assessment of internationalization strategies for small and medium construction companies.” Journal of Construction Engineering and Management, 136(12), 1306-1316. 
Kale, S. (2009). “Fuzzy intellectual capital index for construction firms.” Journal of Construction Engineering and Management, 135(6), 508-517. 
Kim, J., Ham, Y., Chung, Y., & Chi, S. (2019). “Systematic camera placement framework for operation-level visual monitoring on construction jobsites.” Journal of Construction Engineering and Management, 145(4), 04019019. 
Krippendorff, K. (2012). Content analysis: an introduction to its methodology (3rd edition). SAGE, Beverly Hills. 
Kwok, P. K., & Lau, H. Y. (2018). “A modified consensus-building methodology for reaching a group decision using minimum costs.” IEEE Access, 6, 3509-3523. 
Le, Y., Shan, M., Chan, A. P. C., & Hu, Y. (2014). “Investigating the causal relationships between causes of and vulnerabilities to corruption in the Chinese public construction sector.” Journal of Construction Engineering and Management, 140(9), 05014007. 
Lee, S. H., Jeon, R. K., Kim, J. H., & Kim, J. J. (2011). “Strategies for developing countries to expand their shares in the global construction market: phase-based SWOT and AAA analyses of Korea.” Journal of Construction Engineering and Management, 137(6), 460-470. Lim, J. N., Schultmann, F., & Ofori, G. (2010). “Tailoring competitive advantages derived from innovation to the needs of construction firms.” Journal of Construction Engineering and Management, 136(5), 568-580. 
Menches, C. L., & Hanna, A. S. (2006). “Conceptual planning process for electrical construction.” Journal of Construction Engineering and Management, 132(12), 1306-1313. 
Namian, M., Albert, A., Zuluaga, C. M., & Jaselskis, E. J. (2016). “Improving hazard-recognition performance and safety training outcomes: integrating strategies for training transfer.” Journal of Construction Engineering and Management, 142(10), 04016048. 
Nguyen, L. H. (2019). “Relationships between critical factors related to team behaviors and client satisfaction in construction project organizations.” Journal of Construction Engineering and Management, 145(3), 04019002. O’Connor, J. T., & Mock, B. D. (2019). “Construction, commissioning, and startup execution: 
problematic activities on capital projects.” Journal of Construction Engineering and Management, 145(4), 04019009. 
Orozco, F. A., Serpell, A. F., Molenaar, K. R., & Forcael, E. (2014). “Modeling competitiveness factors and indexes for construction companies: findings of Chile.” Journal of Construction Engineering and Management, 140(4), B4013002. 
Ozorhon, B., & Oral, K. (2017). “Drivers of innovation in construction projects.” Journal of Construction Engineering and Management, 143(4), 04016118. 
Patel, D. A., & Jha, K. N. (2017). “Developing a process to evaluate construction project safety hazard index using the possibility approach in India.” Journal of Construction Engineering and Management, 143(1), 04016081. 
Pellicer, E., Yepes, V., Correa, C. L., & Alarcón, L. F. (2014). “Model for systematic innovation in construction companies.” Journal of Construction Engineering and Management, 140(4), B4014001. 
Raoufi, M., & Fayek, A. R. (2018). “Framework for identification of factors affecting construction crew motivation and performance.” Journal of Construction Engineering and Management, 144(9), 04018080. 
Sacks, R., & Pikas, E. (2013). “Building information modeling education for construction engineering and management. I: Industry requirements, state of the art, and gap analysis.” Journal of Construction Engineering and Management, 139(11), 04013016. 
Shapira, A., & Goldenberg, M. (2007). “Soft considerations in equipment selection for building construction projects.” Journal of Construction Engineering and Management, 133(10), 749760. 
Tabish, S. Z. S., & Jha, K. N. (2018). “Beyond the iron triangle in public construction projects.” Journal of Construction Engineering and Management, 144(8), 04018067. 
Tao, L., Wu, C., Chiang, Y. H., Wong, F. K. W., & Liang, S. (2017). “Generational perceptions of freedom-related work values: Hong Kong’s implementation of a no-Saturday-site-work policy in construction.” Journal of Construction Engineering and Management, 143(7), 06017002. 
Taylor, J. E. (2007). “Antecedents of successful three-dimensional computer-aided design implementation in design and construction networks.” Journal of Construction Engineering and Management, 133(12), 993-1002. 
Vasileiou, K., Barnett, J., Thorpe, S., & Young, T. (2018). “Characterising and justifying sample size sufficiency in interview-based studies: systematic analysis of qualitative health research over a 15-year period.” BMC Medical Research Methodology, 18(148), 1-18. 
Vaughan, J. L., Leming, M. L., Liu, M., & Jaselskis, E. (2013). “Cost-benefit analysis of construction information management system implementation: case study.” Journal of Construction Engineering and Management, 139(4), 445-455. 
Yang, J., Shen, G. Q., Drew, D. S., & Ho, M. (2010). “Critical success factors for stakeholder management: construction practitioners’ perspectives.” Journal of Construction Engineering and Management, 136(7), 778-786. 
Yang, R. J., & Shen, G. Q. (2015). “Framework for stakeholder management in construction projects.” Journal of Management in Engineering, 31(4), 04014064. 
Zhang, L., & El-Gohary, N. M. (2016). “Epistemology-based context-aware semantic model for sustainable construction practices.” Journal of Construction Engineering and Management, 142(3), 04015084. 
Zhao, X., Hwang, B. G., & Low, S. P. (2013). “Developing fuzzy enterprise risk management maturity model for construction firms.” Journal of Construction Engineering and Management, 139(9), 1179-1189. 
Zhao, X., Hwang, B. G., & Low, S. P. (2014). “Investigating enterprise risk management maturity in construction firms.” Journal of Construction Engineering and Management, 140(8), 05014006.  
Zhao, X., Hwang, B. G., Low, S. P., & Wu, P. (2015). “Reducing hindrances to enterprise risk management implementation in construction firms.” Journal of Construction Engineering and Management, 141(3), 04014083. 
Zhou, Q., Fang, D., & Mohamed, S. (2011). “Safety climate improvement: case study in a Chinese construction company.” Journal of Construction Engineering and Management, 137(1), 8695. 
 
 
View publication stats

    

    

    
The 2nd International Conference on Inovations in Social Sciences Education and Engineering ( ICoISSEE ) August 07th, 2021 
    
The 2nd International Conference on Inovations in Social Sciences Education and Engineering ( ICoISSEE ) August 07th, 2021 
    
The 2nd International Conference on Inovations in Social Sciences Education and Engineering ( ICoISSEE ) August 07th, 2021 
    
