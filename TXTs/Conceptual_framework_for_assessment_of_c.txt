Construction Management and Economics (January 2006) 24, 31–44Conceptual framework for assessment of client needs and satisfaction in the building development processJASPER MBACHU and RAYMOND NKADO*Faculty of Engineering and the Built Environment, University of the Witwatersrand, Wits, South AfricaReceived 15 April 2004; accepted 17 January 2005A conceptual framework is developed for assessment of client needs, and the measurement and monitoring of client satisfaction levels in the building development process. Data were obtained from qualitative and quantitative surveys of a target population of clients of commercial buildings in South Africa. Satisfaction levels based on multi-attribute measures were compared with those based on single evaluative responses, using Wilcoxon’s matched-pair test. Results showed no significant differences in pairwise comparisons. A strong positive correlation also existed between both equivalent measures of client satisfaction levels. These results validate the conceptual framework. Results of evaluation of client satisfaction levels showed that clients perceived average levels of satisfaction in the building development process. Areas for improvement in the services of contractors and consultants were identified through ‘Criticality Index’ analyses. Empirical models were developed for proactive measurements of client satisfaction levels at distinct stages of the development process. A dynamic approach to satisfaction measurement is recommended. This contrasts with post-purchase and static views adopted in the consumer services segment and enables consultants to monitor and improve satisfaction levels proactively, as the development process evolves.Keywords: Building development, criticality index, needs assessment, performance measurement, satisfaction measurementIntroductionThe concept of customer satisfaction is largely developed in the production sector and consumer services markets, and is regarded as the raison d’eˆtre for companies’ existence and operations (Taylor and Baker, 1994). The provision of service or production of a product offered for sale should be aimed at satisfying identified needs of the targeted customers (Rust and Zahorik, 1993). This is because client satisfaction adds value to the organization from a number of perspectives: creation of sustainable client loyalty to the firm (Preece, 2000), repeat purchase, acceptance of other products/services offered by the service firm, increased market share and profitability levels (Surprenant, 1977), creation of positive word-ofmouth (Churchill and Surprenant, 1977) and a measure of market performance (Handy, 1977). Satisfaction is also important to the client because itreflects a positive outcome from the outlay of scarce resources and/or fulfilment of unmet needs (Day and Landon, 1977; Landon, 1977). On the other hand, consumer dissatisfaction leads to undesirable consequences such as: negative word-of-mouth, complaints, redress seeking, reduction of market share and profitability levels (Day, 1977; Oliver, 1981; Woodruff et al., 1983) and possible divestment from the industry (Kotler, 1997).  The foregoing suggest that a study of client needs and satisfaction is crucial, as current and future prospects in the construction industry depend on the extent to which clients are satisfied with their investments in the procurement process. It is therefore disheartening to read about the rising spate of client dissatisfaction in the industry. Although dated, the NEDO (1974) reports that UK clients were dissatisfied with their buildings. More recently, Bowen et al. (1997) posit that, ‘the construction industry potentially has a higher proportion of dissatisfied and critical clients than*Author for correspondence. E-mail: nkador@ebe.wits.ac.zaany other industry’ (p.1). This agrees with an earlierConstruction Management and EconomicsISSN 0144-6193 print/ISSN 1466-433X online # 2006 Taylor & Francis http://www.tandf.co.uk/journalsDOI: 10.1080/01446190500126866
observation by Kometa et al. (1994), that ‘evidence abounds to suggest that clients are largely misunderstood and dissatisfied with the performance of their consultants and contractors’ (p.433).  Previous studies have identified several factors responsible for client dissatisfaction in the construction industry. For instance, Nkado and Mbachu (2001), while documenting causes of client dissatisfaction in the procurement process note, among other factors, the issue of dissonance between objective reality and client’s perceptions of it, adding, as a lesson for professionals, that client satisfaction/dissatisfaction is a subjective phenomenon, which may not be based on objective reality (e.g. delivery of the project within time, cost and quality targets), but on client’s perceptions of the objective reality. These perceptions are influenced by several subjective dimensions, which could cause significant dissonance between what clients perceive of the target being observed (e.g. project team performance) and the reality about the observed target (e.g. meeting project schedule). Dissatisfaction could result when the project team focuses on objective reality rather than seeing things from clients’ perspectives.  Another factor responsible for client dissatisfaction in the construction industry is the possibility of clients’ stated requirements not sufficiently addressing their real (latent) needs. Owing to insufficient time for in-depth viability appraisal, clients usually adopt irrational approaches in making decisions concerning optimal solutions to their real needs. This results in divergence between clients’ stated and real needs in the procurement process. On the basis of this, Goodacre et al. (1982) argue that listening to, and acting only upon, client’s stated needs may not yield the desired benefits. That this has been the case in the construction industry could be responsible for the reported cases of client dissatisfaction.  Furthermore, the prevalence of client dissatisfaction in the global construction industry has been attributed to inadequate research into client needs and satisfaction. For instance, Liu and Walker (1998) submit that not much effort has been made to identify the needs of clients, which is crucial to ensuring client satisfaction. Green and Lenard (1999) corroborate this by noting that, as a recurring problem throughout the global construction industry, the industry has invested little time and attention in investigating the needs of its clients compared to other economic sectors.  Perhaps the construction industry’s service providers have been unable to fully grasp the issue of client satisfaction largely because of the absence or unawareness of a mechanism for measuring satisfaction in the procurement process. This could be inferred from Bowen’s (1993) findings that ‘little published literature exists on the appropriate mechanisms for assessing client satisfaction’ (p.60).  These developments indicate that further research is needed in the area of client needs and satisfaction within the construction industry. The concepts of assessment of customer needs and satisfaction are fully developed and operational in the production and consumer services sectors, and could be adapted and applied to the construction industry to improve client satisfaction levels. This study could contribute to filling the gap by providing the mechanism for client needs assessment and satisfaction measurement in the development process.  The objective of this paper is to develop a conceptual framework for a dynamic assessment of client needs and satisfaction based on prioritized expectations of clients from the services of consultants and contractors in the development process.Clients’ needs assessmentClients’ needs and requirements in the development process could be categorized broadly into design (architectural and engineering), management (construction project and cost) and construction services, in line with Bennett’s (1985) four major areas of responsibility in construction project development. A framework for client needs assessment in the development process as proposed in this study focuses on the identification and prioritization of client expectations from design, management and construction services from the perspectives of clients. This is illustrated in Figure1.  The above conceptual framework underpinned the research design for this study, whereby investigations were undertaken to determine constructs underlying each of the above five dimensions during the exploratory surveys, while the quantitative surveys were aimed at prioritizing the identified constructs from clients’ perspectives.Measurement of satisfactionKotler (1997) defines satisfaction as ‘a person’s feeling of pleasure or disappointment resulting from comparing a product’s perceived performance or outcome in relation to his or her expectations’ (p.40).Figure 1	Conceptual framework for client needs assessment in the development process (Source: Mbachu, 2003)  Many researchers consider satisfaction as an overall summary measure, while others feel that satisfaction is measured best by a combination of facets or attributes. For instance, Day (1977) sees no difficulty in measuring an individual’s satisfaction or dissatisfaction with the overall outcome. Also, Czepiel and Rosenberg (1977) agree that consumer satisfaction can be thought of as a single overall evaluative response that represents a summary of subjective responses to many different facets. Handy and Ptaff (1975), however, disagree with overall satisfaction measurement, arguing that response to an overall satisfaction measure only crudely measures overall satisfaction. Zikmund (1994) corroborates Handy and Ptaff’s (1975) views by contending that measures of cognitive phenomena (such as satisfaction) are often composite indexes of a set of variables.  This research draws on the views of Handy and Ptaff (1975) and Zikmund (1994) on the appropriate approach to the measurement of satisfaction. This involves the combination of facets or attributes, the measurement of which would give the overall satisfaction level. However, measurement of satisfaction on the basis of a single observation was also explored to provide an alternative index measure for comparative analyses. Assuming that both multi-attribute and single evaluative measures of client satisfaction are valid, the alternative index measure serves to assess the internal consistency (Zikmund, 1994) of the findings and methodological approach adopted in this study.Theoretical satisfaction modelsTwo models for satisfaction measurement adopted in the study are highlighted below.Model 1: Satisfaction level based on single evaluative (overview) responses (So)This is based on Czepiel and Rosenberg’s (1977) summary view of satisfaction measurement. It is computed as the analysed performance index (PI) value of clients’ overview ratings of a professional group’s performance, without considering performances in each identified need or requirement in the group’s service. It is used as an alternative index measure for comparing satisfaction scores with a view to assessing the internal consistency (Zikmund, 1994) of the developed conceptual framework as proposed in this study. The analysis of satisfaction score (So) from clients’ ratings of performance is shown in equation1.4	So~XðPi|Ri%Þ	ð1Þi~1where: Pi5rating point i (1,i,4); Ri%5percentage response to rating point, i.Model 2: Satisfaction level based on multi-attribute measures (ST)This is based on Handy and Ptaff’s (1975) view of composite index measure of satisfaction. It is calculated as the sum of satisfaction scores (Ss) in a given subset. It gives an indication of the level of satisfaction derived by clients from the services of a particular professional group on the basis of perceived levels of importance of a set of needs or requirements, and the professional group’s performance in meeting the needs.  The proposed theoretical model for the multiattribute estimation of the level of client satisfaction (SO) in the development process is of the generic form:SO~SQzSAzSEzSMzSCor	Mq	Ma	MeSO~AX aiSqizB X biSaizC X ciSeii~1	i~1	i~1 ð2Þ	Mm	MczD XdiSmizE X eiSci	i~1	i~1Where: SQ5level of satisfaction with quantity surveying services, comprising satisfaction (Sqi) with a number of attributes (ranging from 1 to M) perceived by the client to be relevant in line with his or her priorities. SA, SE, SM, SC represent levels of satisfaction with architectural, consulting engineering, management and construction services, respectively. A, B, C, D and E are the relative weights assigned to the respective services in accordance with client’s perceived levels of importance attached to the service components in the satisfaction continuum.  The aim of the qualitative surveys was to explore the variables underlying the subcomponents of equation2. The aim of the quantitative surveys was to obtain data, the analysis of which could yield the relative weights or constants in each model subcomponent of equation2.MethodologyThe descriptive survey method was adopted in the study as the technique of observation was employed in the gathering of data through the benefit of questionnaires (Leedy and Ormrod, 2001). The respondent target population comprised commercial property clients in South Africa who are registered members of the eminent South African Property OwnersAssociation (SAPOA), and operate as property developers, investors or owner-occupiers.  The data gathering process involved semistructured pilot interviews conducted with 15 directors of client organizations within the target population in Port Elizabeth and Johannesburg – two of the major cities in South Africa. The constructs generated at this qualitative survey stage were used in designing a questionnaire, which was pretested and administered nationwide to the SAPOA members who did not participate in the interviews and pre-tests. The surveys were conducted between October 2001 and November 2002. However, no time limitation was placed on the experiences of respondents.Methods of data analysisMulti-attribute methods (Zikmund, 1994; Cooper and Emory, 1995) were employed in the preliminary analyses of data to establish the mean ratings and ranks of the variables in a given subset. The research hypothesis was tested using Wilcoxon’s matched-pairs and Spearman’s rank correlation tests. The choice of these techniques was based on the recommendations of Cooper and Emory (1995), given that the test situation involves ordinal measurement scale and two-sample or bivariate analyses. The multiattribute analyses as used in this study was based on the multi-attribute utility approach of Chang and Ive (2002), and involved the estimation of the following parameters.  Mean rating (M): this was computed as the sum of the product of each rating point (P) and the corresponding percentage response to it (R%), out of the total number of responses (T) involved in the rating of the particular variable, i.e.5	M~XðPi|Ri%Þ	ð3Þi~1where: Pi5rating point i (1,i,5); Ri%5percentage response to rating point, i. The mean rating could be the importance index (II), the performance index (PI) or satisfaction index (SI). It seeks to evaluate respondents’ collective rating of a variable on the rating scale used.  Relativity index (RI): this was used to compare the M values of the variables in a given subset. It was computed as a unit of the sum of M’s in a subset of variables (equation4).	RIi~ NMi	ð4ÞPMii~1The relativity index could stand for the relative weight (Rw) or the relative importance index (RII) of a given attribute in a subset.  The satisfaction score (Ss): this represents the relative contribution of each subcomponent to the level of satisfaction derived from a major subcomponent of overall satisfaction. It was computed as the product of two parameters: the relative weight (Rw) of the subcomponent established in the development of multi-attribute model, and the satisfaction index (Si) of the subcomponent computed as the sum of products of rating points and their corresponding percentage responses (R%), i.e.:	Ss~RwSi	ð5ÞThe total satisfaction level (ST) derived from each major component, is therefore the sum of satisfaction scores (Ss) for all the subcomponents or attributes involved; i.e.:N	ST~X Ssi	ð6Þi~1where N5number of subcomponents underlying the major component of overall client satisfaction in question.Criticality index (CI)To prioritize identified areas for improvement, the CI concept was used. The development of the concept draws from the understanding that the extent of the need for improvement in a given attribute of professional service is dependent upon the level of importance attached to it by clients, and the perceived level of satisfaction currently delivered by the professional group concerned (Nkado and Mbachu, 2002). Thus the criticality for improvement increases with the level of importance (as indicated by the importance index) and decreases with the satisfaction level currently delivered (as reflected by the performance index). This means that the need for improvement in a highpriority service attribute would not be critical if the professionals concerned are already delivering high levels of satisfaction. However, the reverse is the case if satisfaction level is perceived to be low. Consequently the CI is computed as:II	CI~	ð7ÞPIwhere: CI5criticality index; II5importance index; PI5performance index.Data and resultsSurvey responsesThe target population of clients was administered 223 copies of the questionnaire; 75 were returned, of which 64 were found usable. This implied a low 29% effective response rate.  Analyses of respondents’ demographic profiles showed that 34.4% were investors/developers, 18.8% were investors/owner-occupiers, while owner-occupiers comprised 7.8%. Developers (7.6%), investors (6.9%) and those who were equally exposed to property development, investment and owner-occupation (24.5%) constituted the rest of the client groupings. The views of the combined client groupings were predominantly those who engaged in both property development and investment.  In terms of organizational status, 53% of the clients were managing directors of their various organizations, and therefore made high-level inputs to the study. Other respondents occupied managerial (23%) and director/senior executive (17%) positions. The survey responses were from key decision makers who evaluate outcomes of the procurement process. This status of the respondents is expected to enhance the reliability and validity of the conclusions emanating from the findings of the study, though the reliability and validity of the findings were additionally verified through internal validation of the developed research models.Re-scaling the Likert points from ordinal to interval scaleBefore interval level analyses of the Likert scale data were carried out, the ordinal scale in which the responses were captured were converted into interval scale to achieve more meaningful interpretation of the results of the analysis. Nkado and Meyer (2001) point out that it is incorrect to assume linear or proportionate intervals between Likert rating points that are not rescaled. A correspondence analysis toolkit of the Number Cruncher Statistical Software (NCSS) was used to re-scale the Likert rating points from ordinal to interval scale for each set of ratings in the questionnaire, as documented by Bendixen and Sandler (1995).Clients’ expectations and ratings of performancesAnalyses of clients’ responses to levels of importance of their requirements, and performances of consultants and contractors in fulfilling them, are summarized in the following sections. Table1 shows an example of the analysis in respect of the quantity surveying services.Clients’ expectations from quantity surveying servicesClients’ expectations from quantity surveying services were explored during the pilot interviews. Levels of importance of the identified variables were rated during the quantitative surveys. Table1 presents clients’ responses, which are subjected to multi-attribute analysis for the purpose of establishing the mean ratings from clients’ collective points of view.  For ease of presentation, Table1 is split into two parts. The first part presents analysis of the relative importance of clients’ requirements from quantity surveying services, while the second part presents the relative performance of the group in meeting these requirements, as well as the perceived general satisfaction level delivered by the group. In Table1a and 1b, the rating scales for levels of importance are: VI5very important; JI5just important; SI5somewhat important; LI5of little importance; NI5not important. Similarly, levels of performance range from D (dissatisfactory) to VS (very satisfactory). In both tables, TR5total number of respondents; M5mean rating (equation1); RII5relative importance index (equation4); So5satisfaction score (equation1).requirements%%%%%TRIIRIIRanka93.36.7000604.870.2301b68.3256.700604.290.2022c67.21813.101.6614.140.1953d62.31813.16.60613.970.1874e55.731.113.100613.950.1865S21.231*Clients’ requirements from quantity surveying services:(a) Accurate and reliable cost and budget estimates, feasibility/viability and risk assessments.(b) Service efficiency (timely job execution and comprehensiveness of cost information).(c) Ability to foresee and budget reasonably for potential causes of cost escalations.(d) Efficient performance of duties as per terms and conditions of appointment/engagement.(e) Demonstration of competency (expertise and experience) for the job.Table 1b	Quantity surveyors’ performances(B) Quantity surveyors’ performanceClients’	requirements%%%%TRPIRemarksScIICI(a)31.675018.330602.41SS0.5544.872.021(b)2543.3331.670602.19SS0.4434.291.959(c)31.1531.1537.70612.29SS0.4464.141.808(d)31.1537.731.150612.33JS0.4353.971.704(e)2543.33256.67602.17JS0.4053.951.820Satisfaction level based on multi-attribute measures (SST)5JS2.282Satisfaction level based on single evaluative (overview) response (SSo):Overview:	18.64	37.288	40.678	3.39591.97SS1.97ResultsTable1a presents clients’ requirements or expectations from quantity surveying services. Results of the multiattribute analysis show that clients accord topmost priority to accurate and reliable cost and budget estimates, feasibility and risk assessments (RII50.23).  On a re-scaled four-point rating continuum, multiattribute analysis shows that the level of client satisfaction delivered by quantity surveyors falls within the ‘just satisfied’ range (Sc52.28). However, overview response analysis shows that the perceived level of satisfaction falls within the ‘somewhat satisfied’ level (Sc51.97), which implies average satisfaction level. Here, Handy and Ptaff’s (1975) argument for multiitem analysis of satisfaction appears superior to Czepiel and Rosenberg’s (1977) preference for single evaluative measures, given that clients’ response to an overall satisfaction measure only crudely measures overall satisfaction.  Criticality index (CI) analysis shows that accurate and reliable cost and budget estimates, feasibility and risk assessments are the most critical areas for improvement, given the high level of importance and perceived low level of performance of quantity surveyors in meeting the need.  From the relative importance index values (RII) in Table1, the quantity surveying (SQ) subcomponent of equation3 is of the empirical form:5SQ~X aqiSqi~0:230Sq1z0:202Sq2z0:195Sq3i~1ð8Þz0:187Sq4z0:186Sq5Quantity surveying consultants could therefore use this model to estimate the level of client satisfaction from their services if the perceived performance ratings (Sqi) are established from the client at any stage of the development process.Client requirements from the services of other consultants and contractorsTablesA1–A4 in the Appendix summarize the results of similar analyses for other consultants and contractors. The tables present, for each group, prioritized clients requirements, satisfaction levels as analysed from both multi-attribute and single evaluative measures and the multi-attribute estimation model.Relative contributions of subcomponents to satisfaction levelsClients’ ratings of the relative contributions of satisfaction levels delivered by each group in contributing to the overall level of satisfaction in the development process are analysed in Table2. The purpose of the analysis was to determine empirically the relative weights of the subcomponents of the multi-attribute model for assessing client’s overall satisfaction in the development process in line with equation3.ResultsTable2 shows that clients perceived the level of satisfaction with quantity surveying services as having the most profound effect on their overall level of satisfaction in the development process. In quantitative terms, this accounts for 29.5% of the total level of satisfaction expressed as a percentage.  On the basis of the relative weight (Rw) values of Table2, the constants in equation3 – A, B, C, D and E – corresponding to clients’ perceived levels of contributions of the group services in contributing to overall satisfaction in the development process have been empirically determined. Equation2 could therefore be re-written as:	Mq	Ma	MeSo~0:295X aiSqiz0:257X biSaiz0:125X ciSei	i~1	i~1	i~1         Mm	Mc	ð9Þ z0:11X diSmiz0:213X eiSci	i~1	i~1Monitoring satisfaction levels in the development processBuilt environment service providers do not have the luxury of making amends after a dissatisfactory outcome in a post-purchase satisfaction survey, as dissatisfied clients may not allow a ‘second chance’. Using the empirical models of equations8 and 9, the level of client’s satisfaction at any stage of the development process (preferably at pre-defined intervals through each stage) could be assessed by asking the client to rate performance on each relevant attribute of the operating component at the pertinent stage. Table3 presents a satisfaction level assessment model for each distinct stage of the development process in relation to the operating subcomponents (group services). The relative importance index (RII) values as empirically determined are adjusted to unity at each stage. The adjustment produces new relative weights (RIIadj) for evaluating the satisfaction level at any given stage.Overall satisfaction levelsOverall satisfaction levels in the development process were analysed from the multi-attribute and overview response analyses in Table4. The multi-attribute approach was based on Equation2, with a summation of the product of the relative weight and the satisfaction score for each group of service. The overview response
Table 2	Contributions of subcomponents to client’s overall satisfaction*DSC102030405060708090TRIIAdj IIRwRanka6.61855.713.16.600006129.5129.510.2951b043.356.70000006025.6725.670.2572c1566.713.30500006021.3321.340.2133d78.7183.30000006112.4612.460.1254e94.91.71.71.7000005911.0211.020.11599.991001*DSC: Development service components:(a) Costing services;(b) architectural design services;(c) construction (contracting) services;(d) engineering services; (e) management services.*TR5total respondents; II5importance index (sum of products of % relative contribution and % responses for each of the nine % relative contribution categories for a given group service component); Adj II5adjusted importance index to ensure 100% total value for all Iis.Table 3	Empirical models for evaluating stage satisfaction levelsStage	Components	RII	RIIadj	Model	Evaluation1: Conception	Costing services (SQ):	0.295	0.535	5	0.535[0.230Sq1+0.202Sq2	0:535XaiSqi	+0.195Sq3+0.187Sq4+0.186Sq5]i~1	Architectural services	0.257	0.465	6	0.465[0.195Sa1+0.171Sa2	(SA):	0:465XbiSai	+0.164Sa3+0.162Sa4	I~1	+0.155Sa5+0.152Sa6]	S	0:552	1	Empirical model for Stage 1 satisfaction level evaluation:SO5SQ+SA2: Design and procurementCosting services (SQ):0.2950.43650:436XaiSqii~10.436[0.230Sq1+0.202Sq2+0.195Sq3+0.187Sq4+0.186Sq5]Architectural services (SA):0.2570.37960:379XbiSaii~10.379[0.195Sa1+0.171Sa2+0.164Sa3+0.162Sa4+0.155Sa5+0.152Sa6]Consulting engineering services (SE):0.1250.18560:185XciSeii~10.185[0.195Se1+0.173Se2+0.165Se3+0.156Se4+0.156Se5+0.155Se6]S0:6771Empirical model for Stage 2 satisfaction level evaluation:SO5SQ+SA+SE3: Construction& close outCosting services (SQ):0.2950.29550:295XaiSqii~10.295[0.230Sq1+0.202Sq2+0.195Sq3+0.187Sq4+0.186Sq5]Architectural services (SA):0.2570.25760:379XbiSaii~10.257[0.195Sa1+0.171Sa2+0.164Sa3+0.162Sa4+0.155Sa5+0.152Sa6]Consulting engineering services (SE):0.1250.12560:125XciSeii~10.125[0.195Se1+0.173Se2+0.165Se3+0.156Se4+0.156Se5+0.155Se6]Construction project management services (SM):0.110.1160:11XdiSmii~10.11[0.175Sm1+0.173Sm2+0.172Sm3+0.166Sm4+0.159Sm5+0.157Sm6]Construction services (SC):0.2130.21360:213XeiSciI~10.213 [0.177Ss1+0.170Ss2+0.168Ss3+0.166Ss4+0.161Ss5+0.159Ss6]S11Empirical model for Stage 3 satisfaction level evaluation:*RIIadj5adjusted RII; ai5relative weight of the ith attribute in a given set; Sqi, Sai, Sei, Smi, Sci,5client’s rating of the level of satisfaction derived from an attribute of client’s requirements or expectations from costing, architectural, consulting engineering, construction/project management and contracting services, respectively.
analysis was based on Equation1, involving a summation of the products of the rating point and percentage responses to give clients’ mean rating of the satisfaction level delivered by each group of service providers.  Results of both multi-attribute and overview response analyses showed average (‘somewhat satisfied’) levels of client satisfaction in the development process.Internal validation of the research modelsIn addition to guiding the quest for data and achieving the research objective, a hypothesis was formulated with the aim of testing the internal reliability and validity of the developed models. The hypothesis tested whether the overall client satisfaction level estimated from the analysis of clients’ overview responses would differ significantly from similar estimates using multiattribute analysis.  As the test characteristics comprise ordinal measurement scale and two sample cases, the appropriate statistical methods are Wilcoxon’s matched-pairs and Spearman’s rank correlation tests (Cooper and Emory, 1995). Wilcoxon’s matched-pairs test was used to test for significance in differences between the set of satisfaction scores obtained from multi-attribute analysis of clients’ requirements from the services of the professionals and contractors, and the corresponding set obtained from the analysis of clients’ overview responses to levels of satisfaction with the services of consultants and contractors.  Spearman’s rank correlation coefficient was used to complement the reliability test by testing theTable 4	Summary of satisfaction scores	Multi-attribute analyses	Overview response analysesDevelopment serviceRel WtSiRemSsSiRemSs1	Costing services0.2952.282JS0.6731.97SS0.5812	Architectural0.2572.376JS0.6111.8SS0.4633	Engineering0.1252.298SS0.2872.3SS0.2884	Management0.111.927SS0.2121.81SS0.1995	Construction0.2133.08JS0.6562.1SS0.4476	Overall satisfaction levelsSS2.439SS1.978*Overall satisfaction rating on ordinal five-point rating scale:3SS(*Additional consistency check on overview responses) Correlation test:Spearman’s rank correlation coefficient (Rho): multi-attribute versus overview satisfaction scores:0.77*Si5satisfaction score (eqn3; Tables1, A1–A4); Ss5relative satisfaction score (eqn5); Rem5satisfaction level of the Si value on the re-scaled rating range: JS5just satisfied; SS5somewhat satisfied; Rel Wt5relative weight.significance of the correlation between the satisfaction scores obtained from the multi-attribute analysis and analysis of clients’ overview responses. Parameters used in the test (i.e. multi-attribute and overview satisfaction scores) were analysed in Table1 and are summarized in Appendix TablesA1–A4. Table4 presents the test data which was inputted into the NCSS analysis template.  In the Wilcoxon’s matched-pairs test, the null hypothesis assumed that the differences between the matched pairs of satisfaction scores analysed from both multi-attribute and overview response analyses would be zero or non-significant. The alternative hypothesis was that the multi-attribute satisfaction scores would be significantly higher.ResultsIn the Wilcoxon’s matched pair, the null hypothesis was not rejected (Appendix, TableA5). The result implies that satisfaction levels analysed from multiattribute evaluations are not significantly different from those derived from overview responses. Perhaps this lends credence to Czepiel and Rosenberg’s (1977) argument that a summary view of satisfaction is valid.  In addition, the Spearman’s rank correlation test result showed a positive statistically significant correlation (coefficient of 0.77) between both sets of satisfaction scores. The correlation was confirmed by the result of a Kolmogorov–Smirnov test, which suggests that both sample distributions are similar.  The test results satisfy the internal consistency and equivalence perspectives on reliability (Zikmund, 1994; Cooper and Emory, 1995) as one measure of the satisfaction phenomenon under study (i.e. multi-attribute satisfaction estimates) correlated significantly with an equivalent measure (i.e. overview response estimates).Practical application and limitation of the empirical modelsThe empirical models for measuring client needs during the development process (see Table3) are for generic applications in the popular traditional procurement process. The relative weights of the requirements of clients from the services of the consultants and contractors as shown in Table3 are generic and could vary over time, for individual clients, and for specific projects. However, a template for the assessment of individual client requirements for all types of procurement arrangement options and at any point in time is shown in TableA6 in the Appendix. The application of this template in a case study for assessing an individual client needs and satisfaction levels was reported elsewhere (Nkado and Mbachu, 2001).ConclusionThis study sought to develop a conceptual framework for the assessment of client needs and satisfaction in the building development process. In addition, the developed framework was used to assess and prioritize clients’ needs and requirements from professional services. Through the criticality index (CI) analyses, areas for improvement in professional groups services were explored.  Results of the analyses of clients’ needs and requirements from the professions showed that, in quantity surveying services, clients place premium on accurate and reliable cost and budget estimates, feasibility and risk assessments. Criticality index analysis showed that this set of expectations is the most critical area for improvement given the high level of importance attached to it by clients, and the perceived low performance of quantity surveyors in this area.  For architectural services, clients attach highest level of importance to designs which are within their budgets, yet adequately address their main needs and requirements. This need was also found to be the most critical area for improvement in architectural services.  Safety and economy in design are the priority expectations of clients from engineering services. Criticality index analysis also confirms this to be the most critical area for improvement given the relatively low performance of engineers in this respect.  For both construction project management and contracting services, clients’ utmost expectation is to receive the completed building within agreed time, cost and quality targets. However, whereas this area of service is the most critical for improvement in the services of construction project managers, criticality index analysis showed that accommodating clients’ changes in good faith is the most critical area for improvement in the services of contractors.  Overall, both multi-attribute and overview response analyses showed that, on a four-point rating continuum, clients are only ‘somewhat’ satisfied with the services of key professional groups and contractors engaged in the development process.  A proactive and dynamic approach to client needs and satisfaction assessment was developed and validated in the study for use by consultants in the assessment of client needs, measurement and monitoring of client satisfaction levels at distinct phases of the development process. The established stage evaluation models are recommended to the project team to enhance client satisfaction levels in the building industry.AcknowledgementsThis research was supported by the RICS Education Trust, UK, to whom the authors are grateful.ReferencesBendixen, M.T. and Sandler, M. (1995) Converting vertical scales to interval scales using correspondence analysis. Management Dynamics, 4(1), 31–49. Bennett, J. (1985) Construction Project Management, Butterworths, London.Bowen, P.A. (1993) A communication-based approach to price modeling and forecasting in the design phase of the traditional building procurement process in South Africa, Unpublished PhD thesis, University of Port Elizabeth, South Africa.Bowen, P.A., Pearl, R.G., Nkado, R.N. and Edwards, P.J. (1997) The effectiveness of the briefing process in the attainment of client objectives for construction projects in South Africa COBRA ’97: RICS Research, Royal Institution of Chartered Surveyors, UK, pp. 1–10.Chang, C. and Ive, G. (2002) Rethinking the multi-attribute utility approach based procurement route selection technique. Construction Management and Economics, 20(3), 275–84.Churchill, G.A. and Surprenant, C. (1982) An investigation into the determinants of consumer satisfaction. Journal of Marketing Research, 19, 491–504.Cooper, D.R. and Emory, C.W. (1995) Business Research Methods, 5th edition, Richard D. Irwin Inc., Chicago, USA.Czepiel, J.A. and Rosenberg, L.J. (1977) The study of consumer satisfaction: addressing the ‘so what’ question, in Hunt, K.H. (ed.) The Conceptualization of Consumer Satisfaction and Dissatisfaction, Marketing Science Institute, Cambridge, MA.Day, R.L. (1977) Alternative definitions and designs for measuring consumer satisfaction, in Hunt, K.H. (ed.) The Conceptualization of Consumer Satisfaction and Dissatisfaction, Marketing Science Institute, Cambridge, MA.Day, R.L. and Landon, E.L. (1977) Towards a theory of consumer complaining behavior, in Woodside, A.G., Sheth, J.N. and Bennett, P.D. (eds) Consumer and Industrial Buying Behavior, North-Holland, New York, pp. 425–37.Goodacre, P., Pain, J., Murray, J. and Noble, M. (1982) Research in building design Occasional Paper No. 7, Department of Construction Management, University of Reading, UK.Green, S.D. and Lenard, D. (1999) Organising the project procurement process, in Rowlinson, S.M. andMcDermott, P. (eds) Procurement Systems: A Guide to Best Practice in Construction, E&FN Spon, London, pp. 57–82.Handy, C.R. (1977) Indexes of Consumer Satisfaction with Food Products: 1974 and 1976 Survey Results, inDay, R.L. (ed.) Consumer Satisfaction, Dissatisfaction and Complaining Behavior, School of Business, Indiana University, Bloomington/Indianapolis, pp. 51–61.Handy, C.R. and Ptaff, M. (1975) Consumer satisfaction with foods products and marketing services Agricultural Economic Report, 281, Economic Research Service, US Department of Agriculture, New York.Kometa, S.T., Olomolaiye, P.O. and Harris, F.C. (1994) Attributes of UK construction clients influencing project consultants’ performance. Construction Management and Economics, 12, 433–43.Kotler, P. (1997) Marketing Management: Analysis, Planning, Implementation and Controls, 9th edition, Prentice Hall, New Jersey.Landon, E.L. (1977) A Model of Consumer Complaining Behavior, in Day, R.L. (ed.) Consumer Satisfaction, Dissatisfaction, and Complaining Behavior, School of Business, Indiana University, Bloomington/Indianapolis, pp. 31–5.Leedy, P.D. and Ormrod, J.E. (2001) Practical Research: Planning and Design, 7th edition, Merrill, New Jersey.Liu, A.M.M. and Walker, A. (1998) Evaluation of project outcomes. Construction Management and Economics, 16, 209–19.Mbachu, J.I.C. (2003) Acritical study of client needs and satisfaction in the South African building industry, Unpublished PhD thesis, University of Port Elizabeth, South Africa.National Economic Development Office (NEDO) (1974) Before You Build, Building Economic Development Committee, Her Majesty’s Stationery Office, London.Nkado, R.N. and Mbachu, J.I. (2001) Modelling client needs and satisfaction in the built environment Proceedings of the ARCOM Conference, Salford, UK, 5–7 September.Nkado, R.N. and Mbachu, J.I.C. (2002) Comparative analysis of the performance of built environment professionals in satisfying clients’ needs and requirements Construction Innovation and Global Competitiveness, Vol.1, CRC Press, Cincinnati, pp. 408–25.Nkado, R.N. and Meyer, T. (2001) Competencies of professional quantity surveyors: a South African perspective. Construction Management and Economics, 19, 481–91.Oliver, R.L. (1981) Measurement and evaluation of satisfaction process in retail settings. Journal of Retailing, 57(Fall), 25–48.AppendicesTable A1	Clients’ requirements from architectural services Preece, C. (2000) Client Satisfaction in Construction: Developing a Programme of Total Client Satisfaction Through Service Quality in Construction Contracting, Department of Civil Engineering, University of Leeds, UK.Rust, R.T. and Zahorik, A.J. (1993) Customer satisfaction, customer retention, and market share. Journal of Retailing, 69(2), 193–215.Surprenant, C. (1977) Product satisfaction as a function of expectations and performance, in Day, R.L. (ed.) Consumer Satisfaction, Dissatisfaction and Complaining Behavior, School of Business, Indiana University, Bloomington/ Indianapolis, pp. 36–7.Swan, J.E. and Combs, L.J. (1976) Product performance and consumer satisfaction: a new concept. Journal of Marketing, 40(April), 25–33.Taylor, S.T. and Baker, T.L. (1994) An assessment of the relationship between service quality and customer satisfaction in the formation of consumer purchase intentions. Journal of Retailing, 70(2), 163–78. Turner, A. (1990) Building Procurement, Macmillan Education Ltd, London.Woodruff, R.B., Cadotte, R.E. and Jenkins, R.L. (1983) Modeling consumer satisfaction process using experiencedbased norms. Journal of Marketing Research, XX(August), 296–304.Zikmund, W.G. (1994) Business Research Methods, 4th edition, Harcourt Brace College Publishers, New York.
BClient requirementsIIRII (ai)PI*RemSaiCIiDesign tailored to suit client’s budget, yet adequately address client’s main needs4.210.1952.11JS0.4121.995iiDelivery to be timely, detailed and comprehensive3.690.1712.73JS0.4681.352iiiFlexibility in design (to accommodate changes with minimal cost implications)3.530.1642.38JS0.3891.483ivOptimal, workable and error-free designs and detailing3.50.1622.2JS0.3571.591vAesthetic appeal (beauty in design and concepts)3.350.1552.07JS0.3211.618viEfficient performance of duties as per terms and conditions of appointment/engagement3.280.1522.82JS0.431.163Satisfaction level based on multi-attribute measures (SST) (Eq8)5	JS	Satisfaction level based on single overview response (SSO) (Eq1) :5	SS	1.86Empirical model component: XaiSai ðEqn: 3Þ~0:195Sa1z0:171Sa2z0:164Sa3z0:162Sa4z0:155Sa5z0:152Sa6i~6*Rem5Remarks for re-scaled Likert points for performance index (PI) levels: 45VS (Very satisfactory); 1.895JS; 1.335SS; 15D(Dissatisfactory); CI5Criticality index (Equation7)Table A2	Clients’ requirements from consulting engineering servicesRII (a )	Mi	Safe and economical design	4.1790.1952.33SS0.4531.794ii	Delivery to be timely, detailed and comprehensive	3.7070.1732.47JS0.4261.501iii Sustainability/flexibility in design and construction	3.5490.1652.22SS0.3671.599iv Workable and error-free designs and detailing	3.3560.1562.12SS0.3311.583v	Functional and durable design and constructions	3.3510.1562.28SS0.3561.47vi	Efficient performance of duties as per terms and	3.335 conditions of appointment/engagement0.1552.36JS0.3661.413Satisfaction level based on multi-attribute measures (SST) (eqn8)5SS2.298Satisfaction level based on single evaluative response (SSO) (eqn1)56SS2.3Empirical model component : XciSeiðeqn 3Þ~0:195Se1z0:173Se2z0:165Se3z0:156Se4z0:156Se5z0:155Se6i~1*Rem5remarks for re-scaled Likert points for performance index (PI) levels: 45VS (very satisfactory); 2.365JS; 1.695SS; 15D(dissatisfactory).Table A3	Clients’ requirements from construction project management servicesii Manage client’s changes efficiently with minimal cost implications iii Team work and efficient coordination of all services to achieve4.6350.1732.33SS0.4021.989desired goals4.6270.1721.68SS0.2882.754iv	Technical and managerial competences/experience v	Efficient performance of duties as per terms and conditions of4.4470.1661.89SS0.3132.353     appointment vi	Effective and unbiased communication of project objectives to all4.2670.1592.17SS0.3441.966parties4.2050.1571.85SS0.2902.273Satisfaction level based on multi-attribute measures (SST) (eqn8)5SS1.927Satisfaction level based on single evaluative response (SSO) (eqn1)56SS1.81Empirical model component : XdiSmi ðeqn 3Þ~0:175Sm1z0:173Sm2z0:172Sm3z0:166Sm4z0:159Sm5z0:157Sm6i~1*Rem5remarks for re-scaled Likert points for performance levels: 45VS (very satisfactory); 2.775JS; 1.665SS; 15D (dissatisfactory).Table A4	Employers’ requirements from the services of contractorsIIRII (ai)PIRemScii	Delivery within agreed time, quality and cost targets	4.970.1773.14JS0.5551.583ii	Accommodating changes made by employer in good	faith	4.760.1692.66JS0.4511.789iii	Efficient coordination of specialist and subcontractors’	works	4.710.1683.36JS0.5641.402iv	Technical and managerial competence	4.650.1653.18JS0.5261.462v	Financial capacity and adequate guarantee against own	and subcontractors’ defaults	4.530.1613.11JS0.5011.457vi	Minimize costs (avoid on-site time and material was	tages)	4.480.1593.03JS0.4831.479Satisfaction level based on multi-attribute measures (SST) (eqn8)5JS3.08Satisfaction level based on single evaluative (overview) response (SSO) (eqn1)5SS2.16Empirical model component : XeiSci ðeqn 3Þ~0:177Ss1z0:169Ss2z0:168Ss3z0:165Ss4z0:161Ss5z0:159Ss6i~1*Rem5remarks for re-scaled Likert points for performance levels: 45VS (very satisfactory); 2.555JS; 1.795SS; 15D (dissatisfactory).Table A5	Wilcoxon’s signed-rank test for difference in meansNumberW Sum ranks	Mean of W	SD of W	Number of Zeros	sets of ties	Multiplicity factor	16.5	10	4.73022	1	1	6	Approximation without continuity correction	Approximation with continuity correctionAlternative hypothesisZ-valueProb LevelDecision 25%Z-valueProb levelDecision25%X12X2,.01.3740.169Accept Ho1.2680.205AcceptHoX12X2,01.3740.915Accept Ho1.4800.931AcceptHoX12X2.01.3740.085Accept Ho1.2680.102AcceptHoTable A6	Template for individual client’s needs assessment and satisfaction measurementNeeds/requirements	*Rank	5	4	3	2	1Rp(Ri6Rpi)Remarks(A)Requirements from costing services:Q1R1`Rp1Ss1Q2R2`Rp2Ss2Q2R2`Rp2Ss2Q2R2`Rp2Ss2QNRN`RpN Sum:SsN(B)Requirements from architectural services:A1R1`Rp1Ss1A2R2`Rp2Ss2A2R2`Rp2Ss2ANRN`RpN Sum:SsN(C)Requirements from consulting engineering services:E1R1`Rp1Ss1E2R2`Rp2Ss2E2R2`Rp2Ss2ENRN`RpN Sum:SsN(D)Requirements from construction project mgt services:CM1R1`Rp1Ss1CM2R2`Rp2Ss2CM2R2`Rp2Ss2CmNRN`RpN Sum:SsN(E)Requirements from contracting services:Cs1R1`Rp1Ss1Cs2R2`Rp2Ss2Cs2R2`Rp2Ss2CsNRN`RpN Sum:SsN*Satisfaction level (five-point rating scale): VS5very satisfied; JS5just satisfied; SS5somewhat satisfied; LS5little satisfied; NS5not satisfied. *Rank5rank of each need/requirement in a given set (highest rank to topmost priority need, vice versa); Rp5rating point (perceived satisfaction level derived from the extent of fulfilment of a given need at the appropriate assessment stage); Ss5satisfaction score obtained; Remarks5satisfaction level of Ss on the rating scale.32	Mbachu and NkadoBuilding client needs and satisfaction assessment	33