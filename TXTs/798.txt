KSCE Journal of Civil Engineering (2022) 26(3):1144-1162	pISSN 1226-7988, eISSN 1976-3808
DOI 10.1007/s12205-021-0972-2	 www.springer.com/12205

SEMA: A Site Equipment Management Assistant for Construction Management
Meng-Han Tsaia, Cheng-Hsuan Yangb, Chen-Hsuan Wanga, I-Tung Yanga,  and Shih-Chung Kangb
aDept. of Civil and Construction Engineering, National Taiwan University of Science and Technology, Taipei 106, Taiwan bDept. of Civil and Environmental Engineering, University of Alberta, Edmonton T6G 2R3, Canada


Received 31 May 2021
Accepted 27 September 2021 Published Online 17 November 2021
KEYWORDS

Chatbot
Image recognition
Construction management
Deep learning
Site equipment management
Collecting construction equipment information such as the site equipment enter and exit date-time, driver's name, type, and quantity is essential in construction management. Most construction projects use paper to record the equipment access history. However, manual recording is always labour-intensive and time-consuming. Therefore, this research aims to develop an assistant system, Site Equipment Management Assistant (SEMA), to automate the site equipment management processes. With the introduction of image recognition and multiple objects tracking technologies, the proposed system can extract equipment-related information from raw videos. SEMA is designed as a chatbot system that contains three major modules: data acquisition, information extraction, and information delivery. A deep learningbased model was first trained to automatically recognize and track construction equipment passing by the site monitor. Information such as equipment entering and exiting date-time, type, and quantity would be extracted and stored in a database. A chatbot interface was developed for users to obtain data from the database through an intuitive and easy-to-use interface. A system evaluation and usability test were conducted. The results showed that the system could effectively improve the construction equipment management process. SEMA can save 60.7% of users' operation time on obtaining related information.

1. Introduction
Construction site equipment management is considered one of the most critical tasks for overall construction management. The management process usually needs the related personnel to record the engineering logs manually. This process may lead to information asymmetry due to the ineffectiveness and inefficiency of the manual works. Such processes make the site equipment management not only time-consuming but also labour intensive.
   In recent years, due to the rapid development of digital camera technology (Katz et al., 2008), more and more construction sites have installed surveillance cameras to record workers and construction equipment. Videos recorded by the surveillance camera are reasonable input recourse for progress management and construction site control. During the construction period, lots of construction equipment may leave and enter the site every day. 
However, construction sites usually face difficulties analyzing and processing these massive videos due to the lack of data processing capabilities (Alavi and Gandomi, 2017). As a result, relevant personnel need to monitor the equipment activities by manually recording the equipment information (e.g., enter and exit date-time, driver’s name, equipment type, etc.) or creating engineering logs by fast-forwarding the recorded videos (Tajeen and Zhu, 2014). However, these methods are usually timeconsuming and have high error rates (Slaton et al., 2020). The long processing time also makes it hard for the project manager to make immediate decisions when an unexpected incident or abnormal situation occurs.
CORRESPONDENCE Meng-Han Tsai 	 menghan@mail.ntust.edu.tw  	 Dept. of Civil and Construction Engineering, National Taiwan University of Science and Technology,                   
Taipei 106, Taiwan
ⓒ 2022 Korean Society of Civil Engineers
  Besides labour involvement, the information acquisition of the equipment management is usually not real-time. In most construction sites, the on-site manager will query the equipment information from monitor workers by radio equipment (e.g., walkietalkie), instant messaging application (e.g., LINE, Whatsapp), or phone calls. The process may lead to information delivery delays and make the on-site manager hard to obtain real-time information. The manual information delivery process may also cause high error rates and thus mislead the manager’s decisions.
  Lastly, the user interface (UI) of the management system is usually not user-friendly. The system usually has one-way interactions and requires a series of training processes for users to get familiar with its UI. The complicated operation procedures might also reduce the user's willingness to use the system. Recently, an increasing number of research or industrial entities have used chatbots to address these issues. A chatbot built on instant messaging applications allows users to query the information through a friendly interface or natural languages. Building a chatbot on existing instant messaging applications can reduce the system's pretraining time and increase users' intentions.
  Therefore, this research aims to develop a site equipment management system, Site Equipment Management Assistant (SEMA), to improve the equipment management process. SEMA is designed to 1) collect videos from surveillance cameras installed in the construction site as input resources, 2) extract useful information from collected videos, 3) deliver the information through a chatbot interface, 4) provide instant notifications to the site managers when an unexpected event occurs automatically, and 5) generate weekly reports based on acquired data from construction videos.
2. Literature Review
At most building construction sites, the collection and analysis of construction resource information have not been automated (Gong and Caldas, 2011). Manually collecting data requires lots of human involvement (Park and Brilakis, 2012). The results of the manually collected data usually have information asymmetry since the data would be impacted by workers’ subjective consciousness and professional ability (Golparvar-Fard et al., 2013). The process not only reduces the availability to continuously monitor the entire construction site (Heydarian et al., 2012) but also increases error rates. The progress on the construction site might thus delay due to inaccurate and incomplete information.
  In recent years, studies have been devoted to developing methods for automatically tracking and recognizing construction resources. These methods are mainly for progress management, safety management, and maximizing the time for continuous monitoring. Modern technologies such as radio-frequency identifications (RFIDs) (Goodrum et al., 2006; Chae and Yoshida, 2010; Teizer et al., 2010), barcode (Li et al., 2003; Oh et al., 2004), ultra-wide band (UWB) (Teizer et al., 2008; Yang et al., 2011), global position system (GPS) (Ergen et al., 2007; Lu et al., 2007), and computer vision (Liu et al., 2018) were utilized to track and onsite construction resources and monitor the construction progress. These studies mainly proposed methods to track construction equipment, materials, and workers for progress management or on-site safety improvements. However, such hardware-based technologies might have extra hardware costs, especially when the number of tracking targets is too high (Brilakis et al., 2011). As the cost of the digital camera falls and the capability of computer vision technologies, utilizing cameras to collect videos in the construction and computer vision technology to extract meaningful information for safety and progress monitoring has become a promising direction in construction management. The following subsections will provide a detailed review of previous studies on applications of videos in construction management, construction resources recognition and tracking, and challenges of the information delivery for the site management.
2.1 Videos in Construction Management
As the price of digital cameras falls, installing digital cameras on the construction site to collect images or stream videos has become an affordable and reliable monitoring solution. The advancement of computer vision and machine learning technology allows automatic analysis of construction activities and construction entities. A lot of visual information can be extracted from images and streamed videos. Moreover, the extracted information can be processed and transferred into an infographic that lets users examine the construction site's progress and make decisions quickly. Thus, studies have focused on construction site videos use as auxiliary tools for progress tracking, safety control, and site monitoring.
  As for progress tracking, the project manager needs a comprehensive and useful monitoring system to acquire the latest construction activities (Ren et al., 2015). Site managers usually use quantification standards to evaluate the site progress through continuous information obtained from site videos to decide resources management and procurement. Furthermore, managers need to track the construction equipment's flow through the construction site video every day to compare it with the daily log. However, transferring the site videos or images into useful information still requires lots of manual effort. Thus, studies have been conducted to automized the information extracting process. For instance, Golparvar-Fard et al. (2015) proposed an automated progress monitoring method using unordered daily construction photos. Son et al. (2014) tried to use an ensemble classifier to classify major materials in images taken from construction sites. Yang et al. (2016) developed a machine learningbased method to recognize the activities of construction workers for progress and productivity check. Park et al. (2015) developed a vision-based method to automatically monitoring whether people are wearing hard hats on the construction site.
  Besides the progress management, footage collected from site cameras is also utilized for safety controls. For instance, Han and Lee (2013) proposed a vision-based framework to detect unsafe behaviours automatically. Computer vision techniques were utilized to estimate body joint positions in the collected site videos and thus identify the predefined unsafe actions of on-site workers. Based on the framework, Han et al. (2014) conducted another study focusing on classifying the workers’ actions by using four motion data types as features: rotation angles, joint angles, position vectors, and movement direction. The classification of actions is then processed based on spatial-temporal similarity. 
  Videos or images captured from site cameras were also utilized in the application of site monitoring. For instance, Teizer and Vela (2009) discussed the feasibility of tracking the personnel on construction job sites from video cameras. Golparvar-Fard et al. (2013) presented a computer vision-based method to recognize the earthmoving equipment’s actions, such as excavators and trucks. The proposed method was validated to apply for construction activity analysis when using long sequences of videos. Rashidi et al. (2016) conducted a comparison study to test different machine learning algorithms for detecting three different materials (i.e., concrete, red brick, and OSB boards) in digital images captured from construction sites.
  Extracting useful information from video footage is considered not only labour intensive but also time-consuming. Additionally, reviewing and processing the massive amounts of video footage increases error rates (Turkan et al., 2012). To address these issues, studies have been conducted to automize the information extraction process. The results of previous studies showed that applying computer vision or machine-learning technologies to process videos and extract useful information for construction management is a promising direction.
2.2 Construction Resources Recognition and Tracking
Having real-time and accurate data of the construction resources (e.g., equipment activity and materials) can help the site manager monitor the construction progress, analyze productivity, and make effective decisions. In the past decades, as sensors become affordable, studies have been conducted to monitor the construction resources by using sensors like GPS (Oloufa et al., 2003; Ergen et al., 2007; Lu et al., 2007) and RFID (Jaselskis and El-Misalami, 2003; Chae and Yoshida, 2010; Elghamrawy and Boukamp, 2010). Recently, with the advancement of artificial intelligence techniques, vision-based monitoring methods have drawn increased attention. Accurate extraction of data and information from images and videos in real-time is becoming widespread. When the construction equipment and workers in the construction site become the recognition targets of the image recognition algorithm, the objects are recognized, classified, and tracked using vision-based methods. Object recognition uses a detector to recognize features such as colour, shape, or other features in each frame. Then a classifier is used to classify the detected object. Finally, the target can be tracked in continuous frames through feature distinguishing (Bewley et al., 2016).
  Studies concerning vision-based systems for construction sites can be divided into two categories: 1) static object detection and classification and 2) tracking objects in multiple sequential and consecutive frames (Kim et al., 2016). For instance, Brilakis et al. (2011) developed a system that uses image recognition to classify construction material to allow users to search the image database. Teizer and Vela (2009) noted that a key challenge in tracking worker’s activity on a construction site is the high level of visual clutter. Construction sites have many moving obstacles that may cause the occlusion problem, and the visual photometry is changing all day. Thus, they used Bayesian segmentation to obtain improved precision. Park and Brilakis (2012) used Speeded Up Robust Features (SURF) to track and recognize the two-dimensional (2D) coordinates of the object from the surveillance camera. After they tracked these objects, they matched the 2D coordinates of the object in each frame to plot the object’s trajectory to enhance on-site safety and monitor the project. Chi and Caldas (2011) proposed a framework to track heavy equipment and workers on construction sites. They used foreground object detection and a segmentation algorithm to distinguish between stationary and moving objects. A multilayer perceptron (MLP) neural network and normal Bayes classifier classify objects and track their activity.
  Besides static object detection and classification, object tracking is also becoming increasingly popular. Tracking the construction resources (e.g., equipment) can help the site manager monitor and record overall progress. On the construction site, there are often lots of construction equipment moving dynamically. It generally requires the tracking of multiple targets in a series of continuous video frames. Multiple target tracking refers to detecting the trajectories of different objects simultaneously. However, most multiple object detection approaches accumulate the features of each frame, leading to low performance. Studies have proposed several detection-by-tracking multiple object tracking algorithms. When tracking objects, bounding boxes of the objects are first set to label the object's position. Then, the data association matching method would confirm whether the same object can be matched in other frames. For instance, Deep SORT is one of the algorithms that can track multiple objects in real-time (Wojke et al., 2017).
  Even though extracting useful information from videos has been developed for applications of construction monitoring, the information delivery methods are rarely discussed in previous studies. The current method to deliver the information extracted from site videos is usually not intuitive enough. In addition, the unfriendly user interface and user experience might reduce the user's willingness to operate the monitoring system.
  Although many image recognition systems have been developed, the data delivery methods of these systems are not sufficiently intuitive or convenient. A well-designed and friendly user interface might increase the user's willingness to operate the system. Moreover, a delivery method that provides real-time information can also help site managers to make immediate and effective decisions (Hui et al., 2015).
2.3 Information Delivery for Construction Management
In addition to extracting information from massive amounts of construction videos, delivering the extracted information effectively is another critical issue. Different management systems have been developed to provide users with a bridge to obtain the extracted information from site videos. For instance, Abeid et al. (2003) proposed a monitoring system based on a web page that connects with surveillance cameras on the construction site to record videos automatically. The system used the critical path method (CPM) and progress control techniques to allow the user to check the construction site anytime and anywhere. Deng et al. (2001) proposed an Internet-based project management application that combines site video viewing and instant chat room functions. The application allows managers or related personnel can discuss and communicate online before making decisions. Gong and Caldas (2011) developed a system for rapid productivity analysis of construction operations based on computer vision and operation process modelling methods. However, these systems' user interface and data retrieval approaches are usually unintuitive and challenging for new users. Users might need to go through complete training to get familiar with these systems. Also, these systems were usually built on a personal computer, which makes them hard to use in the construction environment.
  Recently, with the development of mobile devices and the increasing population of instant messaging applications, utilizing a chatbot system for information delivery purposes has been widely discussed (Shawar and Atwell, 2005). The chatbot is a communication system that allows users to retrieve information through keywords or natural language (Chiaráin and Chasaide, 2016). Chatbots can integrate various advanced technologies and functions to achieve two-way communication for information in real-time (Chan and Tsai, 2019). Studies have been conducted to develop chatbots for delivering information in many fields. For instance, Muslih et al. (2018) proposed a Telegram chatbot to let employees remotely control electronic devices on their workspace by entering predefined keywords. Vegesna et al. (2018) proposed an ontology-based chatbot to handle E-commerce website’s queries from users. Oh et al. (2017) developed a chatbot for psychiatric counselling in mental healthcare services based on emotional dialogues.
  Utilizing chatbots as information delivery tools were also discussed in the field of civil engineering. For instance, Kosugi and Uchida (2019) developed a chatbot to provide disaster information when a disaster occurs. The user can also provide the disaster photo or location to the chatbot to share the situation with other people. Tsai et al. (2019) developed a chatbot, Ask Diana, to provide water-related disaster information for Taiwan government decision-makers. Choa and Ghang (2019) used a chatbot for construction management. The chatbot was designed to automatically generate and deliver daily reports on the construction site for general contractors. Chen and Tsai (2021) proposed a conversation-based building information delivery method for facility management. They developed a chatbot that allows facility managers or related personnel to retrieve facilities’ information through an instant messaging application on mobile devices.
  Although the chatbot system has been implemented in many fields and proven effective and efficient in information delivery, chatbots in site management have rarely been discussed. A chatbot system's light and two-way communication characteristics will allow the site manager to acquire site-related information dynamically. Compared to the conventional delivery system, which was usually built on desktop computers or webpages, the chatbot system can provide a more efficient and instant interface for related personnel to query information and thus make appropriate decisions.
3. Research Objectives

Fig. 1. The System Architecture of SEMAThe objective of this research is to evaluate the efficiency and effectiveness of using an integrated system for on-site equipment management. In previous studies, modern technologies, such as computer vision, artificial intelligence (AI), and information technology (IT) have been utilized in construction equipment management. However, these studies usually focused on a single perspective (e.g., data processing, information extraction, information delivery, etc.) instead of holistic solutions. Therefore, this research aims to develop a site equipment management system that integrates new technologies for data collection, information extraction and information delivery. The developed system should fulfill the following two goals.
1. The system should process and extract useful information from the collected data automatically to reduce the manual processing time. 
2. The system should provide an information delivery mechanismthat can increase the efficiency of information extraction.
4. Methodology
This research proposed a construction site equipment management system, namely Site Equipment Management Assistant (SEMA). The proposed SEMA contains one database and three major modules: data acquisition, information extraction, and information delivery (Fig. 1). First, the data acquisition module would collect videos from site cameras and access reports’ images scanned by users. Second, the information extraction module would be in charge of extracting predefined information from both videos and scanned access forms. The extracted information would then be stored in the site information database. Last, a chatbot would be utilized as the information delivery mechanism to allow users to query information from the database. The following subsections will provide descriptions of each module in detail.
4.1 Data Acquisition Module
The data acquisition module is designed to collect raw data for the site equipment. Two data types will be collected for further use in this module: video streaming videos from the construction site's surveillance cameras and scanned access forms. SEMA will utilize computer vision and deep learning methods to extract the information of the equipment that enters or exits the construction site. In addition, the character recognition techniques will be used to digitalize the paper-based access forms generated by related personnel.
  An API was first developed for collections of site videos to obtain the streaming videos from site cameras. With the fast growth of the Internet of Things (IoT) related technology, most on-site cameras provide access to streaming videos remotely. Therefore, the data acquisition module contains an API that can automatically obtain streaming videos through the Internet connection.

Fig. 2. The Flowchart of the Construction Equipment Detection and Tracking Process  The site manager or gatekeeper usually issues access forms to authorize the equipment or vehicles to enter the construction site. 

The access form contains information such as entering the date, driver’s name, types of equipment, and purposes of entering the site. The driver should put the printed access form in front of the windshield of the equipment as an identification. The data acquisition module allows users to scan the paper-based form to collect the information from the access form. Users can use mobile devices to scan the access form of each piece of equipment. SEMA’s information extraction module will digitalize the form using the Optical Character Recognition (OCR) algorithm.
4.2 Information Extraction Module
The information extraction module is designed to extract useful information from the collected data from the data acquisition module. During the construction period, a massive amount of raw data will be collected every day. Processing the raw data manually could be time-consuming and labour-intensive. Therefore, it is important to automize the information extraction process. This module is developed to extract information from two different types of raw data: videos and scanned access forms.
4.2.1 Extracting Information from Site Videos
SEMA extracts two kinds of information from site videos. The first is the statistic information of the equipment entered the construction site, for example, the number of trucks entered the site today. A deep learning-based algorithm was utilized to detect and track the equipment in continuous image frames. The second information is the highlight video extracted from the long-term raw videos. Image frames that contain equipment’s entry or exit will be marked as keyframes. These keyframes will then be combined as a highlight video for users to review.
4.2.1.1 Equipment Detection and Tracking
Figure 2 illustrates the flowchart of SEMA’s equipment detection and tracking process. SEMA will first extract each image frame for further processing when streaming videos from the data acquisition module. Then, the YOLOv3, which performs highly with respect to recognizing construction equipment, a detector would be used to detect equipment in the image frame. YOLOv3 is a one-stage image recognition algorithm with high performance and accuracy. The construction site equipment requires precise position coordinates and multiple-scale detection to detect construction equipment of different scales. Therefore, this research uses the YOLOv3 (Redmon and Farhadi, 2018) algorithm in the many image recognition algorithms. YOLOv3 has advantages of fast detection, accurate positioning, and high accuracy for object detections compared with other algorithms.
  If a piece of equipment is detected, an equipment label will be created. After creating the label, SEMA will check whether the detected equipment is a new tracking object. If the detected equipment has been tracked in previous frames, then SEMA will start to predict the object's position. Otherwise, it will create a new trajectory for the equipment. A matching cascade compares the predicted position from the previous frame with the actual position detected in the current frame. If these two positions 

Fig. 3. The Schematic Diagram of the Pre-set Detection Lines
match, the system will update the tracker information and the new bounding box. If the two positions are different, the object will be removed. Two detection lines, a blue line and a red line, near the site gate, will be set on the image to check if the detected equipment enters or exits the site (Fig. 3). SEMA determines that the construction equipment or vehicle is entering the site if the construction equipment or vehicle goes through the red line first. If the construction equipment or vehicle goes through the blue line first, SEMA determines that the construction equipment or vehicle exits the site. The counting information of that equipment will be updated if the detection results show that it enters or exits the site; otherwise, the process will start over a new image frame. SEMA will update the newest statistic information to the information delivery module for proactive notifications. Lastly, the ID of the current frame (frameID), the timestamp, the type of the tracked equipment, and the machine ID (machineID) are stored in a database. The tracked equipment’s boundary box, including coordinates (x and y) and sizes (width and height), will also be stored in the database.
  To address the issue of repeated calculation of the site equipment, this research used the Deep SORT, a state-of-the-art multiple objects tracking method, as the equipment tracker. Using Deep SORT can address the occlusion problem caused by a single monitoring system as it can reduce the problem caused by long-term occlusion. Fig. 4 illustrates the flowchart of the Deep SORT method. It used the Hungarian algorithm to calculate the similarity between the prediction box that the Kalman filter generates and the boundary box detected by YOLOv3. There are three resulting statuses: unmatched tracks, unmatched detections, and matched tracks. The Intersection Over Union (IOU) match, which generates the same three types of statuses, will be applied to confirm the new trajectory and enhance accuracy. Finally, SEMA uses the Kalman filter to update the prediction box using the detection box of YOLOv3.
  The flowchart of the matching cascade is shown in Fig. 5. In the beginning, each detector is assigned to a tracker, and each tracker has a parameter indicating how many frames are not matched successfully. This parameter will be zeroed after the tracker has matched successfully and updated. Otherwise, it continues to increase by one. Then, the trackers are matched according to the size of the parameters, with the smaller parameters matching first and the larger parameters matching later. The tracker is deleted when the parameter reaches Agemax, 
Fig. 4. The Flowchart of Deep SORT Method

Fig. 5. The Flowchart of Matching Cascade Process
where the tracker is not matched successfully in Agemas frames. Agemax is the iteration of the detection frames. Cascade matching uses Mahalanobis distance to calculate motion information and uses cosine distance to calculate the appearance information. The Mahalanobis distance is added to the covariance matrix to normalize the distance and better align with the actual data. Deep SORT uses the Kalman filter and the current frame's status predicted to calculate the Mahalanobis distance, as shown in Eq. (1), to present the motion match. The cosine distance is a similarity measurement matrix. Deep SORT adds a feature extraction structure and stores the tracker's feature map to the list that confirms the tracker's status. The list is updated after each match. Appearance features that have finished are removed, and the latest appearance features are retained. In the current frame, the cosine distance, shown in Eq. (2), is used to calculate the minimum distance between the feature vector tracked by the ith object and the jth object detection to determine their similarity:
d ( )1 (i j, ) = (dj –yi)T ×S–1i×(dj –yi) , (1) d ( )2 (i j, ) = min{1–γ Tj γ ( )ki γ k( )i ∈Ri} . (2)
  After the matching cascade process, SEMA uses the IOU match to solve the short-term occlusions. IOU is the overlap divided by the union of two objects, as illustrated in Fig. 6. This research matches the prediction box predicted by the Kalman filter of the current frame and the detection frame detected by YOLOv3 of the current frame to calculate the IOU between the current and unmatched detection frames. After using the Hungarian algorithm to match the track and detect, results than IOU are deleted to obtain a matched track, unmatched track, and unmatched detection. When the object is occluded for a short time, the occlusion object is detected, but the original object is not detected. It is assumed that the occlusion object and the original object are matched. After the occlusion is over, the IOU is larger because the objects have a similar size. Thus, the correct match can be quickly restored. Finally, the matched prediction box will be updated through the YOLOv3 detection box to perform the next tracking.
  The state is changed from unconfirmed to confirmed if the same object is tracked for five consecutive frames for the new tracking object. This means that the object is considered a new 

Fig. 6. Intersection over Union (IOU) Calculation
object by SEMA, an ID is assigned, and a tracker is added to track the object. Tracking the new object and checking the status can reduce the error rate of tracking the wrong object.
4.2.1.2 Highlight Video Extraction
After extracting the statistic information, tracking results are then utilized for highlight video extraction. This research defines keyframes as the video frames where the construction equipment enters or exits the construction site gate. For each frame, SEMA checks whether the equipment’s trajectory passes the detection lines. If it does, SEMA flags the frame as a keyframe. Meanwhile, SEMA stores the machineID of this frame and uses the frame as the center frame of the highlight video clip. Then, the five frames before and after that include the same machineID are added to complete the highlight video. Then, SEMA removes frames with the same frameID to avoid repeated keyframe extraction causing by the multiple equipment tracking. Lastly, SEMA combines all keyframes to generate the highlight video by following the sequence of the frameID and timestamp of each frame.
4.2.2 Extracting Information from Access Forms
To digitalize the paper-based access forms issued from the construction site, SEMA uses the text recognition method to extract the information so that the related personnel can review all the access forms issued from the site anytime and anywhere through mobile devices. The data acquisition module allows the user to scan the access form from their mobile devices. After obtaining the scanned access form, a text detector detects texts in the scanned form. This research utilized an Optical Character Recognition (OCR) method provided by LINE CLOVA. LINE CLOVA is an AI service provided by LINE, an instant messaging platform. It uses the public data and model to develop the OCR method so that developers can use it when developing a chatbot system (LINE Developer, 2021). After detection, both the image and detected text will be stored in the database. Users can query the extracted information or the scanned access forms through SEMA’s information delivery module.

Fig. 7. The Designed User Interface of SEMA
4.3 Information Delivery Module
A chatbot system was developed for delivering the extracted information. Users can query the site equipment-related information anytime and anywhere through their mobile devices with a chatbot system. The development of the information delivery module can be divided into two major parts: user interface design and user intent analysis mechanism. The user interface allows the user to access the information through clickable menus or buttons and typing natural languages. The user intent analysis mechanism analyzes the user intent by using Natural Language Processing (NLP) techniques.
4.3.1 SEMA User Interface Design
To deliver the extracted information from both site videos and scanned access forms, this research developed a chatbot system as the interface. The user interface can be divided into a data display panel, conversation panel, text input panel and clickable button panel (Fig. 7). 
4.3.1.1 Data Display Panel
The data display panel reveals the information queried by users. The chatbot can reply to the user with information, visual data, or other buttons for further actions.
4.3.1.2 Conversation Panel
The conversation panel shows the conversation process between users and the chatbot. It also shows the related keywords when the user clicks the buttons on the user interface to help the user get familiar with the precise keyword for each function.
4.3.1.3 Text Input Panel

Fig. 8. The Dataset of SEMA Contains Four Types of Machines: Concrete Mixer Truck, Excavator, Dump Truck and VehiclesThe text input panel allows the user to query for site-related information by entering the natural language. After the user enters text-based queries, SEMA’s user intent analysis mechanism will analyze the content and provides the user with the required information or further operations guidance to help the user obtain the information.
4.3.1.4 Clickable Button Panel
The clickable button contains functions that users may use, such as “Check the live streaming video” or “Get daily equipment report.”
4.3.2 User Intent Analysis Mechanism
To analyze the text input by users, this research developed a user intent analysis mechanism. A keyword mapping table is developed to provide all information and functions with related keywords. Then, a decision tree is designed to help SEMA determine what kinds of information or functions users are asking for when they use clickable buttons on the chatbot. Using the mapping table and decision tree allows the user to query the information by typing keywords or using clickable buttons.
5. Implementation
For implementation, this research used a general construction as the target area and LINE, a commercial instant messaging platform, to implement the proposed SEMA. Vehicles, dump trucks, excavators, and concrete mixer trucks were considered as recognition targets. To achieve recognition from the surveillance camera video in real-time, Python script and PostgreSQL were used. PostgreSQL was used to store the construction equipment and vehicle information, including the schedule, daily traffic flow, tracking result, and access form's data and image. The following subsections describe details of video information extraction and chatbot implementation.
5.1 Video Information Extraction
To perform the construction equipment detection function of SEMA, an annotated image dataset was first built. The image source of the dataset is from the Alberta Construction Image Dataset (ACID), an open dataset provided by University of Alberta (ACID, 2021). The dataset built in this research contains four different types of machines: concrete mixer truck, excavator, dump truck, and vehicles (Fig. 8). Besides ACID, this research also extracted images from the Visual Object Classes (VOC) dataset. The steps for making the dataset are as follows:
1. Collect the dump truck, excavator and concrete mixer trucks from the ACID dataset, a total of 5550 images, and collect the 1203 vehicle images from the VOC dataset for a dataset of 6753 images total.
2. Randomly extract 90% of the dataset to make training and validation sets.
3. Take 90% of the images from the training and validation 

Fig. 9. The VOC Dataset Structure
Fig. 10. Example of the Detection Results for Single Equipment

Fig. 11. Example of Detection Results for Multiple Types of Equipment in a Single Image
set as the training set.
4. Create a dataset according to the structure of the VOC dataset, which is illustrated in Fig. 9.
  SEMA used a detector to detect the construction equipment from the monitoring system installed on the construction site. Fig. 10 shows examples of SEMA’s detection results for single equipment. Besides, the detector can also detect multiple types of equipment in one image (Fig. 11). Information such as time, machine types, quantities was extracted from site videos and stored in a database (Figs. 12 and 13).
5.2 Chatbot Implementation
This research prototyped a rule-based chatbot on the LINE platform to realize the information delivery module of SEMA. The LINE Messenger API was used to link LINE with SEMA’s server. When users input text or clicking the clickable buttons, LINE Messenger API will send the user’s query to the SEMA server. The server will match the query with the keyword mapping table, then send related information back to the user through LINE Messenger API.
  The chatbot prototype contains six major functions: live stream video checking, daily report generating, schedule setting, highlight video checking, weekly report generating, and access form scanning. Users can check the live stream videos and highlight videos through live stream video checking and highlight video 


Fig. 12. SEMA Tracked and Extracted the Construction Equipment Information such as Through Time, Type, and Coordinate of Bounding Box

Fig. 13. SEMA Extracted the Information such as Type, Quantity, Through Time and Status by Detecting the Construction Equipment from the Videos

checking functions. Suppose the user wants to know how many machines and vehicles have entered the construction site. They can obtain related information by using daily report generating and weekly report generating functions. SEMA will also plot an infographic that visualizes the weekly traffic flow for each piece of construction equipment when the user uses the weekly report function. The schedule setting function allows the user to set the quantity of construction equipment that is planned to enter the site on a specific day. Lastly, the user can scan the paper-based access form by using the access form scanning function. SEMA will automatically extract related information after the user scans the access form.
  Six buttons representing the six major functions were built on the clickable button panel of the main user interface. The user can thus query information by clicking these buttons instead of typing texts. Besides the six functions, the prototyped chatbot also has a proactive notification mechanism that will automatically send notifications and information to the designated user (e.g., site manager) when machines enter or exit the construction site. The following subsections illustrate the operation procedures of SEMA’s six major functions and the proactive notification mechanism.
5.2.1 Live Stream Video Checking
As shown in Fig. 14, when users click the “Live Stream” button on the clickable panel or input the keyword, Live Stream, they can check the site videos to monitor the site in real-time. With 

Fig. 14. The User Operation Procedure of the Live Stream Checking Includes: (1) Click the “Live Stream” Button, (2) Click “Open the Stream Page” Button to Watch the Live Stream
this function, users can check multiple construction sites via SEMA without physically visiting each construction site.
5.2.2 Daily Report Generating

Fig. 15. The User Operation Procedure of the Daily Report Generating FunctionThe daily report generating function allows users to check the traffic flow of the specific construction equipment that enters and exits the construction site. The report also includes the quantity of the construction equipment supposed to enter the site to compare the current traffic flow and the scheduled one. The user operation procedure of the daily report generation function is shown in Fig. 15. To use this function, users can use the keyword “Daily Report” or click the “Daily Report” button to open this function. SEMA will automatically list different types of machines available in the system for the user to select. Then, users can choose the type of machine they want to obtain. After one type of machine is chosen, SEMA will collect the relevant information from the database and provide the information to the user as a new message.
5.2.3 Access Form Scanning
The access form scanning function contains two sub-functions: insert access form and browse scanned access forms. The user operation procedures for these two sub-functions are illustrated in Figs. 16 and 17. When users click the “Access Form” button or type the keyword, Access Form, SEMA will ask them to select whether they want to add a new access form or browse existing forms. If users select the former, SEMA guides the user to use the OCR function of the access form detection module. Alternatively, if users select to browse existing forms, they can browse the scanned forms (pictures) and extracted information of the existing access form in the database.
5.2.4 Weekly Report Generating
The weekly report generating function allows the user to check 


Fig. 16. The User Operation Procedure of Adding a New Access Form

Fig. 17. The User Operation Procedure of Browsing Existing Access Forms

Fig. 18. The User Operation Procedure of the Weekly Report Generating Function

Fig. 19. The User Operation Procedure of Highlight Video Checking Function

the number of different machines that enter the construction site in the past seven days. As shown in Fig. 18, the user can use the keyword, Weekly Report, or click the Weekly Report button to trigger this function. SEMA will ask the user what type of machine they want to check. Users can choose a specific type of construction equipment or all equipment present on the same report. SEMA will then obtain the quantity of construction equipment from the database to generate a visualized infographic in the past seven days. Lastly, the generated infographic will be sent to the user.
5.2.5 Highlight Video Checking
The highlight video checking function allows users to view the highlight video extracted from SEMA’s information extracting module. The user can click Highlight Video button or using the keyword, Highlight Video, to trigger this function. After triggering the function, a webpage will then be opened. The user can then review the highlight video of a specific date stored in the database on the webpage (Fig. 19).
5.2.6 Schedule Setting

Fig. 20. The User Operation Procedure of Setting the Schedule Includes: (1) Click the “Schedule Setting” Button, (2) Click “Setting the Schedule” Button, (3) Choose the Equipment Type, (4) Input the Corresponding Information by Following the Instruction Provided by SEMA, (5) Confirm the 
Information

Fig. 21. The User Operation Procedure of Modifying the Schedule Includes: (1) Click the “Schedule Setting” Button, (2) Click “Modify the Schedule” Button, (3) Choose the Equipment Type, (4) Input the Corresponding Information by Following the Instruction, (5) Confirm the Information

Fig. 22. The User Operation Procedure of Checking the Schedule Includes: (1) Click the “Schedule Setting” Button, (2) Click “Check the Schedule” 
Button, (3) Choose the Equipment Type, (4) Check the Relevant Information Provided by SEMAThe schedule setting function allows the user to set the quantity of different types of machines supposed to enter the construction sites. The function contains three sub-functions: set, modify, and check the machine schedule. The user operation procedures of 

Fig. 23. The Workflow of Proactive Notification Function
each sub-function are shown in Figs. 20, 21, and 22. When the user clicks the Schedule setting button or typing the keyword, Schedule setting, SEMA will ask whether the user wants to set/ modify/check the day's construction equipment schedule. After the user makes further choices, SEMA will then ask the user which type of construction equipment they want to set/modify/ check the schedule for. Finally, SEMA will let the user enter the corresponding information in a specific format to complete the schedule setting function.
5.2.7 Proactive Notification
SEMA will send notifications to related personnel (e.g., site managers) when machines enter or exit the construction site. These notifications can help managers to grasp the site information immediately. Fig. 23 shows the workflow of SEMA’s proactive notification mechanism. SEMA will first extract a single image from the stream video when machines enter or exit the construction site. Second, the information extracting module of SEMA will process the image to recognize what type of equipment is detected and labelled the recognition result on the image. Then, the image will be uploaded to Imgur. Lastly, LINE Message API is used to send the labelled image as a new message to the user proactively.
6. Validation
This research conducted a system evaluation to test the precision and performance of SEMA’s information extracting module and usability to verify SEMA’s effectiveness in construction site equipment management. This research used 10% of the dataset as the validation set for the system evaluation, which was not used in the training set. For the usability test, this research designed five tasks and recured seven users, who are master students with civil engineering backgrounds, to test whether SEMA can help improve construction site equipment management efficiency.
6.1 System Evaluation
For system evaluation, this research used the confusion matrix with precision, recall, and mean average precision (mAP) as evaluation metrics to test the precision and performance of the construction equipment tracking module in SEMA. Precision signifies the fraction of relevant instances and the instances retrieved. Recall is the fraction of the total number of relevant instances which have been retrieved. The F1-score is the harmonic mean of precision and recall. These are calculated as follows:
	True Positive TP(	)
	Precision = ----------------------------------------------------------------------------------------------------- ,	(3)
	True  Positive+False Positive TP+FP(	)
	True Positive TP(	)
	Recall = ------------------------------------------------------------------------------------------------------- ,	(4)
	True Positive+False Negative TP+FN(	)
Precision×Recall
F1–score = 2×--------------------------------------------- ,	(5) Precision+Recall
where True Positive (TP) indicates the number of times, SEMA detects the correct construction equipment, True Negative (TN) indicates the number of times SEMA does not detect an unnecessary detection object, False Positive (FP) indicates the number of times SEMA categorizes unnecessary objects as relevant construction equipment. False Negative (FN) indicates the number of times the loss of the construction equipment was not detected. According to the requirements of PASCAL VOC object detection challenges, Average Precision (AP) is calculated according to the area under the precision-recall curve. Mean Average Precision (mAP) is the average of all kinds of accuracy based on IOU = 0.5.
  The mAP of vehicle, dump truck, concrete mixer trucks, and excavator are 67.16%, 87.87%, 96.12%, and 97.43%. The average detection speed of SEMA is 43.6 frames per second. The mean precision, recall, and F1-score are 97%, 69%, and 81%. These results show that SEMA can recognize and track the construction equipment effectively. However, the detection capability of the vehicle was not highly accurate. This is because the dataset did not have sufficient data for vehicles. Moreover, the VOC dataset does not include sufficient vehicle data from the night and rainy days, resulting in a much lower recognition of the vehicle during rain and at night.
6.2 In-lab Usability Test
To evaluate the effectiveness and efficiency of the integrated system, an in-lab usability test was conducted. Six master students with civil engineering backgrounds were recruited as test subjects. All subjects were asked to conduct five different tasks using the traditional paper-based method and SEMA’s chatbot prototype. The time that each subject spent on each method and the correct rate were recorded for further comparison. Lastly, all subjects were asked to provide comments and their operation experience for SEMA.
6.2.1 Test Design
The usability test was divided into three parts. First, the examiner will introduce SEMA’s features and the basic operations. This research used a construction site located in the urban area in Taiwan for the test. Videos from the surveillance camera installed at the entrance of the site were used as data resources. Also, hard copies of the construction equipment information, including the date, time, driver’s name, type of machine, and reason to enter the site, were provided. During the test, subjects were asked to conduct five tasks using both the paper-based method and SEMA. The five tasks are
1. Count the number of the dump trucks that entered on a particular day.
2. Find the driver’s name when the construction equipment entered the construction site at 12:55 p.m.
3. Count the number of each type of construction equipment in a particular week.
4. Count the number of each type of construction equipment in a particular day and compare the results with the schedule to check the alignment with expected progress.
5. Find the highlight clip from the site video.
  These five tasks all have correct answers so that the correct rate for both methods can be compared. Finally, after the subjects 
Table 1. Results of Using Paper-Based Method
completed the five tasks, they will be asked to provide the disadvantages of both methods and suggestions to SEMA.
6.2.2 Test Results
Tables 1 and 2 list the test results of the usability test. Subjects spent an average of 19.6 minutes completing all tasks by using the paper-based method. An average of 7.7 minutes was spent by using SEMA. It shows that SEMA can increase management efficiency by 60.7%. For the correct rate, using the paper-based method, the average correct rates of tasks in order were 83%, 100%, 78%, 94%. Using SEMA, the average correct rates were 100%, 100%, 100%, 100%, 92%. These results showed that SEMA could help increase the correct rate for the management task, especially when analyzing the data with long durations (e.g., daily and weekly).
  Results of the paper-based method showed that most subjects need to spend much more time completing tasks 3 and 5, where the content of the task is related to the video and weekly data. According to participant feedback, using paperwork to record the construction equipment data is hard to store. Hard copies lead to inefficiency in counting the construction equipment quantities, viewing specific information, and increasing error rates.
Correct 
Task
	Subject A	Subject B	Subject C	Subject D	Subject E	Subject F	Ave.	Rate (%)
143331933214632.58328222119131716.71003211488210253188307276.278445686354233147.310054536026736186811,803805.094Total (secs)7601,2139869779262,2041,177.7-Total (mins)12.720.216.416.315.436.719.6-Table 2. Results of Using SEMAOperation Time (secs)
Ave.
1 18	10	13	17	13	31	17.0	100
2 30	30	34	25	26	45	31.7	100
3 64	74	58	47	74	65	63.7	100 4	41	105	54	27	22	33	47.0	100
5	453	272	244	327	217	285	299.7	92
Total (secs) 606 491 403 443 352 459 459.0 Total (mins) 10.1 8.2 6.7 7.4 5.9 7.7 7.7 -
  Results of using SEMA showed that only the operation time for task 2 was longer than using the paper-based method. By observing the participant’s operation of the chatbot, we found that this was because the subjects were not familiar with the interface and features of the keyword and clickable button. Additionally, like the paper-based method, the participants also spent much more time completing task 5. It was because they 
needed to pause the video to record the information and the mobile device screen is too small. As each highlight clip is very short, subjects need to rewind the video for additional viewings. 
  This research also recorded the user experience and suggestions to operate the chatbot from all participants. These experiences and suggestions had four main themes:
1. The highlight video clip was too short for users to view the complete process. Participants suggested the chatbot could increase the number of frames in the clip to increase completeness to support recording the information.
2. The mobile device screen is not as big as a personal computer. If the reply message is not clear enough, it will cause the data to look messy, and some information may be lost.
3. If a user wants to obtain all types of construction equipment information, there might be wasted time by repeating requests and operations. Therefore, participants suggested the chatbot could include a feature of integrated similarity information of all construction equipment.
4. After the overall operation was complete, the participants judged that SEMA saved significant time to query or record relevant information, and the SEMA interface is user-friendly and easy to use.
7. Discussions
This study developed a construction site equipment management system to reduce the time cost associated with manually recording and retrieving information related to construction equipment entering and exiting the construction gate. The precision of the recognition model and the usability test verified that SEMA could effectively increase the efficiency of site equipment management. By providing a chatbot interface, SEMA allows users to obtain the required information more efficiently and intuitively. The following subsections discuss the contributions, future works, and potential applications of SEMA.
7.1 Contributions
This research proposed a construction site equipment management method by integrating technologies from data processing, information extraction, to information delivery. The major contributions of this research are
1. Development of a complete site equipment management system. This research developed a site equipment management system containing data acquisition, information extraction, and information delivery. The system integrates deep learning and image recognition technologies to process raw videos from the construction site automatically. Additionally, the chatbot was used to provide relevant information to users anytime and anywhere. 
2. Evaluate the feasibility of using an integrated system for construction site management. Through an in-lab usability test, SEMA has been validated to improve the site equipment management’s efficiency with a high correct rate. It can increase the management efficiency by 60.7% compared to the traditional paper-based method.
3. Development of a new information management method for the construction industry. This research proposed a new information management method by integrating deep learning, image processing, and chatbot technologies and used site equipment management as the case example. By replacing the dataset, the system architecture is expected to be further adapted to other applications for construction management, such as productivity monitoring, material management, etc.
7.2 Future Works
Although SEMA can effectively help users improve the efficiency of monitoring and managing construction site equipment information, there are still five aspects that require improvement in the future studies.
1. Development of a comprehensive recognition model. The current dataset of SEMA only contains four types of construction machines. It is required for SEMA to include more types of objects to make the training model more comprehensive.
2. Modification of highlight video extraction. The results of the useability test revealed that the current highlight video clips were too short. The short clips made users hard to review, especially when using mobile devices. Also, some images that contain useful information might be filtered out by using the current method. Therefore, this research will modify the highlight video extraction method to increase the correct rate of keyframe extraction.
3. Improvement of the intent analysis mechanism. SEMA uses a rule-based chatbot with a decision tree and keyword mapping table to match information with the user intent. Technologies such as Natural Language Processing (NLP) will be added to the intent analysis mechanism of SEMA to allow users to query information by typing plain texts.
4. Notifications of abnormal situations. SEMA’s database, which stores all the construction equipment, provides an opportunity to train a machine learning model for identifying the abnormal situation. Future work will focus on developing a machine learning method to identify abnormal situations based on the collected data automatically. By adding this feature, SEMA can use its proactive notification mechanism to send notifications to related users when an abnormal situation happens. The user can thus make a judgement immediately.
5. In-field evaluation and new system implementation framework. This research conducted an in-lab usability test for the efficiency and effectiveness of the integrated system. However, in-field tests with different site conditions and site managers should be conducted to evaluate if the system is effective in different sites. Also, an implementation framework should be developed to help site managers utilize new systems in their daily works (Tsai et al., 2021).
8. Conclusions
This research developed a construction site equipment management system named SEMA. Technologies of image recognition, multiple object tracking and a rule-based chatbot are used to integrate the management process from data acquisition, information extraction to information delivery. To validate the performance and usability of SEMA, a system evaluation test and a usability test were conducted. Results of the system evaluation showed that SEMA has sufficiently high performance to process raw video footages collected from the construction site automatically. The usability test results revealed that SEMA could increase the efficiency of the management task by 60.7% compared to the traditional paper-based method. In conclusion, this research developed a construction site equipment management assistant that can automatically extract useful information from numerous video footage data and interact with users through a chatbot interface. This system has been proven to improve the time-consuming and labour-intensive issues of the site equipment management process.
Acknowledgments
Not Applicable
ORCID
Meng-Han Tsai  https://orcid.org/0000-0002-2466-6152
Cheng-Hsuan Yang  https://orcid.org/0000-0001-7907-6590
Chen-Hsuan Wang  https://orcid.org/0000-0001-8188-3666 I-Tung Yang  https://orcid.org/0000-0003-4905-6657
Shih-Chung Kang  https://orcid.org/0000-0001-9944-0820
References
Abeid J, Allouche E, Arditi D, Hayman M (2003) PHOTO-NET II: A computer-based monitoring system applied to project management. 
Automation in Construction 12(5):603-616, DOI: 10.1016/S0926-
5805(03)00042-6
ACID (2021) Alberta Construction Image Dataset, Retrieved May 29, 2021, https://www.acidb.ca/
Alavi AH, Gandomi AH (2017) Big data in civil engineering. Automation in Construction 79:1-2, DOI: 10.1016/j.autcon.2016.12.008
Bewley A, Ge Z, Ott L, Ramos F, Upcroft B (2016) Simple online and realtime tracking. 2016 IEEE international conference on image processing (ICIP), September 25-28, Phoenix, AZ, USA, DOI: 10.1109/ICIP.2016.7533003
Brilakis I, Park MW, Jog G (2011) Automated vision tracking of project related entities. Advanced Engineering Informatics 25(4):713-724, DOI: 10.1016/j.aei.2011.01.003
Chae S, Yoshida T (2010) Application of RFID technology to prevention of collision accident with heavy equipment. Automation in Construction
19(3):368-374, DOI: 10.1016/j.autcon.2009.12.008
Chan HY, Tsai MH (2019) Question-answering dialogue system for emergency operations. International Journal of Disaster Risk Reduction
41:101313, DOI: 10.1016/j.ijdrr.2019.101313
Chen KL, Tsai MH (2021) Conversation-based information delivery method for facility management. Sensors 21(14):2771, DOI: 10.3390/ s21144771
Chi S, Caldas CH (2011) Automated object identification using optical video cameras on construction sites. Computer-Aided Civil and Infrastructure Engineering 26(5):368-380, DOI: 10.1111/j.1467-
8667.2010.00690.x
Chiaráin NN, Chasaide AN (2016) Chatbot technology with synthetic voices in the acquisition of an endangered language: Motivation, development and evaluation of a platform for Irish. 10th international conference on language resources and evaluation, May 23-28, Portorož, Slovenia
Choa J, Ghang L (2019) A chatbot system for construction daily report information management. Proceedings of the 36th ISARC, May 
21-24, Banff, AB, Canada, 429-437, DOI: 10.22260/ISARC2019/
0058
Deng ZM, Li H, Tam CM, Shen QP, Love PED (2001) An application of the internet-based project management system. Automation in Construction 10(2):239-246, DOI: 10.1016/S0926-5805(99)00037-0
Elghamrawy T, Boukamp F (2010) Managing construction information using RFID-based semantic contexts. Automation in Construction
19(8):1056-1066, DOI: 10.1016/j.autcon.2010.07.015
Ergen E, Akinci B, Sacks R (2007) Tracking and locating components in a precast storage yard utilizing radio frequency identification technology and GPS. Automation in Construction 16(3):354-367, DOI: 10.1016/j.autcon.2006.07.004
Golparvar-Fard M, Heydarian A, Niebles JC (2013) Vision-based action recognition of earthmoving equipment using spatio-temporal features and support vector machine classifiers. Advanced Engineering Informatics 27(4):652-663, DOI: 10.1016/j.aei.2013.09.001
Golparvar-Fard M, Peña-Mora F, Savarese S (2015) Automated progress monitoring using unordered daily construction photographs and IFC-based building information models. Journal of Computing in 
Civil Engineering 29(1):04014025, DOI: 10.1061/(ASCE)CP.1943-
5487.0000205
Gong J, Caldas CH (2011) An object recognition, tracking, and contextual reasoning-based video interpretation method for rapid productivity analysis of construction operations. Automation in Construction
20(8):1211-1226, DOI: 10.1016/j.autcon.2011.05.005
Goodrum PM, McLaren MA, Durfee A (2006) The application of active radio frequency identification technology for tool tracking on construction job sites. Automation in Construction 15(3):292-302, DOI: 10.1016/j.autcon.2005.06.004
Han SU, Lee SH (2013) A vision-based motion capture and recognition framework for behavior-based safety management. Automation in Construction 35:131-141, DOI: 10.1016/j.autcon.2013.05.001
Han SU, Lee SH, Peña-Mora F (2014) Comparative study of motion features for similarity-based modeling and classification of unsafe actions in construction. Journal of Computing in Civil Engineering
28(5):A4014005, DOI: 10.1061/(ASCE)CP.1943-5487.0000339
Heydarian A, Golparvar-Fard M, Niebles JC (2012) Automated visual recognition of construction equipment actions using spatio-temporal features and multiple binary support vector machines. Construction research congress 2012, May 21-23, West Lafayette, IN, USA, 889-898,
DOI: 10.1061/9780784412329.090
Hui L, Park MW, Brilakis I (2015) Automated brick counting for façade construction progress estimation. Journal of Computing in Civil 
Engineering 29(6):04014091, DOI: 10.1061/(ASCE)CP.1943-
5487.0000423
Jaselskis EJ, El-Misalami T (2003) Implementing radio frequency identification in the construction process. Journal of Construction Engineering and Management 129(6):680-688, DOI: 10.1061/ (ASCE)0733-9364(2003)129:6(680)
Katz I, Saidi K, Lytle A (2008) The role of camera networks in construction automation. Proceedings of 25th international symposium on automation and robotics in construction, June 26-29, Vilnius, Lithuania, DOI: 10.22260/ISARC2008/0049
Kim H, Kim K, Kim K (2016) Vision-based object-centric safety assessment using fuzzy inference: Monitoring struck-by accidents with moving objects. Journal of Computing in Civil Engineering 30(4):04015075, DOI: 10.1061/(ASCE)CP.1943-5487.0000562
Kosugi M, Uchida O (2019) Chatbot application for sharing disasterinformation. 2019 international conference on information and communication technologies for disaster management (ICT-DM), December 18-20, Paris, France, DOI: 10.1109/ICT-DM47966.2019. 9032901
Li H, Chen Z, Wong CTC (2003) Barcode technology for an incentive reward program to reduce construction wastes. Computer-Aided 
Civil and Infrastructure Engineering 18(4):313-324, DOI: 10.1111/ 1467-8667.00320
LINE Developer (2021) LINE CLOVA, Retrieved May 29, 2021, https:/ /developers.line.biz/en/services/line-clova/ 
Liu CW, Wu TH, Tsai MH, Kang SC (2018) Image-based semantic construction reconstruction. Automation in Construction 90:67-78, DOI: 10.1016/j.autcon.2018.02.016
Lu M, Chen W, Shen X, Lam HC, Liu J (2007) Positioning and tracking construction vehicles in highly dense urban areas and building construction sites. Automation in Construction 16(5):647-656, DOI: 10.1016/j.autcon.2006.11.001
Muslih M, Somantri, Supardi D, Multipi E, Nyaman YM, Rismawan R, Gunawansyah (2018) Developing smart workspace based IoT with artificial intelligence using telegram chatbot. 2018 international conference on computing, engineering, and design (ICCED), September
6-8, Bangkok, Thailand, DOI: 10.1109/ICCED.2018.00052
Oh SW, Chang HJ, Kim YS, Lee JB, Kim HS (2004) An application of pda and barcode technology for the improvement of information management in construction projects. Proceedings of the 21st ISARC, September 21-25, Jeju, Korea, DOI: 10.22260/ISARC2004/0090
Oh KJ, Lee D, Ko B, Choi HJ (2017) A chatbot for psychiatric counseling in mental healthcare service based on emotional dialogue analysis and sentence generation. 2017 18th IEEE international conference on mobile data management (MDM), May 29-June 1, 
Daejeon, Korea, DOI: 10.1109/MDM.2017.64
Oloufa AA, Ikeda M, Oda H (2003) Situational awareness of construction equipment using GPS, wireless and web technologies. Automation in Construction 12(6):737-748, DOI: 10.1016/S0926-5805(03)00057-8
Park MW, Brilakis I (2012) Construction worker detection in video frames for initializing vision trackers. Automation in Construction
28:15-25, DOI: 10.1016/j.autcon.2012.06.001
Park MW, Elsafty N, Zhu Z (2015) Hardhat-wearing detection for enhancing on-site safety of construction workers. Journal of Construction 
Engineering and Management 141(9):04015024, DOI: 10.1061/
(ASCE)CO.1943-7862.0000974
Rashidi A, Sigari MH, Maghiar M, Citrin D (2016) An analogy between various machine-learning techniques for detecting construction materials in digital images. KSCE Journal of Civil Engineering 20(5):1178-1188, DOI: 10.1007/s12205-015-0726-0
Redmon J, Farhadi A (2018) YOLOv3: An incremental improvement. arXiv:1804.02767
Ren X, Zhu Z, Germain C, Dean B, Chen Z (2015) A case study of construction equipment recognition from time-lapse site videos under low ambient illuminations. 2015 international workshop on computing in civil engineering, June 21-23, Austin, TX, USA, 82-89, DOI: 10.1061/9780784479247.011
Shawar BA, Atwell ES (2005) Using corpora in machine-learning chatbot systems. International Journal of Corpus Linguistics 10(4):489-
516, DOI: 10.1075/ijcl.10.4.06sha
Slaton T, Hernandez C, Akhavian R (2020) Construction activity recognition with convolutional recurrent networks. Automation in Construction 113:103138, DOI: 10.1016/j.autcon.2020.103138
Son H, Kim C, Hwang N, Kim C, Kang Y (2014) Classification of major construction materials in construction environments using ensemble classifiers. Advanced Engineering Informatics 28(1):1-10, DOI: 10.1016/j.aei.2013.10.001
Tajeen H, Zhu Z (2014) Image dataset development for measuring construction equipment recognition performance. Automation in Construction 48:1-10, DOI: 10.1016/j.autcon.2014.07.006
Teizer J, Allread BS, Fullerton CE, Hinze J (2010) Autonomous proactive real-time construction worker and equipment operator proximity safety alert system. Automation in Construction 19(5):630-640, DOI: 10.1016/j.autcon.2010.02.009
Teizer J, Vela PA (2009) Personnel tracking on construction sites using video cameras. Advanced Engineering Informatics 23(4):452-462, DOI: 10.1016/j.aei.2009.06.011
Teizer J, Venugopal M, Walia A (2008) Ultrawideband for automated real-time three-dimensional location sensing for workforce, equipment, and material positioning and tracking. Transportation Research Record 2081(1):56-64, DOI: 10.3141/2081-06
Tsai MH, Chen JY, Kang SC (2019) Ask Diana: A keyword-based chatbot system for water-related disaster management. Water 11(2): 234, DOI: 10.3390/w11020234
Tsai MH, Yang CH, Chen JY, Kang SC (2021) Four-stage framework for implementing a chatbot system in disaster emergency operation data management: A flood disaster management case study. KSCE 
Journal of Civil Engineering 25(2):503-515, DOI: 10.1007/s12205-
020-2044-4
Turkan Y, Bosche F, Haas CT, Haas R (2012) Automated progress tracking using 4D schedule and 3D sensing technologies. Automation in Construction 22:414-421, DOI: 10.1016/j.autcon.2011.10.003
Vegesna A, Jain P, Porwal D (2018) Ontology based chatbot (for Ecommerce website). International Journal of Computer Applications
179(14):51-55, DOI: 10.5120/ijca2018916215
Wojke N, Bewley A, Paulus D (2017) Simple online and realtime tracking with a deep association metric. arXiv:1703.07402
Yang J, Cheng T, Teizer J, Vela PA, Shi ZK (2011) A performance evaluation of vision and radio frequency tracking methods for interacting workforce. Advanced Engineering Informatics 25(4):736-
747, DOI: 10.1016/j.aei.2011.04.001
Yang J, Shi Z, Wu Z (2016) Vision-based action recognition of construction workers using dense trajectories. Advanced Engineering Informatics
30(3):327-336, DOI: 10.1016/j.aei.2016.04.009
1146 M.-H. Tsai et al.

KSCE Journal of Civil Engineering 1145



