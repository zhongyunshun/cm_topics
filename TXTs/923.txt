
The Delphi Method: Review and Use in Construction
Management Research
Amr Sourani & M. Sohail
To cite this article: Amr Sourani & M. Sohail (2015) The Delphi Method: Review and Use in
Construction Management Research, International Journal of Construction Education and
Research, 11:1, 54-76, DOI: 10.1080/15578771.2014.917132
To link to this article:  https://doi.org/10.1080/15578771.2014.917132

Full Terms & Conditions of access and use can be found at https://www.tandfonline.com/action/journalInformation?journalCode=uice20

International Journal of Construction Education and Research, 11:54–76, 2015
Copyright © Associated Schools of Construction
ISSN: 1557-8771 print/1550-3984 online
DOI: 10.1080/15578771.2014.917132
The Delphi Method: Review and Use in Construction Management Research
AMR SOURANI, BSc, MSc, PH.D., Fellow HEA
Liverpool John Moores University, Liverpool, United Kingdom
M. SOHAIL, BEng, MSc, PH.D., Fellow ASCE
Loughborough University, Loughborough, United Kingdom
The Delphi Method is a systematic procedure that is normally employed to achieve a reliable consensus among a selected panel of experts. It can be utilized for different purposes, such as the study or definition of areas of considerable uncertainty and/or a lack of agreed knowledge. Although the method has been used in different fields, few studies have used Delphi in construction research. This could be attributed to the limited awareness of the method, the lack of clear guidance in relation to its operation and the variations in its application. This article, which draws on a review and synthesis of the relevant literature and the authors’ observation and experience of applying the method, critically reviews Delphi, provides guidance into its use, discusses such use in construction management research and demonstrates it through a case study. Furthermore, the article addresses the learning areas/benefits that could be obtained as a result of employing Delphi in students’ research projects through another case study. Such learning areas/benefits could include deep learning; knowledge generation; criticality; skills development; feedback; development of identity and career plans; simultaneous learning and application of research approaches and self-validation; and flexibility, diversity, and efficiency issues.
	Keywords	construction, Delphi, construction, learning, research, review
Background
The Delphi Method is a systematic procedure to evoke expert opinion. Its intended outcome is to achieve a reliable consensus of opinion among a selected panel of experts. Usually, Delphi is conducted through a series of questionnaires. The panel members remain unknown to each other and their interaction is managed in a totally anonymous way (Martino, 1983; Robinson, 1991). Following each round, the responses are analyzed, and based on the analysis, a new questionnaire is developed and sent to the panel members in the next round. The iterative nature of the method enables providing the members with feedback involving new information in each round. They, therefore, are able to reconsider the information they provided in previous rounds in light of the overall results (Procter and Hunt, 1994). Such a process continues for a pre-determined number of rounds or until some
    Address correspondence to Amr Sourani, School of the Built Environment, Liverpool John Moores University, Liverpool, United Kingdom. E-mail: a.sourani@ljmu.ac.uk
54

Figure 1. The Delphi process.
predetermined criterion has been met, e.g. reaching consensus (Robinson, 1991; Mullen, 2003), as illustrated in Figure 1.
    Most of the articles which considered the use of Delphi show that the technique is conducted using questionnaires. Some writers however have either referred to the possibility of conducting Delphi using interviews or used interviews within their Delphi studies e.g. Bendaña et al. (2008), de la Cruz et al. (2008) and Lucko and Rojas (2010). The literature offers little guidance on the nature of the interviews that may be used within Delphi, particularly with regards to their level of structure. However, there are examples in the literature on the use of Delphi with structured and semi-structured interviews e.g. Gombera (2003) and Che Senik (2010). It has also been observed that some authors used a combination of methods in the same study e.g. Smith et al. (2011).
Contribution to Knowledge
In construction related research, there has been a limited number of studies utilizing Delphi. Based on critical review of the literature, discussions with researchers in construction management and experience in applying the method, the authors observed that the limited awareness of Delphi and the lack of clear guidance in the literature in relation to how it operates could be among the contributing factors to the limited use of Delphi in construction management research. Hallowell and Gambatese (2010) argued that the Delphi Method has not seen a widespread use in construction engineering and management research and noticed significant variations among the studies which used Delphi regarding methodological approaches and quality; clear guidance on Delphi was needed for several reasons, including misconception concerning appropriate procedures, the variability among construction related applications and the lack of specific guidance in literature.
This provides the basis for contributions (1) and (2), shown below. In addition, it has been found that a number of publications have considered the benefits (particularly the learning benefits) of undertaking research projects. Among these are Race (2001), Ryder (2004), Seymour and colleagues (2004), Healey (2005), Hunter and colleagues (2006), Robertson and Blacker (2006), Beckman and Hensel (2009), Healey and Jenkins (2009), and Rueckert (2012). No study however has been undertaken to identify whether the employment of a particular research method/technique supports these benefits. This provides the basis for contribution (3). This article aims to cover the knowledge gaps outlined above. In particular, the article contributes to knowledge through attempting to:
1. Synthesize the available literature in Delphi, providing a comprehensive and consistentguidance on areas related to the use of Delphi where little guidance has been available (e.g., in relation to discussing the position of Delphi within the qualitative/quantitative debate and clarifying the level of structure adopted on commencing a Delphi Study)
2. Illustrate the issues outlined in (1) through a case study that has employed Delphi
3. Provide insights into the learning benefits that could be obtained as a result of employingDelphi in students’ research projects using a second case study.
Characteristics of Delphi
Anonymity
Interaction within Delphi is managed in a totally anonymous way. This does not only assist participants in changing opinions without publicly disclosing doing so, but also facilitates the examination of any considerations based on their value alone, minimises the negative impacts of using committees such as group pressure, status, and dominancy of powerful personalities and provides little chance to win support for certain views at the expense of reaching a valid conclusion (Martino, 1983; Mullen, 2003). However, anonymity has its drawbacks, such as the lack of accountability for views expressed by Delphi members where the participants’ names are not disclosed, limiting the boundaries of exploratory thinking, and eliminating the stimulation and generation of ideas (Mullen, 2003).
Iteration with Controlled Feedback
Normally, Delphi is conducted through a series of questionnaires spreading over consecutive rounds. In each round, participants are provided with feedback that involves new information and expresses the group collective opinion. A controlled feedback enables focusing on the objectives of Delphi rather than concentrating on winning the argument by certain participants (Martino, 1983). Furthermore, it could reduce the tendency of participants to reach an agreement at the expense of producing a useful opinion.
Statistical Group Response
Statistical group response commonly represents the group opinion and may involve an indication of the opinion variation within the group (e.g., the median complemented with minima, maxima, quartiles, and/or the inter-quartile range; or the mean accompanied with standard deviation (SD) and/or range). Some studies may utilize frequency distributions to report a statistical group response.
Use of Delphi
According to Mullen (2003), while some publications hailed Delphi as well known, popular, and well-established management technique, other publications entailed that Delphi was not widely known. Padel and Midmore (2005) noticed that the use of Delphi in applied social science was not widely spread, as the method was less well known among researchers in comparison with other methods, but stated that recent use of Delphi had been widespread, especially in health and education topics. Bradley and Stewart (2002) showed that the Delphi Method had been used in many areas ranging from medical research to business issues. Gupta and Clarke (1996) found applications of Delphi in a large number of domains including academia, administration, agriculture, automotive, banking, criminal justice, economics, education, environmental studies, finance, health care, housing, insurance, management, real estate, sales, strategic planning, tourism, training, transportation, and utilities. Delphi could be used for any purpose requiring the use of committees (Martino, 1983). In particular, Delphi can be useful to employ when there is a need to (Linstone & Turoff, 1975; Robinson, 1991; Hinks & McNay, 1999; Bradley & Stewart, 2002; Orndoff, 2005; Padel & Midmore, 2005; Bendaña et al., 2008; Yeung et al., 2009; Lucko & Rojas, 2010):
• obtain accurate information that is unavailable or expensive to obtain
• handle complex problems that require more judgemental analysis
• study or define areas where there is considerable uncertainty and/or a lack of agreed knowledge or disagreement
• allow for combining fragmentary perspectives into a collective understanding
• model a real world phenomena involving a range of viewpoints and for whichthere is little established quantitative evidence
• highlight topics of concern and assess uncertainty in a quantitative manner.
The Position of Delphi within the Qualitative/Quantitative Debate
Despite sharing some features with traditional quantitative techniques such as questionnaire surveys, Delphi has rather been viewed as a qualitative tool by several authors, e.g., Feret and Marcinek (1999), MacCarthy and Atthirawong (2003), Henchion and Mclntyre (2005), and Padel and Midmore (2005). However, Delphi has the potential to produce quantitative or semi-quantitative data. Critcher and Gladstone (1998) entail that Delphi occupies a position close to a constructionist approach and also has the potential to generate quantified results within a positivist tradition. Such an argument refers to the “hybrid” status of Delphi, which extends across the boundary between qualitative and quantitative approaches. Despite this, there is a wide agreement on the qualitative nature of the method. It is probably this position of Delphi that could limit the extent to which the method can be utilized within a quantitative approach. Understanding such a position may be crucial if Delphi is to be criticized for not following procedures conventionally adopted within a quantitative approach. Mullen (2003, p. 40) argue that “it is apparent that many relatively recent criticisms of Delphi and attempts to prescribe the correct approach stem from the positivist critique.” It is also this position of Delphi, however, which provides the technique with advantages over other quantitative approaches. Compared to questionnaire surveys, Delphi offers better interaction with respondents and could potentially provide more understanding of complex problems (MacCarthy & Atthirawong, 2003; Mullen, 2003).
The Level of Structure Adopted on Commencing a Delphi Study
Many Delphi studies commence with a structure consistent with the position of Delphi within the qualitative/quantitative debate. According to Linstone and Turoff (1975, p. 5), the first phase in Delphi is characterised by “exploration of the subject under discussion wherein each individual contributes additional information he feels is pertinent to the issue.” In line with the “exploratory” nature of the first round is the argument made by several authors concerning the need to have open-ended questions in the first round, or, at least, provide the respondents with the opportunity to identify issues that are important or relevant to the study. Mullen (2003, p. 44) found that, according to some commentators, “the first round must be open-ended inviting the panellists to identify, as appropriate to the study, issues, forecasts and views etc.” and suggested that the use of an open-ended first round has been used to judge whether a study is well-conducted. Many Delphi studies have been found using this type of questions in the first round. Examples include Shon and Swatman (1998), Feret and Marcinek (1999), Scholl and colleagues (2004), Padel and Midmore (2005) and Yeung and colleagues (2009). In some cases, authors have been found accompanying the open-ended questions with a list of issues found in the literature; this could assist the respondents in answering the questions but should not prevent them from generating ideas and forming views. For example, in the first round of the study by Chan and colleagues (2001), respondents were asked to provide at least five major criteria influencing the selection of a procurement system in Hong Kong. This was accompanied by a list of criteria found in the literature for the experts’ reference. Some authors, however, have been found commencing their studies with a more structured first round questionnaire by using closed-ended questions (e.g., questions utilizing a Likert-type scale). Examples include Hinks and McNay (1999), Khosrow-Pour and Herman (2001), and Bradley and Stewart (2002).
Selection of Experts
In general, Delphi studies use different sizes of panels. According to Weidman and colleagues (2011), the literature has not specified the number of experts needed for a Delphi study. However, it is recognized that a minimum appropriate size would include seven or eight experts. Mitchell and McGoldrick (1994) argued that the size of the panel may be as large as time and money considerations will permit but should be no less than 8 to 10 members. While Hallowell and Gambatese (2010) indicated that most studies incorporated eight to sixteen experts and suggested a minimum of eight, they argued that the specific number should be determined by the study characteristics (e.g., the number of available experts, the desired geographic representation and the capability of the facilitator) and highlighted the importance of having a sufficient number of experts at the end of the Delphi process and the need to consider this in light of the possibility of drop out by some experts. Maintaining high level of response is one of the major difficulties in Delphi, according to Yeung and colleagues (2009).
    Experts are expected to know more about the subject of study than do others. In broad terms, an expert may be defined as “someone who has a special knowledge about specific subject” (Martino, 1983, p. 27). Hallowell and Gambatese (2010) highlighted two studies that provided guidance for qualifying experts and argued that the requirements mentioned in both studies were dissimilar and vague. Knowledge is perhaps the key criterion for selecting an expert to participate in a Delphi panel. Criteria such as willingness and availability are important to consider (Martino, 1983; Robinson, 1991); however, they may be considered secondary to knowledge or degree of expertness as indicated by Martino. But how could such “knowledge” be established? Some authors highlighted what could be regarded as indicators of knowledge including (Martino, 1983; Shon and Swatman, 1998; Khosrow-Pour and Herman, 2001; Cabanis, 2002; Rogers and Lopez, 2002; Mullen, 2003; Scholl et al., 2004 Henchion and McIntyre, 2005; Hallowell and Gambatese, 2010): publications in the field; signs of professionals eminence such as leadership, membership, or holding office in a professional society or organization; peer judgment and recommendations; honours by professional societies; self-rating of expertise; presentations made at national conventions; relevant years of experience; selection for comment by media; patents held; and faculty membership at an institute of higher learning.
    Many Delphi authors share the view that Delphi does not lend itself to random sampling techniques. Such views seem to be consistent with epistemological positions considering Delphi as a rather qualitative approach. But if random sampling is not the right approach, how should experts be selected? In addition to referring to criteria such as knowledge, availability and willingness, many Delphi authors tend to choose experts from a variety of backgrounds and positions so that the key viewpoints on the topic are represented (Robinson, 1991; Hinks and McNay, 1999; Chan et al., 2001; Scholl et al., 2004; Henchion and Mclntyre, 2005; Bendaña et al., 2008; Yeung et al., 2009). Where a pool of experts emerges from the application of such parameters, random sampling could be adopted to choose pre-qualified experts from this pool. For example, in the studies by Burr and Jones (2010) and Weidman and colleagues (2011), experts were randomly selected from a list involving pre-qualified experts who were chosen based on their expertise.
Number of Rounds
The number of rounds used in Delphi studies varies among these studies. Furthermore, there is no clear agreement in the literature on what determines this number. For example, Yeung and colleagues (2009) observed that such a number varied between two and seven. Lucko and Rojas (2010) showed that Delphi studies involved at least two iterations. Gunhan and Arditi (2005) indicated that most changes in responses took place in the first two rounds and that little was gained after that. Hallowell and Gambatese (2010, p. 103) show the advantage of having a three round Delphi, which facilitates obtaining reasons for outlying responses from the second round and reporting these within the feedback in the third round; such a process could facilitate the consideration of all options and the attainment of a consensus about the correct value instead of “conforming to an incorrect opinion.”
    Some authors tend not to indicate a particular number for Delphi rounds. For example Chong and Zin (2010) argue that such a number should be based on the aim/objectives. This seems logical. Theoretically, a study taking an exploratory approach in its first round through the use of open-ended questions could require more rounds than a study starting with a structured list of issues arising from the literature. However, this should take into account practical considerations such as the time consuming nature of Delphi and the risk of fatigue by respondents; hence consideration should be given to having as few rounds as possible (Gunhan and Arditi, 2005). A balanced approach, that considers both theoretical and practical factors, may therefore be needed. The views of Robinson (1991) and Mullen (2003) could be helpful to achieve such balance. Both authors show that the Delphi process continues for a pre-determined number of rounds or until a predetermined criterion has been met, e.g., reaching consensus.
The Potential of Using Delphi in Construction Management Research
In construction-related research, a limited number of studies have utilized Delphi. Chong and Zin (2010) indicated that they hardly found any published article on Delphi in construction law research but argued that this did not indicate a lack of appropriateness to apply the Delphi method in such a field. Rather, they claimed that it was appropriate to use. As mentioned before, Hallowell and Gambatese (2010) argued that the Delphi method has not seen widespread use in construction engineering and management research and noticed significant variations among the studies that employed Delphi regarding methodological approaches and quality.
    Construction management research normally employs methods such as questionnaire surveys, interviews and case studies. The authors’ observations following discussions with researchers in construction management indicate limited awareness of Delphi, which could be one reason why the method has a limited use in such a field. The notion presented before regarding the lack of clear guidance in the literature on how the method operates as well as the variations in its application could be also indicative of other important reasons. Delphi could be used for any of the purposes mentioned earlier in this paper. Most, if not all, of these reasons could be encountered in construction management research. Yeung and colleagues (2009) found several applications for Delphi; some of these applications are related to construction topics. Examples include the development of residential areas, theory and design application, and bridge condition rating and effects of improvements. In the field of construction management in particular, research topics that could be suitable for Delphi include health and safety, risk management, procurement system selection, contractor selection, and sustainability (Chan et al., 2001; Bendaña et al., 2008; Yeung et al., 2009; Hallowell & Gambatese, 2010).
    The position of Delphi within the qualitative/quantitative debate could be a great advantage. Delphi is primarily a qualitative tool that has the potential of generating quantitative or semi-quantitative results (Feret & Marcinek, 1999; Hinks and McNay, 1999; MacCarthy & Atthirawong, 2003; Henchion & Mclntyre, 2005). It could start with any degree of structure and moves forward in terms of developing that structure, as shown previously. For example, it could initially take an exploratory approach through employing open-ended questions and then takes further structure in consequent rounds, as in the studies by Shon and Swatman (1998), Feret and Marcinek (1999), Scholl and colleagues (2004), Padel and Midmore (2005), and Yeung and colleagues (2009). The second round may involve a list of issues generated from analyzing the results of the first round and any other issues arising from the literature. Experts may be asked to identify the level of importance of the issues included the second round. On the third round, experts could be provided with statistical analysis showing their scores and the group score and the opportunity to modify their score. In this way, every round validates the findings from the previous round hence the self-validation feature of Delphi; Yeung and colleagues (2009, p. 66) noted that the “Delphi technique by its inherent nature serves as a self-validating mechanism because each expert is given a chance to re-evaluate their scores with reference to the consolidated mean scores as assessed by other experts.” The Delphi process in itself could replace a more traditional approach utilizing less structured methods (e.g. semi-structured interviews) at the initial phases of the research and then more structured methods (e.g. questionnaire consisting of closed-ended questions) later on. Therefore, Delphi, due to how it works, could combine two traditional methods in one method.
    One difficulty that could be encountered in Delphi is maintaining response by experts throughout the consecutive rounds. Clarifying how the technique works and obtaining experts’ willingness to participate from the outset could be of paramount importance to secure their response. Where the technique involves the use of questionnaires, general principles of questionnaire design should also be considered to maintain good response. Another difficulty is related to Delphi being time consuming. The processes of developing questionnaires, identifying experts, obtaining their willingness and commitment, distributing questionnaires, follow up of non-respondents, analysis of results and development of new questionnaires based on the analysis are time consuming and many of these processes have to be repeated through the consecutive rounds. The decision to employ Delphi should be informed of this as a potential problem and it is strongly recommended that any attempt to employ Delphi starts at an early stage of the research project to allow sufficient time for all the processes mentioned above to take place.
Case Study 1—Demonstrating the Use of Delphi in Construction Management Research: Use of the Delphi Method in Developing an Agreed Set of Economic Sustainability Criteria That Should Be Addressed in a Procurement Strategy
Background
The Sustainable Procurement Task Force (2006, p. 10) observed that for sustainable procurement, there was “no consistent definition in use across the public sector that both policy makers and procurement professionals could relate to.” Vagueness of definitions and diversity of interpretations have been highlighted by Sourani and Sohail (2011) as one of the barriers to addressing sustainable construction in public procurement strategies. Despite the production of many publications addressing the subject, there was a lack of agreed and comprehensive sets of social, economic and environmental sustainability criteria that should be addressed by UK public clients in developing a procurement strategy (Sourani & Sohail, 2012). This case study contributes to the development of this area by presenting part a research project that aimed at developing agreed sets of such criteria. However, as the aim of this case study is to demonstrate the use of Delphi, it would be sufficient to show the procedure with regards to the development of the economic sustainability criteria only. The social and the environmental sustainability criteria have been developed using the same procedure.
    The type of information sought in this case study demands the use of experts and indicates the need to utilize Delphi. One reason is related to the lack of agreed knowledge on the novel and complex subject of sustainability. Another reason is related to the expected difficulty that normal practitioners would find in interpreting the subject in general and the additional difficulty arising from requesting them to provide the information that is particularly relevant to procurement strategies in the context of the UK public sector. The final reason is related to the “hybrid” position of Delphi within the qualitative/quantitative debate which places it in an ideal situation for use; Delphi is primarily a qualitative tool that provides a rich context-based knowledge however its potential to provide quantitative results indicates whether consensus can be achieved (Critcher & Gladstone, 1998; MacCarthy & Atthirawong, 2003; Mullen, 2003).
Selecting Experts
Experts are usually busy people (Martino, 1983). Their workload may inhibit them from participating in a Delphi panel or may inhibit them from responding at times set by the investigator. Such a problem may be tackled by taking measures such as providing the experts with complete clarification about the exercise, setting appropriate but realistic time scales for response, adopting appropriate procedures to remind the experts with the need to respond and obtaining the experts’ commitment to participate before they become actually engaged in the exercise. All these measures were accommodated in this study. Selection of experts was based on knowledge, willingness, availability and representation of a variety of backgrounds and positions so that the key viewpoints are provided. The indicators of knowledge, as presented before, were considered; all experts had either a clear sign of professional eminence (e.g. leadership, membership, or holding office in a professional society/organization) and/or been a faulty member of an institute of higher education. On top of this, all experts had, at least, one of the following parameters applicable: presentations made at national conventions, publications in the field, and peer judgment/recommendations. Twenty-one experts were selected, representing a wide range of views and sectors; the panel involved a balanced representation of the public sector, professional/consultancy organizations, major contracting organizations and academics.
Round One
The Delphi first round questionnaire involved questions in an open-ended format to facilitate the exploration of the subject and assist in developing more representative answers of the participants’ thinking. In addition, no pre-coded answers were available to formulate closed-ended questions. The views of the experts participated in a pilot study supported this approach. As a part of the questionnaire, respondents were asked to identify five major criteria representing the economic dimension of sustainable construction that should be addressed by UK public clients in developing a procurement strategy. Respondents were notified that they were welcome to provide more than five criteria. Twenty one experts were contacted and seventeen replies were received (representing a response rate of 81%). These were widely distributed among the participating groups; thus provided a balanced view and an appropriate representation (Robinson, 1991; Chan et al., 2001). Any nonresponse was mainly due to the experts’ workload. Similar difficulty was reported in other Delphi studies, e.g., Chan and colleagues (2001). The responses to the questions in Round 1 provided a rich material for analysis. The procedure followed in analyzing the responses of the open-ended questions included the following major steps:
• reading and re-reading the responses received
• establishing preliminary categories within which the responses can be classified.Such categories emerged from key words used in the responses and from words or phrases that were frequently used in the responses. In establishing the categories, it was also taken into account the need to use the best exemplifying phrases. This approach was considered by Scholl and colleagues (2004) who showed the need to present the categories obtained from analyzing open-ended questions with the best exemplifying phrases from Round 1. Each category formulated included responses from at least two experts.
• coding the responses within the established categories
• reviewing the categories formulated and the responses classified to ensure that theresponses were classified appropriately and to identify the possibility of modifying the categories formulated, e.g., by merging similar categories
• reviewing the categories to ensure the appropriateness of the coding undertaken.
Table 1. Analyzed set of economic sustainability criteria based on responses received in Delphi Round 1
IDCriterionE1Clear establishment of need and evaluation of alternative optionsE2Whole life value for moneyE3Supporting the regional/local economy (including stimulating demand for local labor, businesses, materials and services)E4Creating employment opportunitiesE5Fitness for purpose (including consideration of long term flexibility)E6Consideration of whole life costingE7Economic Key Performance Indicators (KPIs)E8Waste minimisation and managementE9Improving the efficiency of the supply sideWhile every effort was made to ensure appropriate coding and representation of the responses through the categories, it should be noted that other classifications of the responses received may exist. This was also experienced in other Delphi studies, e.g., Feret and Marcinek (1999). The analysis of the results obtained in the first round led to identifying nine economic sustainability criteria (criteria E1 to E9 in Table 1). Figure 1 illustrates the Delphi process adopted, which can also be considered a typical example of how Delphi normally operates.
Round Two
Based on the analysis of the results obtained from Round 1, the Delphi second round questionnaire was developed. Respondents were asked to assess the level of importance of the 9 economic sustainability criteria obtained from Round 1 (criteria E1 to E9 in Table 2), using a 5-point Likert-type scale ranging from 1 denoting “not important” to 5 denoting “extremely important.” In addition, respondents were invited to assess the level of importance of another two criteria (criteria E10 and E11 in Table 2), which were suggested by the literature (but not suggested by the experts in the first round). Experts were also asked to add any other criteria that were not listed, to identify their level of importance and to add any comments. Fifteen replies were received in the second round. Two experts were unable to respond due to workload. This however has not affected the overall balanced composition of the panel. The analysis of the results obtained in this round led to identifying the level of importance of the 11 criteria included in the second round questionnaire and to identifying 1 new criterion (criterion E12 in Table 2). For each of the 11 criteria, the mean and the standard deviation values of the scores provided by the experts in the second round were calculated.
Round Three
Based on the analysis of the results obtained from Round 2, the Delphi third round questionnaire was developed. Respondents were given feedback from the second round which involved presenting the economic sustainability criteria E1 to E11 with two scores indicating their level of importance. The first score was named “Your Score” and represented the Table 2. Analyzed set of economic sustainability criteria based on responses received in Delphi Round 2
ID	CriterionMeanSDRankE1Analyzed set of criteria based on responses received in Round 1
Clear establishment of need and evaluation of alternative options4.670.621E2Whole life value for money4.670.491E3Supporting the regional/local economy (including stimulating demand for local labor, businesses, materials and services)3.871.136E4Creating employment opportunities3.671.058E5Fitness for purpose (including consideration of long term flexibility)4.570.513E6Consideration of whole life costing4.530.744E7Economic Key Performance Indicators (KPIs)3.530.929E8Waste minimisation and management3.930.595E9Improving the efficiency of the supply side3.530.999Other criteria suggested by the literature
E10 Financial affordability for intended beneficiaries3.791.257E11 Competitiveness3.500.8511Criteria identified in Round 2 (based on experts’ suggestions made in Round 2)
E12 Consideration of effective logistics strategies	N/A	N/AN/Ascore that the expert provided in Round 2 regarding the level of importance of the criterion while the second score was named “Mean Score” and represented the mean of the scores provided by all the experts participated in Round 2 regarding the level of importance of the criterion. In the third round, experts had the opportunity to reconsider the scores they provided in the second round using the same 5-point Likert-type scale. Thirteen replies were received in this round. Again, due to workload, two experts were unable to respond. This has not affected the overall balanced composition of the panel. Based on the responses to the third round questionnaire, the values for the mean and the standard deviation of the scores assigned to each criterion were calculated and the criteria were then ranked as shown in Table 3.
Establishing the Agreed Criteria Using Delphi
The major objective for conducting Delphi is to obtain a reliable consensus among participating experts. According to Jones and Hunter (1995, p. 376), the aim of consensus methods is “to determine the extent to which experts or lay people agree about a given issue.” However, according to Mitchell and McGoldrick (1994), there was little agreement on what exactly constitutes consensus, and according to Kilner (2004), the literature offered little guidance on the level of agreement required to claim consensus from Delphi. From a review of a wide range of Delphi studies, it was noticed that the authors of these studies measured consensus in different ways. Quite commonly, the extent of consensus was established using the following indicators:


• The percentages of respondents agreeing on certain answers: This was reported inmany Delphi studies. For example, Hughes (2003), defined consensus descriptors as those descriptors that were regarded as “important” or “very important” by more than 83% of the responses; Reetoo et al. (2004) reported the percentages of respondents considering aspects in their study as “important”; Feret and Marcinek (1999) reported that most respondents agreed on certain aspects in their Delphi study; Padel and Midmore (2005) reported the percentages of respondents who considered certain aspects as “important” or “very important”. Using such approaches to indicate agreement was reported by Kilner (2004, p. 376): “The literature offers little guidance on the level of agreement required to claim consensus from a Delphi study. Powell has observed a range of definitions from published studies, including terms such as most participants agree, agreement being implied by the results, or more specifically in numerical terms such as 55% or 100%.”
• Standard deviation values: This is one of the common ways to measure dispersionand expresses the extent to which values differ from the mean (Saunders et al., 1997). Many Delphi studies used or mentioned the use of standard deviation values as indicators of consensus or agreement among respondents. Examples include Feret and Marcinek (1999), Miller (2001) and Scholl and colleagues (2004).
In this case study, the development of the agreed set of economic sustainability criteria was based on identifying and assigning, for each criterion, the mean value, standard deviation value, and percentage of respondents agreeing on ranking the criterion. A criterion with a value of mean that is equal to or above 3 can be considered important (based on the Likerttype scale ranging from 1 to 5). Agreement among respondents that a certain criterion is important can be established based on having 75% or more of the respondents agreeing on giving a ranking that is equal to or more than 3 (i.e., a ranking of 3 = moderately important, 4 = very important or 5 = extremely important). The values shown in column 11 of Table 3 show the percentages of respondents agreeing on ranking that is equal to or more than 3. The values of standard deviation shown in Table 3 can be considered relatively low (therefore indicating agreement). Criteria satisfying the above indicators include the 12 economic sustainability criteria included in Round 3. These criteria scored mean values above 3, were rated by at least 75% of the experts as important and had relatively low values of standard deviation. A summary of the Delphi rounds and outcomes for this case study is shown in Figure 2.
Case Study 2—Learning Benefits of Using Delphi Method in Students’ Research Projects
Background
A number of publications have considered the benefits (particularly the learning benefits) of undertaking research projects. Among these are Race (2001), Ryder (2004), Seymour and colleagues (2004), Healey (2005), Hunter and colleagues (2006), Robertson and Blacker (2006), Beckman and Hensel (2009), Healey and Jenkins (2009), and Rueckert (2012). No study however has been undertaken to identify whether the employment of a particular research method/technique supports these benefits. The aim of this case study is to provide insights into the learning benefits that could be obtained as a result of employing the Delphi method in students’ research projects. The study has benefited from an analysis of various documentation related to an undergraduate construction management related program, named hereafter as Program A, in a UK university (such as program handbooks,

Figure 2. Delphi rounds and outcomes.
program specification, and module handbooks); a review of the publications addressing the learning benefits of undertaking research projects; and a review of the literature on Delphi. A reflection on the potential links between the various sets of documentation and publications (mapping) has led to identifying a number of key areas/learning benefits that could be obtained as a result of employing Delphi in students’ research projects (illustrated in Figure 3). These include: deep learning; knowledge generation; criticality; skills development; feedback issues; development of identity and career plans/opportunities; simultaneous learning and application of qualitative and quantitative research approaches and self-validation; flexibility, diversity and efficiency issues. These are discussed below.
Deep Learning
One learning benefit that research delivers is deep learning. This could be promoted through Delphi as it is normally employed in situations where there is a need to study/define areas of considerable uncertainty and/or a lack of agreed knowledge or to allow for combining fragmentary perspectives into a collective understanding. The technique requires the researcher to identify the major schools of thought in the subject and the different points of view so that agreement could be developed progressively throughout the rounds. This is consistent with the program specification for Program A which
Learning benefit that could be supported
Delphi Feature through employing Delphi in students’ research projects

Figure 3. Mapping Delphi features against learning benefits of students’ research projects.
highlights the ability of the student to analyse and evaluate a complex body of knowledge within the learning outcomes for final-year students and highlights working with limited/contradictory information as one of the transferable/key skills. Furthermore, the involvement of the student as a research facilitator for a panel of experts representing the major schools of thought contributes to deep learning; it has been argued that a context for deep learning could be facilitated through peripheral membership of a community of practice (Robertson & Blackler, 2007). According to Robertson and Blackler (2007, p. 227), frustration amongst students may arise when participation in the research community is delayed and when “students are unable to see the big picture or relate their current learning to disciplinary research.” The views of Healey (2005) seem to be supportive in this regard through highlighting the link between students’ involvement in research and the depth of learning and understanding.
Knowledge Generation
Delphi is normally employed in situations that would ultimately lead to knowledge construction/generation. Students undertaking dissertation modules are normally expected to deliver such an outcome; the dissertation module undertaken within Program A sets the expectations that students should collect, analyze and draw conclusions from data related to the problem or question they set. The learning benefits of knowledge construction/generation have been clearly emphasized by the literature. Healey and Jenkins (2009) highlighted the importance of universities extending and diversifying dissertations so that they are more closely linked with knowledge creation and dissemination. It has been argued that providing students with the opportunity to understand knowledge claims and engage in the construction of knowledge enables the situation of learning in their own perspectives (Hunter et al., 2006). As Delphi offers the potential to identify the different points of view so that agreement could be developed progressively throughout the rounds, the student has the opportunity to identify “how scientific knowledge is built” [which has been reported by Seymour and colleagues (2004) as one main learning benefit of undertaking research] and to identify the potential for multiple interpretations of data, the role of judgement/experience in interpreting data and the uncertainties and limitations of scientific investigation [which have been reported by Ryder (2004) as student learning outcomes from final year research projects].
Criticality
The learning benefits of criticality have been emphasized by the literature. For example, Seymour and colleagues (2004) highlighted critical thinking and understanding how to approach research problems as one of the benefits of undergraduate research. The program specification of Program A highlights the development of intellectual, analytical and critical abilities among the educational aims of the program while the critical appraisal of ideas was reported among the professional practical skills. Delphi would not be normally employed without a reason that has already involved some kind of critical examination of the literature. For example, defining areas with lack of agreed knowledge/disagreement would have already involved an examination of the different perspectives on the subject. Origins of lines of scientific enquiry, the role of previous scientific enquiries, the potential for multiple interpretations of data, the role of judgement/experience in interpreting data, in addition to the uncertainties and limitations of scientific investigation have all been reported by Ryder (2004) as student learning outcomes from final year research projects. Such outcomes could clearly be considered as signs of criticality. The purposes of using Delphi, the nature of the analysis of the results throughout the progressive rounds (which is expected to develop from a qualitative to quantitative analysis throughout these rounds) in addition to the feedback mechanism are all features of Delphi, which could promote these signs.
Skills Development
One of the key learning benefits of undertaking research is the development of skills. Examples of skills that could be developed through student research projects include using information technology and quantitative methods for numerical data analysis and reporting, communication skills, time management, creative thinking, communicating results, and realistic assessment of own performance (Ryder, 2004; Beckman and Hensel; 2009; Myatt, 2009; Brew, 2010; Rueckert, 2012). While other skills could be also developed through research projects; the skills mentioned above are those skills which the use of the Delphi Method could make a clear contribution to their development as shown below.
    A review of Program A’s specification indicates that confidence in applying quantitative and qualitative methods and the application of IT skills are among the learning outcomes of the program. In spite of being generally recognized as a qualitative tool, Delphi has the potential to produce quantitative or semi-quantitative data. Clearly, the use of Delphi entails the use of information technology and quantitative methods through software used in development of questionnaires or in the analysis of the quantitative results (e.g., SPSS). Communication skills have been reported among the key skills that could be developed/benefits that could be obtained through student research projects (Beckman & Hensel, 2009; Brew, 2010; Rueckert, 2012). Such skills have been reported among the intellectual skills which are part of the learning outcomes for final year level within Program A. Communication skills could be promoted through Delphi, as the method involves extensive communication with experts throughout the rounds. This could be in a written form (e.g., through the use of feedback given throughout the rounds) or in an oral form (e.g., through interviews). This is consistent with the program specification, which refers to written and verbal communication as part of the graduate skills.
    Ryder (2004) reported general skills (such as time management, use of initiative, creative thinking, communicating results, personal organization, adapting to an unfamiliar environment and realistic assessment of own performance) as student learning outcomes from final year research projects. While the use of Delphi could make a contribution to all these areas, the development of skills such as time management, creative thinking, communicating results and realistic assessment of own performance could be particularly relevant. With regards to time management, Delphi could exert significant time pressure on the Delphi researcher and this requires careful time management. The processes of developing questionnaires, identifying experts, contacting them, obtaining their willingness and commitment, distributing questionnaires, analyzing the results and developing new questionnaires are time consuming and many of these processes have to be repeated through the consecutive rounds. The program detail specification of Program A refers to time and resource management as part of the transferable/key skills (these are part of the learning outcomes of the program). As for creative thinking skills, the development of deep learning and knowledge generation clearly demonstrates the development of these skills. “Communicating results” has already been discussed within the development of communication skills. Finally, the skills of “realistic assessment of own performance” could be clearly developed through the feedback mechanism incorporated in Delphi.
Feedback Issues
One main factor contributing to successful learning is feedback (Race, 2012). Feedback issues have already been emphasized within most academic policies and guidelines, including those related to Program A. Delphi provides the student not only with the feedback that is normally expected from their research supervisor but also with continuous feedback from participating experts. The individual expert’s reply to the questions posed by the researcher involves some form of feedback in response to both the analysis carried out after each round and the collective opinion provided by the group.
Development of Identity and Career Plans/Opportunities
Among the learning benefits of undertaking a research project are reinforcing, clarifying, confirming interest in or choice of career decisions, plans and goals (Seymour et al., 2004; Myatt, 2009; Brew, 2010); increasing interest in careers in research (Myatt, 2009); and developing the habit of asking questions such as “what if” and “why not” which, according to Beckman and Hensel (2009), could lead to new discoveries or new ways of improving the practice of careers. Delphi offers the potential to identify, communicate and share the results of research with a diverse range of experts. This provides the student with the opportunity to develop their identity, which features as one of the educational aims of Program A and can be considered as a part of the professional socialization process (Hunter et al., 2006). In addition, development of professional relationships and exposure to a wide range of professional organizations could provide the student with further insights into professional career opportunities and improve their employability skills; possession of the qualities needed for employment was highlighted among the learning outcomes for final year level within Program A. In a review of the benefits of undergraduate research, Seymour and colleagues (2004) cited a number of publications signifying that professional socialization; opportunities for networking; and greater readiness for more demanding research and for professional careers indicate how career preparation could be enhanced.
Simultaneous Application of Qualitative and Quantitative Approaches and Self-Validation
According to Healey and Jenkins (2009), there may well be more emphasis on “learning the epistemologies” and “forms of discipline-based enquiry and learning particular disciplinary research methodologies.” The dissertation module within Program A highlights sourcing, collecting, and analyzing relevant and original qualitative and/or quantitative data within the learning outcomes of the module. Delphi could offer a unique opportunity to simultaneously learn and apply qualitative and quantitative approaches. As discussed earlier, Delphi occupies a position that is close to a constructionist approach, has the potential to generate quantified results within a positivist tradition and is also a self-validating method.
Flexibility, Diversity and Efficiency Issues
The flexibility of Delphi in terms of being conducted using questionnaires or interviews could be a great advantage in terms of diversity issues; according to Skulmoski et al. (2007, p. 9), this flexibility “not only affords the ability of the method to answer many research questions, but also can be well matched to the abilities and aptitudes of the graduate student.” Such flexibility reinforces the educational aims of Program A. Where Delphi is conducted using questionnaires, several advantages are offered, particularly the cheap cost of administration. The need for financial implications to be manageable to students should be taken into account in dissertations work, particularly with resource limitations becoming more severe (Race, 2001).
Conclusion
Delphi has been used in many fields and for different purposes. In theory, the field of construction management should be no exception; the literature does not suggest that the use of Delphi depends on the subject of study. Rather, its use depends on the research problem. Delphi could be used in situations such as defining areas with lack of agreed knowledge or combining fragmentary perspectives into a collective understanding; examples of construction management topics that could be suitable for Delphi include health and safety, risk management, procurement system selection, contractor selection and sustainability. In practice, there has been a limited number of studies that utilized Delphi in construction management research, which tends to employ more traditional methods such as questionnaire surveys, interviews and case studies. A critical review of the relevant literature, together with authors’ observation and experience of applying the method in their research indicate that the contributing factors to the limited use of Delphi in construction management research could include the limited awareness of the method, the lack of clear guidance in the literature regarding how the method operates and the variations in its application.
    Delphi, through its main characteristics (anonymity, iteration with controlled feedback and statistical group response) seeks to optimise the use of committees. Delphi studies used different sizes of panels. It is generally recognized that a minimum appropriate size would include seven or eight experts. Some studies tend to link the size to criteria such as the purpose of investigation and the standards used to select the panel members. The number of rounds used in Delphi studies varies among these studies. There is no clear agreement on what determines such a number. A balanced approach taking into account both theoretical considerations (such as achieving the aims of the study) and practical considerations (such as the risk of fatigue by some respondents) may have to be considered. Consequently, the Delphi process could continue for a pre-determined number of rounds or until some predetermined criterion has been met (e.g. achieving consensus). Delphi is a self-validating method. Many Delphi studies start with an exploratory approach in the first round and the results obtained throughout the rounds are analyzed and addressed in more structured forms in subsequent rounds. In this way, every round validates the findings from the previous round.
    Delphi offers the opportunity to perform quantitative analysis on the results obtained. However, it should be noted that such analysis is normally limited, taking a basic form (such as identifying the mean and the standard deviation). Advanced statistical tests are less commonly performed. One contributing factor is the aim of employing Delphi; which is normally identifying whether consensus has been reached. Such aim could be achieved by performing basic statistical tests. Another contributing factor could be related to the limited quantitative power of Delphi, particularly in light of the relatively small number of respondents in Delphi studies in comparison with conventional questionnaire surveys.
    The first case study presented in this paper demonstrated how the method was used to reach consensus regarding an area where there has been little agreed knowledge. Several features of Delphi were highlighted in the case study, including the following:
• Experts should be selected based on knowledge, willingness, availability and rep-resentation of a variety of backgrounds and positions so that the key viewpoints on the topic are provided; this should reduce common bias among experts as a result of sharing a common culture.
• Delphi could be time consuming for participating experts; experts are busy peo-ple and with the need for them to respond to several rounds, there is considerable risk of drop out by some of them. Sufficient number of experts should therefore be appointed. Measures to reduce possible fatigue should be considered including proper research design.
• Delphi may take an exploratory approach through employing open-ended questionsand then takes further structure in consequent rounds. For example, subsequent rounds may be used to identify the level of importance of issues identified in the first round and to validate such results. Delphi is therefore a self-validating method.
• Consensus could be measured using different indicators, e.g., the percentage ofrespondents agreeing on certain answers and standard deviation values. Agreement may be based on applying one of these indicators or both, as in the case study presented.
This paper has also provided a reflection and insights into the key areas/learning benefits that could be obtained as a result of employing the Delphi Method in students’ research projects. The second case study presented in this paper indicates that such key learning areas/benefits could include deep learning; knowledge generation; criticality; skills development; feedback issues; development of identity and career plans/opportunities; simultaneous learning and application of qualitative and quantitative research approaches and self-validation; and flexibility, diversity, and efficiency issues. Such benefits could be enhanced through a number of features of Delphi, such as the purpose of employing Delphi, the involvement of the student as a research facilitator, the nature of the method in terms of being a self-validating method, communication with experts from various backgrounds, the nature of the analysis of the results throughout the progressive rounds, the feedback mechanism, the use of information technology and quantitative methods, the time pressure on the Delphi researcher, exposure to a diverse and wide range of professional organizations, the “hybrid” status of Delphi which extends across the boundary between qualitative and quantitative approaches, and flexibility in terms of the possibility of conducting Delphi rounds using questionnaires or interviews.
    Further research may be conducted to provide more clarity with regards to selection of experts in Delphi panels. The literature reveals conflicting signs with regards to this; while studies such as Burr and Jones (2010) and Weidman et al. (2011) involved random selection from a list involving pre-qualified experts who were chosen based on their expertise, other studies mentioned by Mullen (2003) indicate inappropriateness of random sampling for selecting Delphi panels. Attention may therefore be given in future research to explore such inconsistencies in the literature and identify ways to overcome these. Further research may also address more case studies to confirm the findings of the second case study presented in this paper. The case study has benefited from an analysis of documentation relevant to an undergraduate construction management related program in a UK university. Further research could also be conducted to identify the learning benefits of employing the Delphi method in students’ research projects within the context of postgraduate programs. Delphi could be of particular appropriateness to employ in postgraduate programs as these programs normally offer longer period for undertaking an intensive research. Furthermore, such programs normally involve students with a degree of maturity and probably work experience and professional contacts, making it easier for them to identify and involve appropriate experts. Without action from construction management researchers and willingness to try this tried and tested method, Delphi may stay as a powerful method that the construction management field has been unable to realize its potential.
References
Beckman, M., & Hensel, N. (2009). Making explicit the implicit: Defining undergraduate research. CUR Quarterly, 29(4), 40–44.
Bendaña, R., del Caño, A., & de la Cruz, M.P. (2008). Contractor selection: fuzzy control approach. Canadian Journal of Civil Engineering, 35(5), 473–486.
Bradley, L., & Stewart, K. (2002). A Delphi study of the drivers and inhibitors of Internet banking. International Journal of Bank Marketing, 20(6), 250–260.
Brew, A. (2010) Imperatives and challenges in integrating teaching and research. Higher Education Research & Development, 29(2), 139–150.
Burr, K. L., & Jones C. B. (2010). The role of the architect: Changes of the past, practices of the present, and indications of the future. International Journal of Construction Education and Research, 6(2), 122–138.
Cabanis K. (2002). Computer-related technology use by counselors in the new millennium: A Delphi study. Journal of Technology in Counseling. 2(2). Retrieved September 18, 2013 from http://jtc. columbusstate.edu/vol2_2/cabaniss/cabaniss.htm
Chan, A. P. C., Yung, E. H. K., Lam, P. T. I., Tam, C. M., & Cheung, S. O. (2001). Application of Delphi method in selection of procurement systems for construction projects. Construction Management and Economics, 19(7), 699–718.
Che Senik, Z., Isa, R. M., Scott-Ladd, B., & Entrekin, L. (2010). Influential factors for SME internationalization: Evidence from Malaysia. International Journal of Economics and Management, 4(2), 285–304.
Chong, H. Y., & Zin, R. M. (2010). Application of the Delphi into Construction Law Research. The International Journal of Interdisciplinary Social Sciences, 5(1), 200–206.
Critcher, C., & Gladstone, B. (1998). Utilizing the Delphi technique in policy discussion: A case study of a privatised utility in Britain, Public Administration, 76(3), 431–449.
de la Cruz, M.P., del Caño, A., & de la Cruz, E. (2008). New paradigms for public procurement of construction projects in the United Kingdom—potential applicability in Spain. Canadian Journal of Civil Engineering, 35(3), 276–286.
Feret, B., & Marcinek, M. (1999). The future of the academic library and the academic librarian: a Delphi study. Library Career Development, 7(10), 91–107.
Gombera, P. P. (2003). A risk management system for healthcare facilities service operators. PhD Thesis. University of Derby, UK.
Gunhan S., & Arditi, A. (2005). Factors affecting international construction, Journal of Construction Engineering and Management, 131(3), 273–282.
Gupta, U. G., & Clarke, R. E. (1996). Theory and applications of the Delphi technique: A bibliography (1975–1994). Theoretical Forecasting and Social Change, 53, 185–211.
Hallowell, M. R., & Gambatese, J. A. (2010). Qualitative research: Application of the Delphi method to CEM research. Journal of Construction Engineering and Management, 136(1), 99–107.
Healey, M. (2005). Linking research and teaching: exploring disciplinary spaces and the role of inquiry-based learning, In Barnett, R. (Ed), Reshaping the university: new relationships between research, scholarship and teaching. Maidenhead, UK: McGraw-Hill/Open University Press, 67–78.
Healey, M., & Jenkins, A. (2009). Developing undergraduate research and inquiry. York: Higher Education Academy. Retrieved June 14, 2012, from http://www.heacademy.ac.uk/assets/York/
documents/resources/publications/DevelopingUndergraduate_Final
Henchion, M., & McIntyre, B. (2005). Market access and competitiveness issues for food SMEs in Europe’s lagging rural regions (LRRs). British Food Journal, 107(6), 404–422.
Hinks, J., & McNay, P. (1999). The creation of a management-byvariance tool for facilities management performance assessment. Facilities, 17(1/2), 31–53.
Hughes, R. (2003). Definitions for public health nutrition: a developing consensus. Public Health Nutrition, 6(6), 615–620.
Hunter, A. B., Laursen, S. L., & Seymour, E. (2006). Becoming a scientist: The role of undergraduate research in students’ cognitive, personal, and professional development. Science Education, 91(1), 36–74.
Jones, J., & Hunter, D. (1995). Qualitative research: Consensus methods for medical and health services research. British Medical Journal, 311, 376–380.
Khosrow-Pour, M. & Herman, N. (2001). Critical issues of web-enabled technologies in modern organizations. The Electronic Library, 19(4), 208–220.
Kilner, T. (2004). Desirable attributes of the ambulance technician, paramedic, and clinical supervisor: findings from a Delphi study. Emergency Medicine Journal, 21, 374–378.
Linstone, H., & Turoff, M., (Eds.) (1975). The Delphi method: Techniques and applications. Reading, MA: Addison Wesley.
Lucko, G., & Rojas, E. M. (2010). Research validation: Challenges and opportunities in the construction domain. Journal of Construction Engineering and Management, 136(1), 127–135.
MacCarthy, B. L., & Atthirawong, W. (2003). Factors affecting location decisions in international operations – a Delphi study. International Journal of Operations & Production Management, 23(7), 794–818.
Martino, J. P. (1983). Technological forecasting for decision making. New York: Elsevier Science Publishing Co.
Mitchell, V., & McGoldrick, P. J. (1994). The role of geodemographics in segmenting and targeting consumer markets: A Delphi study. European Journal of Marketing, 28(5), 54–72.
Miller, G. A. (2001). The development of indicators for the promotion of sustainable tourism. PhD Thesis, University of Surrey, UK.
Mullen, P. M. (2003). Delphi: myths and reality. Journal of Health Organization and Management, 17(1), 37–52.
Myatt, P. (2009). Student perceptions of the undergraduate research experience: what do they think they really gain and how much influence does it have? UniServe Science 2009 Conference Proceedings, Sydney, Australia.
Orndoff, C. J. W. (2005). Promising new tool for stakeholder interaction. Journal of Architectural Engineering, 11(4), 139–146.
Padel, S., & Midmore, P. (2005). The development of the European market for organic products: insights from a Delphi study. British Food Journal, 107(8), 626–647.
Procter, S., & Hunt, M. (1994). Using the Delphi survey technique to develop a professional definition of nursing for analysing nursing workload. Journal of Advanced Nursing, 19, 1003–1014.
Race, P. (2001). The lecturer’s toolkit: a practical guide to learning, teaching & assessment, Second Edition, London: Kogan Page.
Reetoo, K. N., Macdonald, E. B., & Harrington, J. M. (2004). Competencies of occupational physicians—The customer’s perspective. Suffolk, UK: Health and Safety Executive Books.
Robertson, J., & Blacker, G. (2006). Students’ experiences of learning in a research environment, Higher Education Research and Development, 25(3), 215–229.
Robinson, J. B. L. (1991) Delphi methodology for economic impact assessment. Journal of Transportation Engineering, 117(3), 335–349.
Rogers, M. R., & Lopez, E. C. (2002). Identifying critical cross-cultural school psychology competencies. Journal of School Psychology, 40(2), 115–141.
Rueckert, L. (2012) What do students gain by doing research? Retrieved June 30, 2012, from http:// www.neiu.edu/∼lruecker/rsrchassess.ppt
Ryder, J. (2004) What can students learn from final year research projects? Bioscience Education E-journal 4, paper 2. Retrieved June 14, 2012, from http://www.bioscience.heacademy.ac.uk/ journal/vol4/beej-4-2.htm
Saunders, M. N. K., Lewis, P., & Thornhill, A. (1997). Research methods for business students. London: Pitman.
Scholl, W., Konig, C., Meyer, B., & Heising, P. (2004). The future of knowledge management: an international Delphi study. Journal of Knowledge Management, 8(2), 19–35.
Seymour, E., Hunter, A. B., Laursen, S. L., & DeAntoni, T. (2004). Establishing the benefits of research experiences for undergraduates: First findings from a three-year study. Science Education, 88, 493–534.
Shon, T., & Swatman, P. M. C. (1998). Identifying effectiveness criteria for Internet payment systems. Internet Research: Electronic Networking Applications and Policy, 8(3), 202–218.
Smith, J. P., Miller, K., Christofferson, J., & Hutchings M. (2011). Best Practices for Dealing with Price Volatility in Utah’s Residential Construction Market. International Journal of Construction Education and Research, 7(3), 210–225.
Sourani, A., & Sohail M. (2011). Barriers to addressing sustainable construction in public procurement strategies. Proceedings of the Institution of Civil Engineers - Engineering Sustainability, 164(4), 229–237.
Sourani, A., & Sohail, M. (2012, June). Which economic sustainability criteria should be addressed in public procurement strategies? 4th CIB International Conference on Smart and Sustainable Built Environment (SASBE): Emerging economies, São Paulo, Brazil, 561–567.
The Sustainable Procurement Task Force (2006). Procuring the Future – Sustainable Procurement National Action Plan: Recommendations from the Sustainable Procurement Task Force. DEFRA.
Weidman J. E., Miller K. R., Christofferson, J. P., & Newitt, J. S. (2011). Best practices for dealing with price volatility in commercial construction. International Journal of Construction Education and Research, 7(4), 276–293.
Yeung, J. F. Y., Chan, A. P. C., & Chan, D. W. M. (2009). Developing a performance index for relationship-based construction projects in Australia: Delphi study. Journal of Management in Engineering, 25(2), 59–68.






56	A. Sourani and M. Sohail

The Delphi Method	55



56	A. Sourani and M. Sohail

The Delphi Method	55



