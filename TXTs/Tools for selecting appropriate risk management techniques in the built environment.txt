Tools for selecting appropriate risk management techniques in the built environmentDoug Forbes , Simon Smith & Malcolm HornerTo cite this article: Doug Forbes , Simon Smith & Malcolm Horner (2008) Tools for selecting appropriate risk management techniques in the built environment, Construction Management and Economics, 26:11, 1241-1250, DOI: 10.1080/01446190802468487To link to this article:  https://doi.org/10.1080/01446190802468487Full Terms & Conditions of access and use can be found at https://www.tandfonline.com/action/journalInformation?journalCode=rcme20  
Construction Management and Economics (November 2008) 26, 1241–1250Tools for selecting appropriate risk management techniques in the built environmentDOUG FORBES1*, SIMON SMITH2 and MALCOLM HORNER11Division of Civil Engineering, University of Dundee, Dundee DD1 4HN, UK2School of Engineering and Electronics, University of Edinburgh, Edinburgh, UKReceived 29 April 2008; accepted 8 September 2008The built environment is full of uncertainty which leads to risk. The literature shows that there is a wide range of techniques available to deal with risk; however numerous studies have shown that only a relatively small number are used in practice. One reason for this small number is a lack of knowledge of the circumstances in which they can be used. With the aim of overcoming this lack of knowledge two decision support tools are developed, which assist in selecting appropriate cases. The first tool is a two-dimensional matrix which provides a graphical output but has several limitations; the second is a case-based reasoning (CBR) model. These tools have been built from literature examples of the application of risk techniques. A framework has been developed to assess the examples. It uses a PESTLE (Political, Economic, Social, Technical, Legal and Environmental) analysis to assess the problem characteristics. The associated data used in the problem were defined as fuzzy, incomplete or random. The results of the CBR validation demonstrated a tool that predicts the correct technique in excess of 80% of cases, and allows the matrix to be revised and refined.Keywords: Risk management, risk techniques, decision support system, case-based reasoning.IntroductionRisk, as presented in this paper, has two elements: outcome and likelihood. In two seminal works concerning the management of risk in construction Flanagan and Norman (1993) describe risk in terms of probabilities applied to decision-making and Godfrey (1996) considers it the likelihood of an event occurring. There is a wide range of techniques available to manage risks in the construction industry and the risk management cycle is well defined. The first stage is identification of risks. The Institution of Civil Engineers et al. (1998) produced a guide for managing risk in projects. They highlight the importance of identifying risk because those which are not identified cannot be managed. Risks are then analysed (estimation and evaluation stages); this allows the risks to enter the final stages of the cycle which are defined by Baker et al. (1999) as response and monitoring. At all of these stages a number of different risk management techniques are available. However, previous researchers haveshown that there is a discontinuity between those techniques that are used in practice and those that have been developed in the literature (e.g. Akintoye and MacLeod, 1997; Wood and Ellis, 2003). The academic literature shows that while there is a number of techniques available, practitioners rely and focus on only a small number.  To overcome this problem two decision support tools were developed. The first used uses a matrix approach and the second a case-based reasoning (CBR) model to select appropriate techniques. These tools allow users of risk management techniques to make more informed decisions in selecting appropriate techniques and to consider applying techniques that might have not been previously considered by the user.Risk management in the built environmentEdwards and Bowen (1998) in a review of risk management research in the construction industry found that it had grown considerably over the last four*Author for correspondence. E-mail: d.r.forbes@dundee.ac.ukdecades. Since the mid-1980s, with the publication ofConstruction Management and EconomicsISSN 0144-6193 print/ISSN 1466-433X online # 2008 Taylor & Francis http://www.tandf.co.uk/journalsDOI: 10.1080/01446190802468487  
systematic methods for dealing with risk, numerous approaches have been developed and are in use across the construction industry. These include standard guidance, specifically designed for construction, including Perry and Hayes (1985); Godfrey (1996); Institution of Civil Engineers et al.(1998) and Allan et al. (2007). Beyond the construction industry Chapman (1997) and Kendrick (2004) have produced systems to deal with general project management risks. HM Treasury (2004) have presented an approach to deal with risks in financial problems. However, these approaches tend to present generalized methods by which risk can be managed and dealt with. There is little guidance as to what techniques should be used in what circumstances. Indeed, the Risk Analysis for Management of Projects Guide (RAMP Guide)(Institution of Civil Engineers et al., 1998) provides few details on specific techniques and directs readers to the PRAM Guide (Project Risk Analysis andManagement Guide) (Simon et al., 1997). Overall, this lack of specific guidance on selecting techniques is an issue that needs to be addressed.  A review of the literature has shown that there are 36 different techniques available to identify and analyse risks. However, numerous studies have shown that only a handful of these are used in practice. Akintoye and Macleod’s (1997) review of technique usage in the UK is commonly referred to in relation to this problem. They found that usage rates were very low for all but seven techniques. The most commonly used were experience-based techniques, which were used by 77% of contractors and 100% of project management practices. Subjective probability, Monte Carlo simulation and sensitivity analysis were used, but to a substantially more limited extent. In contrast were more ‘complex’ techniques which were seldom used and often unknown to the respondents (e.g. stochastic dominance). The authors gave eight reasons for the limited range of techniques. Most of these reasons relate to a lack of confidence in the technique or a  perceived lack of applicability to construction.  Bajaj et al. (1997) focused solely on identification techniques in New South Wales, Australia, and found a focus on group-based experiential techniques. Baker et al. (1998) reviewed the differences in the use of risk techniques between the construction industry and the oil and gas sectors. This study showed a tendency for the construction industry to avoid using quantitative techniques, and a greater focus in construction on financial rather than technical risks in comparison to the oil and gas industries.  A review in Australia by Uher and Toakley (1999) in the late 1990s demonstrated a distinct preference for qualitative methods. These results were backed up by Lyons and Skitmore (2004) in the same country which found that brainstorming was the preferred approach for identification, while assessment was carried out by a combination of experience, judgement and intuition.  Returning to a UK context, a review of cost consultants in 2003 by Wood and Ellis found that probability and consequence was a technique that was considered by most of the respondents. The same was true for Monte Carlo simulation. However, very few carried out sensitivity analysis and only one out of the 11 respondents sampled used any form of decision, fault or event tree. More ‘complex’ methods (e.g. influence trees, neural networks) were not even considered by those sampled for the study.  All of these studies have shown, over time and across continents that the construction industry tends to use only a limited number of techniques. Additionally, there has been a tendency to avoid softer risks such as those concerning social and political issues (Edwards and Bowen, 1998). The techniques which are used tend to be experiential and qualitative. This is in contrast with an industry that focuses heavily on financial risks that are most suitable for consideration using quantitative methods.  The reason why practitioners do not expand their range of techniques is unclear, as only the questionnaire of Akintoye and Macleod (1997) investigated this. One finding of their study was that practitioners considered ‘complex’ techniques may not be applicable to construction. This perception among practitioners is not confirmed by the academic literature, which is littered with examples of such techniques being applied. For instance, Flanagan and Norman (1993) demonstrate the use of stochastic dominance; Tah and Carr (2000) apply fuzzy logic to risk management and Wang et al. (2004) use neural networks to assess risk. These are all examples of ‘complex’ techniques applied to risk management in the built environment.  It is therefore suggested that there are two reasons for these techniques not being used. The first is that practitioners do not have the available resources (money, time, people, technology) to apply it. This research does not seek to address this issue. The aim of this research is to provide guidance for a second problem, namely a lack of knowledge of the circumstances in which a particular technique could be applied.  The literature demonstrates that not all techniques are appropriate for every situation. For example, a review of three identification techniques (nominal group, brainstorming and the Delphi method) was carried out by Buntin and Chapman (1998). When these were applied to construction management problems it was shown that brainstorming—although frequently considered the best method—is not always applicable. This implies that a single technique is not always a panacea.  Dey and Ogunlana (2004) produced a decision support system for risk technique selection in buildoperate-transfer projects. However, Dikmen et al. (2004) noted the absence of a fully integrated decision support tool and called for a formal framework to be created (Dikmen et al., 2004). Wang et al. (2004) also identified this need:It has been recognized that a framework with a holistic nature is desirable for risk assessment of large engineering systems where appropriate risk modeling [sic] and decision-making tools can be selected for use at different stages of the design process and operations.  Further, Lyons and Skitmore (2004) concluded that one risk technique may not always be appropriate for every situation. Thus, the research presented in this paper aims to identify a decision support tool or tools that will allow the selection of appropriate techniques for different problems in the built environment.MethodInitial research reviewing the literature identified 36 different techniques that have been applied in construction management problems in the past. Some of these 36 were applied at more than one stage of the risk management cycle (e.g. estimation and evaluation). This resulted in 52 applications of the 36 techniques across all three stages comprising 16 at identification, 18 at estimation and 18 at evaluation. A further 13 techniques identified had insufficient details to be used.Problem assessment frameworkA framework was developed against which problem types in the literature could be assessed. To ensure that the framework that was developed was rigorous, a method development by Morgan et al. (2000) for ranking risk was used. This process set four objectives: (1) logical consistency; (2) administrative compatibility; (3) equity; and (4) compatibility with cognitive constraints and biases. The requirements to meet each of these objectives are outlined by Morgan et al. (2000). All of these were met in developing the problem framework.  There is a range of structures in the literature defining the problems to which risk techniques are applied. The ‘risk environment’ breakdown distinguishes between external and internal risks. External risks are those ‘arising from the external environment, not wholly within the organization’s control, but where action can be taken to mitigate the risk’ (HM Treasury, 2004). Conversely, internal risks are those within the organization’s control, or ‘risks that have their origin within the project organization or its host, arising from their rules, policies, processes, structures, actions, decisions, behaviours or cultures’ (Barber, 2005). This is a universal difference and is applicable to all types of risk. It has therefore been used as the first level of breakdown in the framework. One significant difference between the external and internal nature is the position of the assessing organization. This high level of breakdown is too general for the purposes of selecting appropriate techniques; therefore a further level of breakdown is required.Defining the problem characteristicsThe first step in developing the problem characteristics was to assess existing generic structures. HM Treasury (2004) use the PESTLE model to define the external risks associated with a project. PESTLE encompasses Political, Economic, Socio-Cultural, Technological, Legal and Environmental elements (Cabinet Office, 2004). PESTLE has been principally applied in the past to external risks but we explored its potential application to internal risks. If this were possible it would simplify considerably the characterization of risk management problems. The literature contains many sets of the sources of risk in the built environment (for instance Radujkovic, 1996; Edwards and Bowen, 1998). These sets of risk were used to assess the ability of PESTLE to comprehensively categorize both internal and external risks. Fifteen sets of risks were identified in the literature, and each was assigned to one of the internal or external PESTLE descriptors. This not only demonstrated that PESTLE was capable of describing all the types of risks management problems in the built environment, but also provided more details about the types of risk that are associated with each of the descriptors.  There are two further parts to the problem characteristics. These are the ‘risk owner’ and the ‘project phase’. The risk owner helps to identify the internal or external nature of a risk. The risk owner is defined as being contractor; client; consultant/designer; financier; facilities management organization or government. This list was compiled during the review of the literature. If other organizations had been identified (e.g. subcontractor, supplier), these would have been, and can be, included as necessary.The RIBA Plan of Work (RIBA, 2000) and theProcess Protocol (Cooper et al., 2005) provide wellestablished breakdowns of project phases. However, these generic project stages were considered too detailed for this research. The stages used in the framework presented in this paper were selected to cover the whole life cycle of a project and are in line with the RIBA Plan of Work (2000) and whole life costing (Marenjak, 2004). The stages are (1) inception/ feasibility; (2) design; (3) construction; (4) commissioning; (5) operation; and (6) decommissioning.Defining the data characteristicsSo far the framework only defines the nature of the problem. No account is taken of the characteristics of the data used. Two structures for uncertainty in construction data were identified. Kishk (2004) developed a breakdown for whole life cost data including tangibility, availability and randomness. Blockley (1995) included fuzziness, incompleteness and randomness (FIR). This is stated as being the basis of uncertainty in risk and reliability. In their book, Systems for Rethinking Construction, Blockley and Godfrey (2000) apply the FIR model to systems in construction. The FIR model was used as the base for the data characterization because it was generic and encompassed the characteristics of Kishk (2004).FIR modelThe first element of the data characteristics stage of the framework is fuzziness. Fuzziness is the ‘‘imprecision of definition’’ (Blockley, 1995). For the purposes of defining the nature of data in a problem, fuzziness is present if that which is being assessed is imprecise. This imprecision may stem from a difference in understanding of the terms used, or from a range of possible values in the data (Blockley and Godfrey, 2000). For example fuzziness occurs in terms such as high, medium or low; or large and small costs.  The incompleteness aspect of a model is concerned with that which is not known (Blockley and Godfrey, 2000). Using this basis all risk management models are attempting to model incompleteness. If the problem is assessed on the presence of unknowns, all risk management techniques would fall into this category. To overcome this, the exact nature of the incompleteness was refined to relate solely to the data to which the technique was applied. This provided a better representation of the incompleteness of the data.  The final consideration is that of randomness. Randomness is the ‘‘lack of a specific pattern’’ (Blockley, 1995). This is the uncertainty defined by probability and statistics (Blockley and Godfrey, 2000). The data relating to a given problem were characterized using the revised definitions of the FIR model.  The FIR characteristics have been retained to model the uncertainty in data for three reasons: (1) the model is simple to use, and easily assessed; (2) the model is widely acknowledged in construction literature and was developed for uncertainty; and (3) the process of assessing examples in the literature demonstrated that data fitted the structure.Analysis of techniquesUsing the framework, historic examples of risk management problems for the built environment were analysed to produce a collection of problem characteristics and corresponding techniques. The examples were collated from the published literature of journal articles, conference proceedings and textbooks. In total 179 examples were assessed, which were collected from 94 references.  One issue identified during this process was that not all of the examples were actual applications. Some simply suggested a problem situation for which a technique might be applied. These were recorded separately as the effect of these ‘suggested’ examples requires further investigation.Presentation as a matrixThe first stage in developing decision support tools was to present the data from the 179 examples in a matrix format. The two-dimensional matrix had the categorized problems on the horizontal axis and the techniques on the vertical. The 179 problem examples were combined for each of the corresponding 52 applications. In its graphical format, the matrix could be used to select risk management techniques for a set of problem characteristics.  The matrix is a useful visual tool for identifying what tools are appropriate for a given problem situation. However, there are two pitfalls with the presentation which limit its effectiveness. First, no account is taken of the frequency with which a technique has been applied in the past. A decision on technique selection has to be made solely on whether the problem characteristics exist or not and there is no indication whether this is one or several times. Secondly, the aggregation process used clouded the selection of techniques. For example, the same technique may have been applied to a social and environmental problem with fuzziness, and then in another example to a technical risk with random data. In the original matrix there is no means of differentiating between the two problems, and it is implied that the technique is applicable to social problems with random data. To overcome these problems the possibility of developing a tool using case-based reasoning (CBR) was explored. Case-based reasoning is a method that can be used to solve problems based on past experience stored in a case-base. In essence, CBR identifies the technique most appropriate for addressing new problems based on the techniques used to address similar problems in the past.Further development of the matrixThe research carried out applying CBR, as detailed later in this paper, demonstrated that the selection of techniques was not dependent on the risk owner or project phase. Thus, the matrix was refined to exclude these features. This resulted in PESTLE, fuzziness, incompleteness and randomness on the horizontal axis and the techniques on the vertical. This reduced matrix is shown in Figure1. There are five techniques identified in the literature as being appropriate to risk management in the construction industry but which only had ‘suggested’ applications. These have been included in the techniques in the matrix, marked with an asterisk (*) with no problem characteristics defined. The ‘suggested’ problems have been omitted because the CBR model has shown the shortcomings of‘suggested’ examples. The characteristics of the data and problem for the technique could be included if an actual example is recorded.Development of the CBR modelIntroduction to CBRCase-based reasoning (CBR) is a branch of artificial intelligence. It is a method that examines what has taken place in the past and applies it to a new situation (Kolodoner, 1993). Watson (1999) performed an extensive review of the application and investigated the philosophy of CBR. He concluded that CBR is not a technique, but an approach to solving problems. The development method for a CBR model is dependent upon the problem to which it is being applied. In solving new problems based on past experience CBR uses the basis of human reasoning. This process applies a set of attributes, or features, to define each case in the case-base. These are connected to the associated output of the cases in the case-base, referred to as the outcome. The case-base is then accessed when presented with a new case, to locate similar historic cases and the corresponding outcomes. CBR has been used within the construction management literature for applications such as predicting the outcome of construction litigation (Arditi and Tokdemir, 1999), predicting construction cost (Yau and Yang, 1998), identifying failure mechanisms (Liao et al., 2000) and assessing the productivity of cyclic construction processes (Graham and Smith, 2004). This is only a small selection of the published literature available demonstrating the successful application of CBR to construction management problems.  The research presented in this paper has utilized the knowledge-based principles of CBR to identify where risk management techniques have been used in similar risk management problems previously. The CBR methodology has been used to determine the key features from the framework and therefore to simplify the selection process. The aim in this section of the paper is to discuss the application of CBR to the selection of appropriate risk management techniques; the mechanics or philosophy of CBR itself are not explored in depth as they lie outwith the scope of the paper. The reader is referred to Watson (1997) and Kolodoner (1993) for more information on the principles of CBR.Building the CBR modelsThe CBR cycle is shown in Figure2. The first stage in CBR is to develop the case-base that contains the details of past cases. When a new case is then presented to the case-base similar cases are retrieved. The outcome from these historic cases can then be used to make a decision on the appropriate outcome for the new case. In case-base reasoning it is sometimes possible to adapt the outcome to take account of partial matches among the features. However, the categorical nature of the outputs as risk management techniques meant that adaptation was not applicable to this research.  In developing a CBR model to assist in selecting appropriate risk management techniques the following variables in the methodology were investigated to obtain the optimum model: the feature similarity metric; the weighting of each of the features; the selection method; and the threshold value. The selection method in CBR takes account of the problem in the matrix relating to the frequency of use.Building the case-baseThe case-base was populated from the examples which were assessed against the framework. The features were defined as the six elements of the framework (internal/ external PESTLE; project phase; risk owner; fuzziness; incompleteness; and randomness). It was noted during this process that one example of a technique, for one risk owner or stage, may be applied to more than one of the PESTLE characteristics. This was overcome by extracting the combination of each of the framework features. For example, if a problem was social and  
Figure 1	Matrix for selecting appropriate risk management techniques  
Figure 2 The case-based reasoning process political and applied at inception and design stages, this would be combined into ‘social and inception’; ‘social and design’; ‘political and inception’; and ‘political and design’. This maintained the six features and had the advantage of creating a larger case-base than 179 examples. The assessment of the 179 examples resulted in 6177 cases in the case-base after the combinations of each had been derived. Each of the input features from the framework was assigned a numerical value. For example, the 12 elements of the external and internal PESTLE assessment were assigned 1 to 12. These values are nominal. For instance, a value of 12 in this feature is as different from a value of 11 as from 1.ValidationThe optimum model was tested by validating the model using an additional 42 examples, of which 20 contained ‘suggested’ examples. These examples were combined to create 1226 cases as was done for the cases in the case-base. The purpose of validation in CBR is to compare the ability of the model to predict correctly the known outcome of a new case (Gonzalez et al., 1998). Its use is demonstrated in the following example.  Assume a new case which has the outcome of ‘Monte Carlo Simulation’ at the estimation stage for an internal technological problem envisaged at construction stage by the contractor. The problem involves fuzziness. For Table 1 Validation prediction rates (%) for CBR toolall of the cases in the case-base a similarity score is calculated. All of the data are nominal in the risk tool problem, so similarity is measured for each feature as 100% where the feature of the new case matches the feature of the case in the case-base. The feature score is 0% where there is no match. The mean similarity is calculated across all the features for each case in the case-base. The most similar cases can then be selected with their appropriate outcomes. If cases in the casebase with the highest similarity score had ‘Monte Carlo simulation’ as the outcome, then the validation case was successfully predicted.  To assess the difference between ‘suggested’ and ‘actual’ examples the case-base was split. The first models considered the ‘suggested’ examples as being identical to actual examples; secondly the case-base only contained the actual cases. It was demonstrated through validation that significantly better results were obtained when the suggested values were removed, and so the ‘suggested’ values were not retained for further model builds. These results are shown in the left-hand side of Table1 for the six-feature model.	Six-feature model	Four-feature model‘Suggested’ values included	‘Suggested’ values removed‘Suggested’ values removedIdentification	72.8	87.180.0Estimation	60.9	93.598.5Evaluation	53.9	92.898.5  Case-based reasoning allows investigation into the features that are important in retrieving similar cases. This is performed by removing features one at a time from the case-base and the validation set and revalidating to find the errors. All combinations of input features were investigated, and it was found that the project phase and risk owner could be removed from the tool as this did not significantly affect the output.The purpose of the risk owner element was to differentiate between external and internal risks. With risk owner no longer required there is no need to differentiate between the six elements of external PESTLE and the six internal. Thus, the index of 12 on the PESTLE feature was reduced to six. The model that was produced was able to predict the correct techniques from the case-base used, for the validation cases in 80% of cases for identification techniques, and 98.5% of cases for the estimation and evaluation stages. The results are shown for the four-feature model in the right-hand side of Table1.DiscussionThe matrix produced is a useful tool to highlight trends and gaps within the risk management research. The first aspect considered is the frequency with which techniques are applied in the matrix. There are 52 applications of techniques available for all the risk management stages. The problem characteristic occurring most frequently is economic. There are 40 applications managing economic risks. The reasons behind this probably stem from the relative simplicity of monetizing values to calculate the risk and a focus within the industry on profit and cost. Before the aggregation of the external and internal PESTLE features it was noted that there were 40 internal economic and 29 external. The large number of internal examples may be accounted for by organizations being concerned with the risks they can most readily control. External economic risks, including market and residual value, may be harder to assess and may therefore have been avoided. This means not that they cannot be assessed using the given techniques, but that examples have not been identified. There was also a limited number of techniques available to deal with the political, social and legal risks with 22, 24 and 27 applications respectively. This is possibly due to these being ‘softer’ risks, making assessment of them more complex.  In assessing the FIR, out of 52 applications, 32 and 19 can deal with incompleteness and randomness respectively; however only 13 can deal with fuzziness. This is due to the relatively new emergence of fuzzy assessment. This is likely to increase as techniques grow in acceptance, and fuzzy methods are researched.  The missing values highlight the dynamic nature of the matrix. It has been constructed using 179 examples from the literature. A gap does not necessarily mean that a technique cannot be applied, but that an example has not been located to complete the matrix. However as it stands the matrix allows valuable judgements to be made in selecting techniques.  The CBR model has overcome the limitations of the matrix in aggregating the data and selecting techniques based on the number of examples in the case-base. It has shown that the risk owner and project phase elements can be removed from the model and maintain at least statistically the same level of validation results. The inclusion of the ‘suggested’ examples was shown to have a significant impact on the outputs. It is interesting to note that the complete exclusion of these values produced better results. There are two possible reasons for this: first it may be that these examples are suggested as a panacea in the literature, but are actually not. Secondly, in assessing the actual example more details are given simply because they are examples— thus the exact nature of the category is easier to assess. There are limitations in the data used to investigate the two approaches. The basis of selecting techniques is that the examples in the literature are correct. It has been shown that the ‘suggested’ examples would indicate that these examples are not always reliable. However, the effect of these has been removed. According to the literature the remaining examples all demonstrated successful application of the relevant technique.  The two tools developed in this work are decision support methods. This was the intended aim of the research, which has been met. The restrictions on the available data resulted in a framework that is able to characterize appropriate techniques. However, it is likely that other factors will be considered by those who are selecting the techniques. This does not restrict the tools as they provide the decision maker with guidance concerning the tools that would be appropriate. A final decision to apply a given technique should be made only after considering the user’s ability and familiarity with the technique, and other project-specific parameters, for instance project size, cost and duration.ConclusionsThe risk management technique matrix that has been produced from this work is a useful and simple to use tool in selecting the most appropriate risk management techniques for the built environment. This overcomes the issue of knowing when a particular technique can be applied. However, it is still necessary for the user of the technique to understand how the technique should be applied.  In addition to meeting the goal of developing decision support tools for selecting risk management techniques, there are three key conclusions which can be drawn. First, it is possible to characterize risk management problems using PESTLE and FIR.Despite PESTLE being developed for external risks it has been adapted and proved to be effective also for internal risks. The data structure is constrained by using a standard framework. However, it is important that this has a combination of simplicity, while remaining comprehensive. Additional measures beyond the FIR were considered and were found to be difficult to quantify and assess. FIR has been used because it is well established, takes a generic approach to representing uncertainty and is easily understood.  Secondly, the ‘suggested’ values that exist in the literature may affect the effective choice of risk management techniques. It is important to ensure that the application of a technique is verified with an actual example before it is included in the case-base. Thirdly, the research has demonstrated that certain combinations of problem characteristics do not have extensive examples provided for their application. The matrix output has shown that there is a lack of tools available to deal with particular areas. These are the ‘softer’ risks in the legal, social and political dimensions. Further research should be carried out into these areas, including the development of fuzzy techniques and the application of techniques for government, financiers and facilities management organizations. A more complete and accurate database could then be established from which to build the tools.  In conclusion, a CBR tool has been produced that can predict appropriate risk management techniques for use in the built environment using the standard problem characterization framework. The tool makes an assessment based on the frequency of occurrence from historic cases, and allows decision makers to choose an appropriate risk management technique in the field of construction management. However, it is still necessary for the user to have the resources and understanding to apply the chosen technique.  Finally, the application of CBR has been of benefit in this work in simplifying the problem characterization framework by removing the project phase and risk owner. A consequence of this is that the PESTLE feature can also be simplified by removing the requirement to differentiate between external and internal types. This further simplifies the matrix approach.AcknowledgementsThe support of the Engineering and Physical Sciences Research Council (EPSRC) in funding this work is gratefully acknowledged.ReferencesAkintoye, A.S. and MacLeod, M.J. (1997) Risk analysis and management in construction. International Journal of Project Management, 15(1), 31–8.Allan, N., Davis, J. and Godfrey, P. (2007) Ten steps to managing strategic risk—a holistic approach. Proceedings of the ICE: Civil Engineering, 160(3), 137–43.Arditi, D. and Tokdemir, O.B. (1999) Using case-based reasoning to predict the outcome of construction litigation. Computer-Aided Civil and Infrastructure Engineering, 14, 385–93.Bajaj, D., Oluwoye, J. and Lenard, D. (1997) An analysis of contractors’ approaches to risk identification in New South Wales, Australia. Construction Management and Economics, 15(4), 363–9.Baker, S., Ponniah, D. and Smith, S. (1998) Techniques for the analysis of risks in major projects. Journal of the Operational Research Society, 49(6), 567–72.Baker, S., Ponniah, D. and Smith, S. (1999) Risk response techniques employed for major projects. Construction Management and Economics, 17(2), 205–13.Barber, R.B. (2005) Understanding internally generated risks in projects. International Journal of Project Management, 23(8), 584–90.Blockley, D. (1995) Process re-engineering for safety, in James, M. (ed.) Risk Management in Civil, Mechanical and Structural Engineering, Paper presented at the conference organized by the Health and Safety Executive in cooperation with the Institution of Civil Engineers, 22 February, Thomas Telford, London, pp. 51–66.Blockley, D. and Godfrey, P. (2000) Doing It Differently: Systems for Rethinking Construction, Thomas Telford, London.Buntin, G.D. and Chapman, R.J. (1998) The effectiveness of working group risk identification and assessment techniques. International Journal of Project Management, 16(6), 333–43.Cabinet Office (2004) Strategy Survival Guide, available at www.strategy.gov.uk/downloads/survivalguide/downloads/ ssg_v2.1.pdf (accessed May 2006).Chapman, C. (1997) Project risk analysis and management— PRAM the generic process. International Journal of Project Management, 15(5), 273–81.Cooper, R., Aouad, G., Lee, A., Wu, S., Fleming, A. and Kagioglou, M. (2005) Process Management in Design and Construction, Blackwell, Oxford.Dey, P.K. and Ogunlana, S.O. (2004) Selection and application of risk management tools and techniques for build-operate-transfer projects. Industrial Management and Data Systems, 104(4), 334–46.Dikmen, I., Birgonul, M.T. and Arikan, A.E. (2004) A critical review of risk management support tools, in Khosrowshahi, F. (ed.) 20th Annual Conference of Association of Researchers in	Construction	Management	(ARCOM),	Heriot	WattUniversity, Edinburgh, 1–3 September, Vol.1, pp. 1145–54.Edwards, P.J. and Bowen, P.A. (1998) Risk and in construction: a review and future directions for research. Engineering, Construction and Architectural Management, 5(4), 339–49.Flanagan, R. and Norman, G. (1993) Risk Management andConstruction, Blackwell, Oxford.Godfrey, P.S. (1996) Control of Risk: A Guide to the Systematic Management of Risk from Construction. Special Publication 125, CIRIA, London.Gonzalez, A.J., Xu, L. and Gupta, U.M. (1998) Validation techniques for case-based reasoning systems. IEEE Transactions on Systems, Man and Cybernetics—Part A: Systems and Humans, 28, 465–77.Graham, D. and Smith, S.D. (2004) Estimating the productivity of cyclic construction operations using case-based reasoning. Advanced Engineering Informatics, 18, 17–28. HM Treasury (2004) The Orange Book. Management of Risk— Principles and Concepts, HMSO, Norwich.Institution of Civil Engineers, Faculty of Actuaries and Institute of Actuaries (1998) RAMP: Risk Analysis and Management for Projects, Thomas Telford, London.Kendrick, T. (2004) Project Management Tool Kit: 100 Tips and Techniques for Getting the Job Done Right, AMACOM, New York.Kishk, M. (2004) Combining various facets of uncertainty in whole-life cost modelling. Construction Management and Economics, 22(4), 429–35.Kolodoner, J. (1993) Case-Based Reasoning, Morgan Kaufmann, San Mateo, CA.Liao, T.W., Zhang, Z. and Mount, C.R. (2000) A case-based reasoning system for identifying failure mechanisms.Engineering Applications of Artificial Intelligence, 13, 199–213.Lyons, T. and Skitmore, M. (2004) Project risk management in the Queensland engineering construction industry: a survey. International Journal of Project Management, 22(1), 51–61.Marenjak, S. (2004) A generic approach to minimising WLC in the building industry, PhD thesis, University of Dundee.Morgan, M.G., Florig, H.K., DeKay, M.L. and Fischbeck, P. (2000) Categorizing risks for risk ranking. Risk Analysis, 20(1), 49–58.Perry, J.G. and Hayes, R.W. (1985) Risk and its management in construction projects. Proceedings of the Institution of Civil Engineers, 78(1), 499–521.Radujkovic, M. (1996) Risk management: maintaining programmed construction time in economies in transition, in Langford, D.A. and Retik, A. (eds) The Organisation and Management of Construction: Shaping Theory and Practice, Vol. 2, E&FN Spon, London, pp. 811–9.RIBA (2000) Plan of Work, RIBA Enterprises, London.Simon, P., Hillson, D. and Newland, K. (1997) Project Risk Analysis and Management Guide, The Association for Project Management, Norwich.Tah, J.H.M. and Carr, V. (2000) A proposal for construction project risk assessment using fuzzy logic. Construction Management and Economics, 18(4), 491–500.Uher, T.E. and Toakley, A.R. (1999) Risk management in the conceptual phase of a project. International Journal of Project Management, 17(3), 161–69.Wang, J., Sii, H.S., Yang, J.B., Pillay, A., Yu, D., Liu, J., Maistralis, E. and Saajedi, A. (2004) Use of advances in technology for maritime risk assessment. Risk Analysis, 24(4), 1041–63.Watson, I. (1997) Applying Case-based Reasoning: Techniques for Enterprise Systems, Morgan Kaufmann, San Francisco, CA.Watson, I. (1999) Case-based reasoning is a methodology not a technology. Knowledge-Based Systems, 12, 303–8.Wood, G.D. and Ellis, R.C.T. (2003) Risk management practices of leading UK cost consultants. Engineering, Construction and Architectural Management, 10(4), 254– 62.Yau, N.-J. and Yang, J.-B. (1998) Case-based reasoning in construction management. Computer-Aided Civil andInfrastructure Engineering, 13, 143–50.      1242	Forbes et al.  Risk management techniques	1243    