	Building and Environment 43 (2008) 458–468	www.elsevier.com/locate/buildenvDevelopment of a customer satisfaction evaluation model for construction project managementJyh-Bin Yang, Sheng-Chi PengInstitute of Construction Management, Chung Hua University, No. 707, Sec. 2, Wu-Fu Rd., Hsinchu 300, TaiwanReceived 11 May 2006; accepted 20 July 2006Abstract  Construction project management (CPM) is a technical-oriented service for construction project clients. Evaluating the performance of service providers is beneficial both to purchasers, enabling them to appraise the services received, and to providers, helping them to improve their services. However, no appraisal system for such services exists. This study developed a novel customer satisfaction evaluation model for CPM services that was developed using a questionnaire-based survey and statistical analysis. Test results show that the developed model is a feasible system. Research using this model reveals that CPM services in Taiwan are satisfactory with acceptable performance for clients. The developed model is a good reference for evaluating and assessing CPM performance. r 2007 Elsevier Ltd. All rights reserved.Keywords: Construction management; Project management; Professional services; Performance evaluation; Surveys  
1. Introduction  With the ISO 9000 standard gaining popularity worldwide, total quality management (TQM) has become a strategic and survival approach for most firms in every industry. TQM is a complete management philosophy that emphasizes overall satisfaction through the continuous improvements to products and processes. Notably, TQM is concerned with customer satisfaction and is not merely a slogan [1]. Since 1988, TQM has been codified in a national award (the Malcolm Baldrige National Quality Award) in the United States, ‘‘customer satisfaction,’’ once the most criteria in TQM evaluation, has been transformed into ‘‘customer relationships and satisfaction’’ in the category of customer and market focus [2]. Obviously, customer satisfaction is a key factor in achieving quality improvement. The construction industry has many characteristics common to manufacturing and service industries. In the construction industry, customer satisfaction demands on contractor’s performance are in accordance with contractual duties, obligations and responsibilities. Total customerCorresponding author. Tel.: +88635186684; fax: +88635370517. E-mail address: jyhbin@chu.edu.tw (J.-B. Yang).0360-1323/$-see front matter r 2007 Elsevier Ltd. All rights reserved.doi:10.1016/j.buildenv.2006.07.044satisfaction has never been a goal for designers, construction managers, subcontractors and material suppliers [3]. It is hard to achieve higher satisfaction level by any single project participant. However, there is no doubt that making customer (client) as satisfied as possible is an essential task for any firm in the construction industry regardless of the construction-related products or services they provide.  The application of professional construction management (PCM) has increased rapidly since it was first introduction and promoted in the early 1960s [4–7]. In a narrow sense, PCM forms a three-party team, including the owner, the architect/engineer (A/E) and the project manager, to accomplish the owner’s authorized tasks [5]. On the contrary, from a broad perspective, PCM is an effective means of satisfying an owner’s construction needs [4]. Functional PCM tasks consist of the following phases of construction projects: conceptual planning; conceptual design; detailed design; construction; closeout; and, startup. PCM is now regarded as a professional team for serving all owner needs in a construction project.In Taiwan, the Government Procurement Law (GPL),promulgated on May 27, 1998, allows several innovative concepts and regulations, including the PCM (the officialFig. 1. Trend of new project delivery methods in Taiwan.term in GPL is project management, therefore, construction project management (CPM) is used hereinafter replacing the PCM term) approach and the most advantageous tendering approach [8] for construction projects and procurement entities. As stated in Article 39 of GPL—‘‘In conducting a procurement, an entity may entrust a supplier, according to this Act, with the project management related to planning, design, supply, or contract performance’’, a construction project can have a CPM contract to serve the consultative and administrative needs [9]. After the GPL of Taiwan went into effect, the number of construction projects with CPM contracts issued has been increasing (see Fig. 1). With CPM stepping into its flourishing phase in Taiwan, it is necessary to appraise the performance of CPM services. This study focuses on developing a customer satisfaction evaluation model for evaluating CPM services and examines its applicability in Taiwan.2. Customer satisfaction  There has been a quite obvious increase in the emphasis on a firm’s ability to produce high-quality products and/or provide high-quality services. Identification of high-quality products or services can be achieved by measuring customer satisfaction with these products or services. The concept of customer satisfaction transforms all industries from production centralized to customer based. Several evaluation models or indices exist for assessing customer satisfaction in various industries. To achieve a highly reliable and stable index of satisfaction, the American Customer Satisfaction Index (ACSI) [10] defines the satisfaction as a weighted average of three survey ratings: perceived quality, perceived value, and customer expectations. The ACSI index has been used to measure the satisfaction in the manufacturing/nondurables, manufacturing/durables, transportation, communications and utilities, retails, finance and insurance, services, public administration, and government. Although the ACSI index has an accepted satisfaction evaluation methodology, it is not designed for the construction industry. Generally, the evaluation result for customer satisfaction is highest for competitive products, lower for competitive services and retailers, and lowest for government and public agencies [11]. The ACSI system criteria cannot be adapted to the construction industry, a new evaluation model must be developed not only for the construction industry, but also for CPM services.3. Related research  Construction projects involve numerous stakeholders that are closely related and interacted during a given project. The level of a stakeholder satisfaction directly influences the current project and subsequent projects and the level of satisfaction experienced by other stakeholders. For contractors, completing a project in accordance with the plans and specifications within budget and on time satisfies owner needs and generates profit. Ahmed and Kangari [12] used six client-satisfaction factors, including time, cost, quality, client orientation, communication skills and response to complaints, to conduct a survey for analyzing the client-satisfaction factors in the construction industry. They concluded that these six factors are equally important when evaluating client satisfaction. Maloney argued that the physical product and service delivery must be considered when assessing customer satisfaction in the construction industry. For electrical construction projects, Maloney proposed a dual-influence model using five dimensions—contractor/customer relationship, project management, safety, prepared/skilled workforce and cost—to evaluate customer satisfaction and for contractor selection decisions [13]. Furthermore, Maloney claimed that labor-management activities at levels of contractor– workforce, contractor–local union and contractor association–local union influence customer satisfaction [14]. Contractors need to establish partnerships with labors to enhance customer satisfaction.  To measure home-buyer satisfaction, Torbica and Stroh [15–17] developed a model, called HOMBSAT, with three distinct dimensions of house design, house and services. The indicators of house design and house are used to rate the product quality of a transaction, whereas indicator of services is used to rate the service quality. The HOMBSAT can provide a total home-buyer satisfaction across three dimensions to the home builders to track the overall quality of their services. Moreover, Torbica and Stroh also confirmed that a home builder can increase home-buyer satisfaction by implementing TQM [18]. In 2002 and 2003, J.D. Power and Associates reported that the quality of workmanship/materials and customer services account for 50% of overall customer satisfaction among buyers of new homes, and the levels of customer satisfaction increased significantly in the highly competitive homebuilder industry [19]. Liu, who surveyed residential satisfaction of housing estates in Hong Kong, utilized questionnaires comprising nine categories with a total of 51 questions [20]. That study developed a well-structured post-occupancy evaluation method for measuring customer satisfaction.  Tang et al. [21] investigated the client satisfaction of engineering consulting firms in Hong Kong using a questionnaire-based survey. Their study used the following eight factors (expressed in 29 indicators) to evaluate overall client satisfaction: professionalism of service; competitiveness of service; timeliness of service; quality of design; degree of innovation; completeness of other considerations; availability of support for client; and, supervision at implementation. Tang et al. concluded that the quality of engineering consulting services in Hong Kong was slightly higher (mean score is 3.122) than neutral (default score is 3) [21]. Leung et al. [22] measured participant satisfaction in the construction management process. Through 15 established and verified hypotheses, the study showed that management mechanisms (e.g., communication, participation and commitment) rather than particular project goals (e.g., time, cost and quality) influence directly participant satisfaction.4. Research approach  This study developed a customer satisfaction evaluation model for CPM services through the following processes. (1) Set an evaluation framework and related factors. This study used eight practical cases, Taiwan’s GPL regulations and several studies to identify the evaluation hierarchy and associated factors. (2) Develop a usable questionnaire. Each question was based on each factor generated by the preceding process. A pilot survey was conducted to validate the questionnaire. After the pretest, the questionnaire was refined. (3) Collect field data. This study conducted an official survey to obtain raw research data for further analysis. The questionnaire was sent to 57 project clients; of the 24 replies, 22 were valid for analysis. (4) Analyze collected data. All responses were analyzed by the methods of descriptive statistics and inferential statistics to improve survey reliability. (5) Develop a formal evaluation model. The proposed evaluation model was developed according to antecedent statistical results and tested using several practical CPM cases in Taiwan. The five steps can be classified into three stages, i.e., questionnaire survey, model evaluation and formal model development, as discussed in Sections 5, 6 and 7, respectively.5. Questionnaire survey  Owing to the nature of data outsourcing of questionnaire-based survey, the development of a questionnaire plays the key role in customer satisfaction research. A wellstructured questionnaire magnifies desired achievements of a research. Hayes [23] suggested a three-stage model for developing a practical questionnaire for customer satisfaction evaluation, namely determine customer requirements, develop and evaluate the questionnaire, and finally, apply the questionnaire. This study transformed Hayes’ model into a comprehensive model with five stagesFig. 2. Processes of questionnaire development for customer satisfaction.that are as follows. Fig. 2 shows the questionnaire development process.5.1. Defining customer satisfaction  In addition to construction products, a contractor also provides a set of construction services that range from meeting periodically with owner representatives to a product of services that is provided by subcontractor or other material vendors. For CPM services, a client must find a service provider to do all construction-related works. However, clients with CPM service usually are nonprofessionals in the construction industry. As such, they are unfamiliar with construction-related works, which is why they require professional services. Thus, customer satisfaction in CPM services is defined as the degree to which client requirements are satisfied in construction-related works.5.2. Determining customer requirements  The Procurement and Public Construction Commission of Taiwan has promulgated several procurement regulations. One regulation regarding how to select a supplier and the formulas for calculating service fees of technical services has an article stipulating the kinds of construction works that an entity can entrust to suppliers. An entity who entrusts any CPM service should comply with these regulations. Fig. 3 shows the working areas of CPM service provided in Taiwan. Detailed legal services are listed on the web /http://www.pcc.gov.twS. To identify the customer requirements for CPM services, this study collected work items from eight real CPM cases and compared these items with regulations to extract general customer requirements. Unique items added to the contract of any real case are pruned off. In summary, there are 82 work items utilized in the proposed model.5.3. Developing the questionnaire  Performance of CPM services was evaluated using a hybrid approach that monitors ongoing and completed services. This evaluation approach consists of two stages:financial analysis formulation of the preliminary budget,shcedule feasibility study report ·othersin-service and post-service stages. To ensure the integrity of this CPM service evaluation, knowledge areas in the Project Management Institute’s publication, A Guide to Project Management Body of Knowledge (PMBOK) [24], was utilized to establish the evaluation dimension. Although nine knowledge areas exist in PMBOK, not all are suitable for this study. Discussion with several domain experts concluded that the appropriate dimensions for the in-service stage are cost, quality, time, communication and technique/tool; whereas those for the post-service stage are cost, quality, time and scope. Fig. 4 presents a detailed evaluation framework. There are 51 and 31 questions in the in-service and post-service stages, respectively. In the evaluation framework, all identified work items are classified according to the previous dimensions. To form a questionnaire, all evaluation items are re-written into the question type as shown in Fig. 5. The formal questionnaire is in Chinese.management and coordination of the progress of the design tendering strategy ·others·tender documents·evaluation of tenders ·othersinterface of various work itemsschedule and quality control change order ·othersmaintenance or operational manualsacceptance and transfer of the project others  The questionnaire consists of four sections. In the first and second sections, respondents were asked to choose one of five choices (very unimportant, unimportant, neutral, important and very important for the importance issues, and very dissatisfied, dissatisfied, neutral, satisfied and very satisfied for the satisfaction issues) for all questions in the in-service and post-service stages, respectively. The third section probed respondent general impressions of services in the dimensions and asked respondents to grade overall satisfaction on a scale (very dissatisfied, dissatisfied, neutral, satisfied and very satisfied). The grades obtained were then used to calculate the value of total satisfaction for project management (TSPM). The fourth section collected basic information, such as the scale of a project in money, of involved CPM cases.5.4. Questionnaire evaluation  A pretest was conducted to assess a draft of the questionnaire. Five employees of CPM clients were invited to examine the questionnaire. The main concerns raised were as follows: (1) the meaning of some questions is unclear; (2) the default options for some questions are unsuitable; and, (3) some questions are hard to answer because the questions (the work items) are not applicable to respondent experience. All concerns were addressed and the questionnaire was modified according to the following principles: (1) questions are rewritten to improve clarity for respondents and default options are also adjusted; (2) the answer ‘‘not applicable’’ is added to each question.Evaluation ItemApplicableImportanceSatisfactionYesNoVUUNIVIVDDNSVSFinancialanalysis and recommendation on the sources of financeNote:VU forvery unimportant; U for unimportant; N for neutral;I for important; andVI for very important.VD for very dissatisfied; D for dissatisfied; N for neutral; S for satisfied; andVS for very satisfied.Fig. 5. Part of research questionnaire.5.5. Using questionnaire  When analyzing the status of CPM services in Taiwan, the entities who issued CPM projects between January 31, 2000 and December 31, 2002 were considered. The original data is extracted from the Electronic Procurement System of Taiwan Government /http://web.pcc.gov.twS. In this period, 115 CPM projects were launched: 47 central government projects; 62 local government projects and 6 school projects. Among them, 28 projects whose anticipated procurement budgets were below 1 million New Taiwan dollars (NT dollars) were excluded. Only 31 entities were contacted by the research team. Of the 57 questionnaires sent, 24 replies were received, 22 of which were valid. Figs. 6 and 7 present the distribution of questionnaires sent and responses received from service clients and providers, respectively. In general, the responses received cover all client and provider types. Thus, the analysis result will be representative of CPM services in Taiwan.6. Model evaluation6.1. Descriptive statistics test—reliability and validity test  This study used descriptive statistical method to analyze important characteristics and summarize survey results. Reliability is a prerequisite for measuring validity. Cronbach’s alpha coefficient was used as an index to test survey reliability. In general, the closer the Cronbach’s alpha coefficient is to 1.0, the more reliable the test is. As stated in the literature [25], an alpha equal to or greater than 0.70 is considered satisfactory. Reliability estimates below 0.60 are usually regarded as unacceptably low. Table 1 listed the detailed values of Cronbach’s alpha coefficient for each dimension. In summary, the reliabilities of each dimension are acceptable (greater than 0.60).  Test validity is difficult to establish since no accepted standard exists for comparison. Nevertheless, attempts can be made to establish validity using respondent subjectiveFig. 6. Distribution of questionnaire in different service clients.Fig. 7. Distribution of questionnaire in different service providers.Table 1Reliability analysis results for original evaluation frameworkStage	Dimension	Reliability (alpha coefficient)ImportanceSatisfactionIn-serviceCost0.95480.9354Quality0.89000.8661Time0.90860.8681Communication0.94640.9410Technique/Tool0.72850.8899Post-serviceScope0.65880.6196Cost0.94710.9046Quality0.95200.9261Time0.94840.9598Table 2Mean scores of respondentsStageDimensionImportanceSatisfactionIn-serviceCost7.686.77Quality7.246.98Time7.396.97Communication7.957.18Technique/Tool7.607.05Post-serviceScope7.006.59Cost7.797.51Quality7.306.92Time7.526.55Note: for the importance issue, average value: 7.50, variance: 0.087, stand deviation: 0.295.judgments based on experience and empirical indicators. To be valid, a test must be reliable; but reliability does not guarantee validity, i.e., it is possible a meaningless (invalid) test can have a higher reliability. In general, the questionnaire used in this study is based on literature reviews, domain expert interviews and a pretest; thus questionnaire validity can be acceptable when reliability is acceptable.6.2. Descriptive statistics test—mean valve analysis  All questions have default options with corresponding scores (2 for very unimportant; 4 for unimportant; 6 for neutral; 8 for important; and, 10 for very important) for subsequent analysis. This study used the threshold of one sigma (one standard deviation) of respondent scores for the importance issue to erase unimportant questions. Table 2 shows detailed values of variation in the importance issue. With a threshold value of 7.205 for the importance score, 12 and 10 questions were erased from the in-service and post-service stages, respectively. Notably, the importance score for questions in the scope dimension is below the threshold; therefore, the dimension of scope is erased. Finally, there are 39 and 21 questions in the in-service and post-service stages, respectively.6.3. Inferential statistics—importance-satisfaction matrix analysis  Importance-satisfaction matrix analysis [26], which is a means of combining satisfaction and importance measures to obtain a clear indication of which areas should be addressed and which should be maintained, is a standard method of analyzing customer satisfaction. The method forms a quadrant matrix that has four different meanings for interpretation and adoption. The top left-hand quadrant of the matrix shows items that are ‘‘high’’ in importance and ‘‘low’’ in satisfaction, and therefore they have been labeled as ‘‘more work needed to improve performance.’’ The lower left-hand corner contains items that have been rated ‘‘low’’ in both importance and satisfaction. Items in this quadrant have been labeled as ‘‘second priority for improvement’’. The top right-hand corner of the figure contains items that are rated ‘‘high’’ in both importance and satisfaction and the items here have been labeled as ‘‘works are excellent and should be maintained’’. Finally, the lower right-hand corner shows items that are ‘‘high’’ in satisfaction and ‘‘low’’ in importance. These items have been labeled as ‘‘second priority to maintain’’. Results of evaluating customer satisfaction in the matrix can be a clear indication of the level of satisfaction and the strategy to be adopted for improving satisfaction.  As designated in the questionnaire, each question has a five-point scale to indicate relative importance and satisfaction. The importance scores are rated on the following scale: 2, very unimportant; 4, unimportant; 6, neutral; 8, important; and, 10, very important. Similarly, the satisfaction scores are rated on the following scale: 2, very dissatisfied; 4, dissatisfied; 6, neutral; 8, satisfied; and, 10, very satisfied. Mean scores (see Table 2) for the dimensions of importance and satisfaction were used to plot the matrix. Figs. 8 and 9 show the quadrant matrix of the two stages where the mean importance is plotted against the vertical axis and the mean satisfaction against the horizontal axis. The average values of all responses for in-service and post-service are in the high importance and satisfied quadrant, meaning that the works are excellent2.002.00 4.00 6.00 8.00 10.00Mean SatisfactionFig. 8. Importance–performance relationship of in-service stage.and should be maintained. In these CPM cases, the analysis results are not located in the very importance and very satisfied areas, the shadow areas in Figs. 8 and 9 that are the optimum areas. It implies that service performance still has some room for improvement. In summary, the CPM services in Taiwan are in general satisfactory.6.4. Algorithm for measuring TSPM  In order to differentiate the performance of satisfaction for CPM, this study developed a novel model of TSPM to measure a service provider’s performance status that can be an index for performance improvement. TSPM considers all dimensions in two stages and accumulates the scores according to a normalized scale. The TSPM is calculated by Eq. (1), in which, Si, the mean satisfaction score for dimension i, is calculated by Eq. (2); Wi, the relevant weight for dimension i, is calculated by Eq. (3); Smax is the maximum value for the satisfaction score—10 in this case; n is the number of dimensions in this study—8 in this case. In Eq. (2), Sj is the satisfaction score in j question; m is the number of dimensions in dimension i. In Eq. (3), Ii is the mean importance score in dimension i and is calculated by Eq. (4), in which Ij is the importance score of j question; and m is the number of dimensions in dimension i. In the TSPM scale, a score above 8 is in the interval of very satisfied area and a score between 6 and 8 is in the satisfied area. Table 3 presents the values for calculating the TSPM index in the studied cases.Pn	i¼1ðSiWiÞ	100%,	(1)TSPM ¼SmaxPmj¼1SjSi ¼ ,	(2) mIiWi ¼ Pn	,	(3)  I i¼1 iPmj¼1IjIi ¼ .	(4) m  According to the developed TSPM index, the TSPM value in Taiwan is 6.99. The CPM service in Taiwan falls in the interval of satisfied. This is in accordance with the results obtained by the importance-performance matrix that uses the respondent overall impressions as scores. These analytical results indicate that service providers must provide more effective and efficient services to earn client  
2.002.00 4.00 6.00 8.00 10.00Mean SatisfactionFig. 9. Importance–performance relationship of post-service stage.Table 3StageDimensionMean importance score IiWeight Wi (%)Mean satisfaction score SiWeighted dimension satisfaction scoreIn-serviceCost7.6812.706.770.8598Quality7.2411.976.980.8357Time7.3912.226.970.8518Communication7.9513.157.180.9440Technique/Tool7.6012.577.050.8861Post-serviceScope————Cost7.7912.887.510.9675Quality7.3012.076.920.8354Time7.5212.446.550.8146Calculation information for TSPMtrust and satisfaction.7. Formal model development7.1. Factor analysis  To construct the formal evaluation model for CPM services, this study employed factor analysis technique to identify essential factors. This analysis is made by using the results of mean value analysis depicted above.  Factor analysis technique attempts to reduce the number of variables and to detect the structure from the relationships between variables; that is, factor analysis is applied as a means of data reduction or structure detection. Factor analysis can be either exploratory or confirmatory in nature. The objective of exploratory factor analysis is to distinguish the common factors from specific factors and to explain their relationships according to the observed data [27]. As the employed process of questionnaire development is a forward thinking process and the correlations between questions are unclear, this study used the factor analysis technique to identify the structure of the satisfaction evaluation model. The processes of factor analysis include factor extracting, factor loading, factor rotating and factor labeling.7.1.1. Factor extracting  To extract common factors reflecting raw data, this study used the method of principal components factoringTable 4Factor analysis results for the in-service stageto calculate the eigenvalues, communality and factorloading coefficient of factors for further analysis. The calculation was run in SPSSs software. Kaiser’s Rule [28], which recommends retaining only principal components with eigenvalues exceeding unity, was used to remove some insignificant factors, 39 factors in the in-service stage and 19 factors in the post-service stage were utilized for factor analysis.7.1.2. Factor loadingNo. of	Variance question	accountedfactor (%)for (%)Factor 1Factor 2Factor 3Factor 4Factor 5Factor 6AD3*18.43547.2747.270.8530.1050.2590.2530.1450.902AE10.7550.3200.4380.1970.910AD50.7470.2140.2440.2440.2680.827AD70.7370.2160.2310.668AD10.7160.3720.2950.2320.3990.967AA80.6290.4390.2210.767AE30.5360.4730.3080.1740.1610.789AC73.5048.9856.250.1490.9130.2020.1040.910AC60.8570.1440.1570.826AB130.1640.8230.2640.2350.1860.2400.930AC30.4180.6840.2890.2720.1800.837AC40.4360.5770.2100.2780.4270.844AC50.1900.5700.5090.1920.2540.736AB160.4950.4330.3910.758AB92.8577.3363.580.3100.6980.1330.4690.856AB110.2440.2810.6780.2120.1170.4100.886AA60.4420.6430.2950.2920.1930.824AB120.4840.3430.6190.2180.2680.878AA40.6160.5420.2890.1420.839AA70.4550.2190.6090.5160.896AB100.1590.2510.6070.3790.1380.2060.847AA10.5510.1540.5880.707AB62.4636.3169.890.1910.7710.1850.767AB10.3600.1180.7070.1580.687AB50.1590.1740.2960.7000.3770.790AA30.1390.3210.6820.1220.4700.899AA50.3770.1250.5250.6380.848AD40.4770.3070.1230.5810.3560.846AA90.3960.1170.3620.4880.666AA20.1600.2210.2470.4870.1110.800AE42.0075.1575.040.1790.1030.8990.890AB70.2290.1440.1060.8830.2130.914AC10.1220.1760.4450.2720.6630.830AD20.5740.2450.1710.5880.2120.818AD60.2580.4770.4080.5690.3540.916AD80.4380.4900.2260.1280.5680.2380.918AC91.8564.7679.800.2150.2440.1820.8690.898AB200.1870.1440.3770.7590.787AB30.2620.1930.3340.2440.2960.5970.799Note: *: AD3, the third question in forth dimension of first stage.  Tables 4 and 5 are the factor-loading matrices for the inservice and post-service stages, respectively. The values in
the columns of factor name are the correlations between original variables and common factors. Using the results of factor loading, the communality (the proportion of variation in each test accounted for by the factors) can be calculated subsequently. The community in each new dimension is greater than 0.70, which is an acceptable level.7.1.3. Factor rotating  In factor analysis, the common factor model has an infinite number of solutions; therefore, rotating the factor solution plays a key role in finding a more meaningful solution. Kaiser’s Varimax Rotation [29] was applied for factor rotation to achieve a simple structure by focusing on the columns of factor-loading matrix. After numerous scenarios of factor analysis by SPSSss software, the analytical results reached a stable status (all eigenvalues are meaningfully different from zero [27]).7.1.4. Factor labeling  Because the accumulated accounting variance is greater than 75%, the numbers of retained factors (new dimension) in the two stages are 6 and 3, respectively. This study relabeled the factors as follows: (1) ability for change management (accounting for 42.27% of the variance), (2) ability for schedule management (accounting for 8.98% of the variance), (3) ability for resource management (accounting for 7.33% of the variance), (4) ability for data inspection (accounting for 6.31% of the variance), (5) team performance (accounting for 5.15% of the variance) and (6) ability for other activities (accounting for 4.76% of the variance) in the in-service stage; and (1) achievement of in-Table 5BC311.66255.5355.530.9350.891BC10.8650.1430.2150.815BC80.8600.3330.858BC70.8240.1700.807BD20.7700.3870.783BD50.6300.3860.1440.788BD60.5990.4620.3320.684BC60.5920.2720.2730.788BC20.5870.3690.3790.747BB32.74313.0668.600.1330.9080.900BB20.1830.8700.1890.913BB10.3800.8230.2810.917BD70.7090.1580.836BD90.3680.5630.3440.813BD80.4390.5620.4620.737BC41.8408.7677.360.1530.9420.924BD30.3390.1910.8700.944BD40.1780.2310.7830.865BC50.1630.2750.7590.932Factor analysis results for the post-service stageservice activities (accounting for 55.53% of the variance), (2) achievement of construction payment and inspection (accounting for 13.06% of the variance) and (3) achievement of construction tendering (accounting for 8.76% of the variance) in the post-service stage.7.2. Model framework  After extracting the essential factors, the model framework was constructed. Fig. 10 shows the proposed model structure with the evaluation items. The in-service stage has 6 dimensions with 39 evaluation items and the post-service stage has 3 dimensions with 19 items.8. Conclusions and suggestions  Success of a consulting firm depends on its ability to satisfy customers. Firms must redefine their bottom lines by using client satisfaction, high-quality standards, and profits as their top priorities in today’s extremely competitive markets. For clients and service providers, developing an appraisal system for achieving their needs in service transaction is the most effective means of achieving project success. This study presented a customer satisfaction evaluation model that should benefit both clients and service providers in developing their own appraisal systems and serves as a framework for further research in CPM performance evaluation. Although the model is just validated for Taiwan’s CPM environment, the development process and framework offer a valuable reference for	Stage	Dimension	Evaluation Item	ability for change 	· Regular consultant meeting· Interfaces coordination and integration· Review and recommendation of change orders· Involvement of service provider to client· Overall management ability· Examination or audit on construction payment · Handling of construction warrant interfaces· Control of project schedule· Forecast of project schedule· Management and coordination of schedules in different phases· Coordination and management of design schedule· Examination and supervision of construction schedule· Examination of construction feasibility study· Works of acceptance and transfer of project· Financial analysis and recommendation on the sources of finance· Evaluation on the source of required resources· Formulation of preliminary budget· Examination of construction budget· Assessment of tender documents· Assistance in tendering works· Assistance in signing contracts· Recommendation on the selection of providers for professional      services and technical service and formulation of related      documents · Development and control of service quality assurance system · Development of the chart of duty and authority of various providers      for professional services and technical service · Examination of environmental impact assessment reports· Examination of design, specifications, drawings· Examination of the payment of providers for professional services     and technical service· Reasonable analysis of resources prices· Examination of budgets of construction project and equipments· Audit of information on payment settlement· Schedule planning of project· Evaluation and recommendation of design requirements· Examination of interfaces of design and construction· Computerization of document management and construction 	     management· Evaluation of contract disputes and claims· Service attitude of project team members· Achievement of regular project meetings· Abilities of project team members in alternative study and      evaluation  · Collaboration of project team members· Service quality management system and achievement of quality     guarantee · Quality of value engineering reports· Achievement of examining construction plan· Schedule achievement of examining construction plan· Quality of schedule reports· Schedule achievement of schedule reports· Achievement of executing project meetings· Integrality of project minutes· Achievement of managing construction documents and contracts· Accuracy of paymentconstruction payment · Schedule achievement of payment· Integrality of payment certificate· Schedule achievement of submitting acceptance reports · Schedule achievement of submitting as-built drawings and documents· Schedule achievement of project completion· Preparation of tender documents· Schedule control of tendering· Achievement of tendering works· Schedule control of signing contractsFig. 10. Evaluation framework for TSPM.evaluation and assessment of CPM performance in other contexts.  Different countries or economic entities may have different project delivery systems. Furthermore, the scope of CPM in each country or economic entity may be totally different in contents. Thus the developed model may not be appropriate for other countries or economic entities. To establish a universal appraisal system for CPM is impracticable. However, the PMBOK developed by PMI has recently been taken as a standard for project management. For the construction industry, the ‘‘construction extension to a guide to the project management body of knowledge’’ [30] can be regarded as a common basis for construction project management. To develop an appraisal system for the CPM service in accordance with the knowledge areas of PMBOK’s construction extension would benefit service buyers or providers in the future.References[1] Hellard RB. Total quality in construction projects: achieving profitability with customer satisfaction. London: Thomas Telford; 1993.[2] National Institute of Standards and Technology (NIST). Criteria for performance excellence /http://www.quality.nist.govS [accessed August 15, 2004].[3] Kubal MT. Engineered quality in construction: partnering and TQM. New York: McGraw-Hill; 1994.[4] Barrie DS, Paulson BC. Professional construction management. Journal of the Construction Division, ASCE 1976;102(3):425–36.[5] Barrie DS, Paulson BC. Professional construction management: including C.M., design-construct, and general contracting. 3rd ed. New York: McGraw-Hill; 1992.[6] Madsen JD. Professional construction management services. Journal of the Construction Division, ASCE 1979;105(2):139–56.[7] Tatum CB. Issues in professional construction management. Journal of Construction Engineering and Management, ASCE 1983;109(1):112–9.[8] Yang JB, Wang WC. Contractor selection by the most advantageous tendering approach in Taiwan. Journal of the Chinese Institute of Engineers 2003;26(3):381–7.[9] Public Construction Commission, Executive Yuan, Taiwan. /http:// www.pcc.gov.tw/S [Accessed June 15, 2005].[10] Fornell C, Johnson MD, Anderson EW, Cha J, Bryant BE. TheAmerican customer satisfaction index: nature, purpose, and findings. Journal of Marketing 1996;60(4):7–18.[11] Johnson MD, Herrmann A, Gustafsson A. Comparing customer satisfaction across industries and countries. Journal of Economic Psychology 2002;23(6):749–69.[12] Ahmed SM, Kangari R. Analysis of client-satisfaction factors in construction industry. Journal of Management in Engineering, ASCE 1995;11(2):36–44.[13] Maloney WF. Construction product/service and customer satisfaction. Journal of Construction Engineering and Management, ASCE 2002;128(6):522–9.[14] Maloney WF. Labor-management cooperation and customer satisfaction. Journal of Construction Engineering and Management, ASCE 2003;129(2):165–72.[15] Torbica ZM. Total Quality Management (TQM) and customer satisfaction in home building. PhD dissertation. University of Florida, Gainesville, Florida, 1997.[16] Torbica ZM, Stroh RC. HOMBSAT—an instrument for measuring home-buyer satisfaction. Quality Management Journal 2000;7(4): 32–44.[17] Torbica ZM, Stroh RC. Customer satisfaction in home building. Journal of Construction Engineering and Management, ASCE2001;127(1):82–6.[18] Torbica ZM, Stroh RC. Impact of total quality management on home-buyer satisfaction. Journal of Construction Engineering and Management, ASCE 1999;125(3):198–203.[19] Power JD. Associates. New-home builder customer satisfaction study. Agoura Hills, California /http://www.jdpa.comS [accessed May 31, 2004].[20] Liu AMM. Residential satisfaction in housing estates: a Hong Kong perspective. Automation in Construction 1999;8(4):511–24.[21] Tang SL, Lu M, Chan YL. Achieving client satisfaction for engineering consulting firms. Journal of Management in Engineering, ASCE 2003;19(4):166–72.[22] Leung MY, Ng Thomas S, Cheung SO. Measuring construction project participant satisfaction. Construction Management and Economics 2004;22(3):319–31.[23] Hayes BE. Measuring customer satisfaction: survey design, use and statistical analysis methods. Milwaukee, Wisconsin: ASQC Quality Press; 1997.[24] Project Management Institute. A guide to the project management body of knowledge (PMBOKs Guide). 2000 edition. Newtown Square, PA, 2001.[25] Nunnally JC, Bernstein IH. Psychometric theory. 3rd ed. New York: McGraw-Hill; 1994.[26] Martilla JA, James JC. Importance–performance analysis. Journal of Marketing 1977;41(1):77–9.[27] Lattin JM, Carroll JD, Green PE, Green PE. Analyzing multivariate data. Pacific Grove, CA: Thomson Brooks/Colec; 2003.[28] Kaiser HF. The applications of electronic computers to factor analysis. In: Proceeding of the, application of Computers to psychological problems. American Psychological Association; 1959.[29] Kaiser HF. The varimax criterion for analytic rotation in factor analysis. Psychometrika 1958;23:187–200.[30] Project Management Institute. The construction extension to a guide to the project management body of knowledge (PMBOKs Guide).2000 edition. Newtown Square, PA, 2003.ARTICLE IN PRESS460	J.-B. Yang, S.-C. Peng / Building and Environment 43 (2008) 458–468  ARTICLE IN PRESS	J.-B. Yang, S.-C. Peng / Building and Environment 43 (2008) 458–468	459  ARTICLE IN PRESS  