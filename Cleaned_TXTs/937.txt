*Department of Civil & Building Engineering - Loughborough University
**Department of Social Sciences - Loughborough University
†School of the Built Environment - University of Glamorgan
There have been many recent calls for greater use of qualitative methods in construction management research, or at least for greater consideration to be given to the use of these methods if appropriate. However, for many researchers, particularly those using methods involving a very thorough, in depth data gathering exercise, and a fairly free-form approach to the collection instrument, this can lead to practical analytical problems through the generation of overwhelming amounts of qualitative data, and potential difficulties of working with a number of complex data sets. Increasingly, qualitative data is becoming far more diverse than simple transcribed information from interviews, and now encompasses a wide range of data from different sources, such as participant and non-participant observation field notes, video recordings and other graphical media. Whilst the combination of such data can greatly enhance qualitative and compliment quantitative studies, making sense of the emerging issues is difficult in terms of remaining organised, rigorous and systematic in the analysis. This paper discusses the problems inherent with qualitative data analysis, and describes the authors' experience of dealing with such data using the most popular computer package currently available to qualitative researchers; NUDISTTM.  The research used NUDIST as part of an analytical strategy which combined several distinct data sets, including a substantial amount of semi-structured interview data. The paper concludes by discussing the particular relevance of such packages for construction management researchers, and other issues concerning qualitative data analysis.
Data analysis, qualitative methodology, software.
INTRODUCTION - A  PARADIGM SHIFT IN CONSTRUCTION MANAGEMENT RESEARCH?
Many recent papers and articles have sought to open up the debate surrounding the construction management field’s apparent historical obsession with methodological assumptions which could be said to be grounded in the rationalist paradigm (Seymour & Rooke 1995; Edum-Fotwe et al 1996, Loosemore et al 1996). In particular, there are concerns that attempts to provide objective accounts of social reality cannot be achieved using only rationalist methodologies.
This paper does not seek to enter the debate over the various pros and cons of different methodological approaches, nor does it offer opinion on construction management’s apparent epistemological identity crisis (see Loosemore 1997). Rather, this paper assumes, that as the debate continues construction management researchers are likely to move towards a more balanced methodological approach in common with other
Dainty, A R J, Bagilhole, B M and Neale, R H (1997) Analytical strategies for dealing with qualitative data in construction management research. Stephenson, P (Ed.), 13th Annual ARCOM Conference, 15-17 September 1997, King's College, Cambridge. Association of Researchers in Construction Management, Vol. 2, 484-93.
applied fields (Miles & Huberman 1994), and as a result there will be an increasing diversity in the type of data collected, and subsequently, greater analytical challenges will emerge.
We believe that there is a danger, that the attraction of interpretativist methodologies may lead construction management researchers to designing research projects without giving adequate consideration to how they will analyse the data that they collect. Miles & Huberman (1994) warn that, whilst qualitative data may be “sexy”, and data analysis techniques and procedures have come a long way over the past ten years, that many of the pervasive issues concerning analysis have not gone away (e.g. data overload, labour intensiveness, researcher bias, the problems of ensuring generizability). In some respects, the purpose of this paper is to act as a caveat to researchers about to climb aboard the interpretativist band-wagon, and to look beyond the epistemological arguments towards the practical issues of how they deal with their data, and ultimately how they convince others of the validity and reliability of their explanations of the social phenomena under investigation.
It was not appreciated at the outset of the authors’ project that such a large amount of data would be collected, which would be so rich and holistic that it made effective analysis using manual analytical techniques impossible within the available timeframe. As Miles (1985: 117-134) succinctly puts it:
“Collecting and analyzing the [qualitative] data is a highly labor-intensive operation, often generating much stress, even for top quality research staff.... qualitative data tend to overload the researcher badly at almost every point: the sheer range of phenomena being observed, the recorded volume of notes, the time required to writeup, coding and analysis can all become overwhelming. But the most serious and central difficulty in the use of qualitative data is that the methods of analysis are not well formulated.”
Miles (1979) famously described qualitative data as an ‘attractive nuisance’ because of the associated difficulties with collecting and analysing it effectively. It could be assumed that, judging by the apparent propensity of construction management researchers to apply quantitative analysis techniques to qualitative data, such as content analysis (see Krippendorff 1980), many have faced similar problems. Prein & Kuckartz (1995: 152-157) highlight the inadequacy of such approaches for exploring most social situations and cite the example of where words are either ambiguous or context dependent as instances where content analysis is inadequate for finding meaning in such data. Thus, it now seems appropriate to open the debate on how researchers in construction management can analyse such data.
A key problem of many qualitative studies are that few discuss the process of data management and theory construction in-depth. Richards (1996†) for instance, is critical of research reports which offer no reflexive assessment of how particular packages assisted or hindered research or impacted on the research process, and especially where researchers appear to try to justify their method by merely naming the package that they used. Hence, at each stage of the project, we have tried to assess the research process facilitated by NUDIST, in terms of the effects on the research and researchers. Thus, whilst this paper does not seek to enter a debate as to the suitability of techniques such as interviewing as a source of data (see Bryman 1992 for a full discussion),  it attempts to give researchers an insight into the advantages and disadvantages of contemporary analysis packages and seeks to stimulate discussion on what is becoming an increasingly significant issue for construction management researchers.
As mentioned above, the authors’ research has involved the collection of several diverse data sets, which are being combined and analysed simultaneously in order to improve the generizability of our findings. Triangulation of data improves the reliability and validity of the data in two ways: by the systematic combination of different methods; and through using different data sources. Triangulation can reduce the likelihood of the researcher drawing erroneous conclusions through an overreliance on a single data set or technique, increasing the probability that the social explanations produced have wider resonance, and not be limited by the empirical parameters of the study (Mason 1996; Dainty 1996).
Whilst triangulation can be seen as an approach to combine different methods of data collection to give a different perspective of the phenomena under investigation, Bryman (1988) suggests that researchers will usually wish to confirm or disconfirm their previous results, or establish a more complete picture through the use of different strategies. Thus, the implementation of a mixed-method approach will usually involve the division of the research into two component parts (Prein & Kuckartz 1995). Mason (1996) criticises this approach, in that different methods and data sources are likely to give different explanations of different phenomena, and are unlikely to corroborate each other. However, she also acknowledges that approaching research questions from different angles does enhance validity, because it acknowledges that the phenomena have more than a single dimension, and demonstrates that research has grasped more than one of those dimensions. Thus, whilst the use of multiple methods will not demonstrate validity of method per se, it should enhance understanding of the phenomena under investigation.
The problems inherent in combining hermeneutic methods with techniques aimed at reducing and standardising data, are that assumptions have to be made which imply homogeneity in all cases under investigation. There is a case, therefore, for the combination of different qualitative methods, particularly when the aim is to address differing ontological levels through differing methods of enquiry, and where the researcher is clear in how they will link these levels (see Mason 1996; Denzin 1989). Two problems occur in the combination of different data collection techniques; the use of multiple methods can lead to the collection of vast amounts of data, and the analysis must effectively combine the findings of the research in pursuit of the same research aim to data that potentially require very different analytical techniques. Increasingly, therefore, researchers have looked towards computers to facilitate and automate some of the analytical processes.
COMPUTER AIDED ANALYSIS AND THE ETHNOGRAPHIC RESEARCHER
It was once thought that computer aided analysis of ethnographic data could lead to trustworthiness, systematic methods and remove subjectivity and a journalistic style of enquiry (Kelle 1995). Whilst it is now generally accepted that current packages cannot achieve this by themselves, there is general agreement in the literature that using some form of computer aided analysis is likely to enhance the quality of this type of research.
A fundamental problem had existed until the computer revolution in qualitative data analysis, that there has to be a trade-off between the number of cases that the researcher investigates and the number of attributes that can be studied within those cases (Ragin 1994). Whilst to some extent this is still the case when using computers, the fact that more data can be handled effectively, brings the researcher closer to being able to simultaneously study phenomena both extensively and intensively. Kelle (1995) argues that computer-aided analysis offers the potential for increasing sample sizes, with the associated benefits of enhancing validity through the increased likelihood that the research will be representative of the population being studied, and not reliant on potentially anecdotal accounts from informants whose opinions may not reflect the overall population.
A plethora of different packages are now available for qualitative researchers (see Weitzman & Miles, 1995 for an excellent critique of the packages available). All offer features and searching operators with varying degrees of complexity and allow the researcher to manipulate the data in a variety of different ways. Most computer aided methods enhance the validity of research findings in two ways - in assisting the management of data from larger samples, and offering the facility to code and retrieve all data on a particular topic (Kelle, 1995). As such, they free the researcher of mundane organisational and mechanical tasks, and allow more time for the interpretative work. Furthermore, unlike human minds, the computer will not become tired and miss data during the analysis (Agar 1993; Weaver and Atkinson 1994).
Richards (1996) sees researchers who avoid the use of computers in qualitative analysis as severely disadvantaging themselves, stating that they run the risk of merely producing “signposts for future research” as opposed to confident results. Moreover, she sees the debate of whether computers can aid qualitative researchers as having moved on considerably in recent years, to the question: how they can help?
“The debate about whether to compute in qualitative research seems to be over. It never really began. The advantages of computers for managing messy data records are obvious, wherever variety of records and richness of accounts challenge researchers. All researchers working in qualitative mode will be clearly helped by some computer software.... computing [is] unavoidable for most researchers”.  (Richards, 1996)†.
Thus, there can be seen to be a strong supporting case for using computers, as long as a package is selected which is appropriate for the analytical needs of the study. However, there are also counter views.
CRITICISMS OF COMPUTER AIDED QUALITATIVE DATA ANALYSIS
Weaver and Atkinson (1994) warn that the codification procedures that computer packages tend to facilitate are bound to restrict the diversity of approaches available to qualitative researchers. Fielding and Lee (1991) also warn of the dangers of focusing on a particular view of analysis through these packages; also focusing on the codification techniques, that is, where the data are broken down and assigned a conceptual label and the text chunks are then retrieved and linked in new ways. A criticism of these cataloguing or ‘indexing systems’, is that they are not analytically neutral, as the researcher has to make assumptions as to what kinds of phenomena are being indexed, and in what form they will be retrieved (Mason, 1996). Furthermore, there is also a danger that every piece of coded text will address more than one concept at one time, and so the links between coded categories may become extremely complex. If the researcher moves too far away from the data through the codification process, this may lead to erroneous findings, as data may be taken out of context.
Furthermore, it should be borne in mind that computer packages can never replace the intuition of the researcher, or the subjective judgements which are a key characteristic of qualitative research. They should only be looked upon as a tool to facilitate the coding and effective searching of the data. Thus, while computer packages may allow the researcher to conduct searches with large and diverse data sets which would be impossible using manual techniques within realistic time scales, the researcher must not be under any illusions about the time and effort that they will still have to spend coding, searching and developing testing ideas and theories within the data. However, their use does encourage self assessment by the researcher, as they lead to a greater awareness of the processes involved (Tesch 1990; Weaver and Atkinson 1994). This paper is testament to this having been the case during the authors’ research.
THE PROBLEM - THE AUTHORS’ RESEARCH
The authors on-going research is examining the determinants of male and female construction professionals’ career patterns, to establish reasons for apparent disparities in career progression rates, and initiatives developed to improve professionals’ retention to large contracting organisations. The research adopts the Grounded Theory approach, where what is relevant to the area of study under investigation is allowed to emerge from the data (Glaser & Strauss 1967, Strauss and Corbin 1990). This approach aims to develop theory which is faithful to everyday reality, and as such needs to be induced from diverse data. The method advocates assigning codes, or conceptual labels to the data, and then relating them through statements of relationship. Nothing should be assumed about the phenomena under investigation, and the researcher tries to understand the complex social systems under investigation (in this case career development in construction companies) and the part that the actor plays in shaping it.
Accordingly, the majority of the data collected to date is tape recorded interview data in a semi-structured format that has been transcribed verbatim. Ninety two interviews have been carried out in which the informants have been encouraged to talk about their career experiences in their own frame of reference. This non-directive interview style led to the collection of interesting and diverse career histories. In total, over one million words have been transcribed from the interviews alone. The nature of the data is fairly ‘messy’, with the interviews varying greatly in their length and the language used (principally because the informants came from a large variety of professions, hierarchical positions and different career stages), and being from different organisations. The sheer volume of the data when transcribed was daunting, but the interviews were carried out until the point of data saturation had been achieved, and no new organisational issues pertaining to the phenomenon under investigation were emerging from the data (Glaser & Strauss 1967).
Over-reliance on the interview data was seen as a potential weakness of the research, as this research design would have assumed that the data elicited from the informant would fairly reflect their outlook and attitudes over their entire career. This approach would not, therefore, have taken account of their disposition at the time of the interview, which was particularly significant since the majority of the interviews were conducted during the economic recession, when their opinions of their employer and the industry may have been affected by job insecurity. Accordingly, the interview data were enhanced with longitudinal data from career experience diaries, completed by a selection of the career histories group over a period of 4 months. Here, the informants were asked to follow a set format for the diary entries, although their length and depth of  were highly variable.
Other data collected included: general field notes taken during the interviews; career determinant graphs constructed by the informants to give an objective overview of their career progression; document memos and coding notes taken during the coding process; the informants CVs; financial information and organisational charts of the participating companies; feedback from a postal questionnaire to the original informants on the applicability of the recommendations put forward; pilot study data collected during the development of the research instrument; and correspondence with some of the construction professionals who had taken part in the research. The problem here, therefore, was firstly how to analyse such a massive amount of ‘messy’ textual data, and secondly how to simultaneously combine and analyse  the data from the interviews with the longitudinal data from the diaries, and other non-imputable data such as the organisational charts and career history graphs.
Some form of computer aided solution seemed essential, but the decision to use ‘Nonnumerical Unstructured Data Indexing Searching & Theorising’ (NUDISTTM) was not taken arbitrarily, as the authors wanted to ensure that the package chosen would compliment the data collected and methods employed. The authors’ chosen analytical strategy, to use Grounded Theory techniques, demanded a coding-oriented approach to the analysis. Mason (1996) recommends this approach when data are predominantly text based, where issues do not appear in an orderly manner in the data and where the researcher wishes to establish whether the data address the theoretical concerns of the research. These were all major concerns of this project. Furthermore, there was the need able to handle the combination of the different data sets, with the facility to include reference to data unsuitable for inputting into a computer. Hence, the selection of a code-oriented package seemed the most logical choice.
The decision to select NUDIST from the code-oriented packages available was fairly easy. It was the best selling package on the market. Weitzman and Miles (1995) ranked NUDIST* as one of the top 2 or 3 programmes for coding-oriented analysis, and in particular rated its searching capabilities as more sophisticated than any of its competitors. Version 3.0 boasts some 18 searching operators for investigating links between conceptual labels in the system. The package allows memos to be created for each document and conceptual label developed, which can in turn be indexed, searched and built back into the system. This is one of several ways in which NUDIST facilitates ‘system closure’ an essential aspect of Grounded Theory research, where results of searches and analyses are fed back into the analysis rather than being taken out of the system. As such, findings are built up cumulatively, leading to the linking of findings, and the eventual development of explanations which reflect the complex nature of social phenomena.
NUDIST’s ability to handle off-line data was also a feature which made it stand out from the majority of the available programmes, as it allows the effective integration of data as diverse as video recordings, books and tape recordings, as well as text based data. The simultaneous analysis of such data can significantly enhance the reliability and validity of the research, and this feature was seen as useful for including the CVs, organisational charts and career history graphs in the analysis. A final reason for selecting NUDIST, was the fact that we could remain in close proximity to the data. In particular, it was possible to examine the raw text files in their original form, even after they had been broken down and fully coded. This proved useful when trying to find general concepts or explanations in single cases, and for comparing the career profiles and perspectives of particular individuals and not across the entire data set.
Analysis using NUDIST involves the creation of a bespoke ‘index system’, a hierarchical ‘tree’ of issues spanning downwards, each node of which will eventually contain coded text chunks of data assigned by the researcher, and references to nontextual data which are stored outside of the system (such as tape count numbers on video cassettes, references to books etc.). Data is inputted in its original state, assigned a conceptual label (or labels if the piece of data spans several issues), and is then placed under an appropriate node within the system. The index system is totally flexible and can be manipulated by the researcher by cutting, pasting, deleting and merging nodes (and the data that they contain) together. Searching and testing ideas in the data is done in two ways: firstly, through text searches using either simple ‘string-searches’ or sophisticated ‘pattern-searches’ which look for text matches of patterns of characters; and through ‘index system searches’, where links between the conceptual labels created in the index system are investigated by the use of Boolean and other more complex search operators. As findings and ideas are generated, they are built back into the system and become part of the data being analysed. The screen shot below shows the NUDIST project environment, a section of the index system from the authors’ project (with edit menu) and an overview of the entire index system (top left of tree section.)
Gaining a basic understanding of using the package was aided by attendance at a residential course run by one of the developers of the package. However, the software was relatively easy to use, once the intricacies of developing and manipulating the ‘index system’ had been mastered. The coding process was long and laborious, and even when proficient at using the software, on average it took 8.5 to 9 hours to code a single interview of around 15,000 words. The physical amount of data that NUDIST will handle is only restricted by the size of the hard-drive of the computer (QSR
1996), and the speed of simple text and index system searches was impressive, although it was found that when all 92 transcripts were coded into the package that the retrieval times on complex searches could take several minutes to complete**.
NUDIST facilitated the research in several ways, but particularly in the handling of the massive amount of data collected. Despite the length of time that it took to code the transcripts, this process gave the researchers the opportunity to really get to know the data and get a good appreciation of the recurring issues and themes before starting to explore the data set. Combining the other textual data was also easy, and the diary data was coded into the index system in an identical manner, allowing its analysis to be carried out simultaneously. The creation of a sub-tree within the system, also allowed it to be searched independently of the rest of the data. Whilst the capacity of the software to allow reference to data not stored in the package was useful, in practice, the cumbersome nature of having to refer to a filing cabinet to retrieve such data whilst trying to search and combine data at the same time, meant that this data was generally integrated into the research as a distinct exercise following the NUDIST analysis.
The central weakness of NUDIST as far as we were concerned was the reliance on having to set up the software’s unit of analysis at the outset of the project. The ‘textunit’ is the smallest amount of data that NUDIST can analyse, and most researchers tend to set this at one text line, or one paragraph of data. The problems arise when retrieving coded sections, where the user is forced to have to retrieve data around that which he/she actually wants. Whilst in some cases this is useful for establishing the context of sections of text, on some occasions where there had been many comments on a particular issue, it involved sifting through many pages of irrelevant data. Furthermore, we found many of the searching facilities of limited use in our analysis (although it is acknowledged that this will not be the case for all projects), and we also found the package’s ‘command files’ feature (where particular coding and searching processes can be automated to speed up the analysis), very hard to develop.
However, overall we found the package user friendly, and after the coding had been completed, good fun to use. This was important because it held the researchers interest in the analysis, particularly because it was so simple to look for links and correlations in the data that would have seemed too obscure or unlikely to exist to warrant trying if manual techniques were being used. The result was that a large number of different searches were carried out, most of which did not lead to significant findings, but others demonstrated significant and unexpected complex organisational and social behaviour which has led to more comprehensive findings being generated. Furthermore, the potential of the text searching operators for those wishing to carry out a full linguistic analysis of the data, or for automating content analysis, are obvious. Even if the researcher does not want to use NUDIST’s other searching and theorising features, we suggest that the package be considered purely for these reasons.
PARTICULAR ISSUES FOR CONSTRUCTION MANAGEMENT RESEARCHERS - THE METHODOLOGICAL IMPACT OF COMPUTER USE IN QUALITATIVE RESEARCH
Construction management as a field is currently undergoing a learning process in response to the calls for greater consideration to be given to qualitative methods, and as such, researchers are unlikely to have an in-depth knowledge of qualitative methods, or specialist analysis packages such as the one described in this paper. It is essential, therefore, that we begin a reflexive discourse on our experiences of ethnographic research and computer aided analysis in construction management research, so that the applicability of such packages can be fully understood.
We see two fundamental issues to be considered by researchers considering using computers in their analyses. Firstly, how will the techniques that they are forced into using when adopting a particular package, affect the quality and applicability of the findings and explanations developed, and secondly, how does the particular package selected facilitate the understanding and representation of the findings generated.
As mentioned above, a major criticism of qualitative data analysis programmes is that they tend to force researchers down particular analytical routes which may not be best suited to the data collected or the phenomenon under investigation. NUDIST was no exception, and whilst the code-oriented/system-closure approach was particularly applicable to Grounded Theory projects, it may not be for other research techniques. The hierarchical ‘tree’ structure used for conceptualising the emerging issues may be unsuitable for some projects, where non-hierarchical relationships between variables need to be explored. Inevitably, therefore, there has to be a degree of compromise.
How to represent qualitative findings is another problem for the qualitative researcher. Simister (1993) pointed out that one of the problems inherent within the richness of interview data is that analysis is precluded without a reduction in the form of data, if it is to be intelligible to a third party, and yet at the same time must convey the deep meanings that have emerged from the analysis. NUDIST was strong in this regard, as through its ‘vector’ and ‘matrix’ searching operators, qualitative cross-tabulations of issues could be constructed, which could then easily be transformed into matrix formats to summarise themes and trends for different informant groupings within the sample. Furthermore, the hierarchical tree which forms the basis of its index system is a powerful tool for demonstrating the location and significance of the issues emerging from the data. We would recommend substantial investigation into their data management and representational tools before a package is selected.
CONCLUSIONS
We found NUDIST an effective tool for data management, and found the hierarchical index system an excellent way to order thoughts and concepts during the coding process. However, the power of the searching operators available led to doubts over whether we could ever do the analysis of the data justice, as there is potentially an infinite number of different search combinations available, particularly when dealing with a large data set with many coded categories. As Richards & Simon (1993) state, “The confidence in routine data management, logging of research pathways, through retrievals, shifts anxiety from the ability to control the data to the ability to do it justice.”
The authors’ do not contend that qualitative research methods provide a more appropriate technique for construction managers, nor do we see qualitative and quantitative methods as being mutually exclusive (see Loosemore et al 1996, Van Maanen 1983: However, the move towards the use of more qualitative methods now seems inevitable, and so this paper urges researchers considering a qualitative study involving the collection of a large amount diverse data, to fundamentally question how they plan to draw meaning from the data that they collect (Miles and Huberman 1994). It is only through debating these analytical issues, and through being reflexive about our analyses and techniques, that we are likely to improve the quality and validity of our research, and produce research that leads to practical benefits for the industry.
* Version 3.0 for  Microsoft Windows was used in this project and is the version reviewed by Weitzman & Miles (1995). Version 4.0 was released shortly before submission of this paper which includes many enhanced features including a revised user interface.  ** The researchers were using a Pentium 133 with 1GB hard Drive and 8MB RAM, † Prof. Richards is co-developer of NUDIST.
Agar, M. (1983) Microcomputers as Field Tools. Computers in the humanities, 17, 19-26.
Bryman, A.E. (1988) Quantity and quality in social research.
Bryman, A.E. (1992) Research methods and organization studies. Unwin Hyman.
Dainty, A.R.J. (1996) Structural and cultural determinants of men’s and women’s career progression in the construction industry. In Proc. ARCOM Human Resource Issues Workshop, Nov 1996, 1-21.
Denzin, N.K. (1989) The research act: a theoretical introduction to social methods, London:
Edum-Fotwe, F.T. Price, ADF and Thorpe, A, (1996) Research method versus methodology:
achieving quality on scholarly research for construction management. A.Thorpe (Ed.), In Proc. 12th Annual ARCOM conference, Sheffield Hallam. 428-438.
Fielding, N.G. and Lee, R.M. (Ed.s), (1991) Using computers in qualitative research, London:
Glaser, B.G. and Strauss, A.L. (1967) The discovery of grounded theory: strategies for qualitative research, London: Weidenfield & Nicholson.
Kelle, U. (1995) Computer aided qualitative data analysis: theory methods and practice, London:
Krippendorff, K. (1980) Content analysis: an introduction to its methodology, London:
Loosemore, M. Hall, K. and Dainty A.R.J. (1996) Innovation and courage in construction management research. A.Thorpe (Ed.), In Proc. 12th Annual ARCOM conference Sheffield Hallam. 418-427.
Loosemore, M. (1997) An identity complex in construction management research - practical and conceptual problems. In 3rd International Electronic Forum on Research & Education for Construction (keynote).
Mason, J. (1996) Qualitative Researching, London:
Miles, M.B. (1979) Qualitative data as an attractive nuisance: the problem of analysis. Administrative Science Quarterly, 24, 590-601.
Miles, M.B. (1985) Qualitative data as an attractive nuisance: the problem of analysis. In Qualitative Methodology. J Van Maanen (Ed.).
Miles, M.B. and Huberman, A.M. (1994) Qualitative data analysis: an expanded source book, California:
Prein, G. and Kuckartz, U. (1995) Computers and triangulation. In computer aided qualitative data analysis: theory methods and practice, (U.Kelle Ed.), London:
Ragin, C.C. (1994) Construction social research: the unity and diversity of  method. Thousand Oaks/Lindon: Pine Forge Press.
Richards, L. (1996) Reflections on a three-year NUDIST project. RW.Burgess (Ed.), Studies in Qualitative Methodology, 5, JAI Press.
Richards, L. and Simon, D. (1993) Making the change: report from a project designed for qualitative computing, unpublished report.
Seymour, D.E. and Rooke, J.A. (1995) The culture of the industry and the culture of research, Construction Management & Economics, 13, 511-523.
Seymour, D.E., Crooke, D. and Rooke, J. The role of theory in construction management: a call for debate. Construction Management & Economics, 15, 117-119.
Simister, S. (1993) Computer aided analysis of interviews for construction management research. R.A. Eastham and R.M. Skitmore (Ed.s), Proc. 9th Annual ARCOM conference, Salford, 198-204.
Strauss, A.L. and Corbin, J. (1990) Basics of qualitative research, California:
Van Maanen, J. (1983) Reclaiming qualitative methods for organizational research. In qualitative methodology, (J Van Maanen Ed.).
Weaver, A. and Atkinson, P. (1994) Micro-computing and qualitative data analysis, Aldershot:
Weitzman, E.A. and Miles, M.B. (1995) Computer programmes for qualitative data analysis. California:
Dainty, Bagilhole and Neale
Analytical strategies for dealing with qualitative data
