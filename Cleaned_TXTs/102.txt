Extraction of decision alternatives in construction management projects: Application and adaptation of NSGA-II and MOPSO
a Department of Irrigation & Reclamation Engineering, Faculty of Agricultural Engineering & Technology, College of Agriculture & Natural Resources, University of Tehran, Karaj, Tehran, Iran b Department of Engineering, Shahrekord University, Shahrekord, Iran c Department of Land, Air & Water Resources, Department of Civil & Environmental Engineering, and Department of Biological & Agricultural Engineering, University of California,
139 Veihmeyer Hall, University of California, Davis, CA 95616-8628, USA
Time-cost-quality trade-off
The time-cost trade-off problem is a known bi-objective problem in the field of project management. Recently, a new parameter, the quality of the project has been added to previously considered time and cost parameters. The main specification of the time-cost trade-off problem is discretization of the decision space to limited and accountable decision variables. In this situation the efficiency of the traditional methods decrease and applying of the evolutionary algorithms is necessary. In this paper, two evolutionary algorithms that originally search the decision space in a continuous manner including: (1) multi-objective particle swarm optimization (MOPSO) and (2) nondominated sorting genetic algorithm (NSGA)-II, are considered as the optimization tools to solve two construction project management problems. These problems are both in discrete domain including two or tree objectives, separately. In this regard, some procedures has been suggested and then applied to adopt both algorithms capable in solving the problems in a discrete domain. Results show the advantages and effectiveness of the used procedures in reporting the optimal Pareto for the optimization problems. Moreover, the NSGA-II is more successful in determining optimal alternatives in both time-cost trade-off (TCTO) and time-cost-quality trade-off (TCQTO) problems than the MOPSO algorithm.
2011 Elsevier Ltd. All rights reserved.
Introduction
Simulation and optimization models can provide solutions to many problems in the field of operations research. Although simulation models are based on trial and test methods followed by engineering judgment, final solutions may not be optimal. In contrast, optimization models can yield optimal/near-optimal solutions by searching a part or an entire decision space. Different singleobjective optimization methods such as linear (LP), nonlinear (NLP) and dynamic programming (DP) are capable to move toward optimal solutions. However, difficulties in determining optimal solutions, especially in some discrete or nonlinear problems, as well as the curse of dimensionality in solving the large-scale problems, are disadvantages of those optimization methods.
Corresponding author.
0957-4174/$ - see front matter  2011 Elsevier Ltd. All rights reserved.
Evolutionary algorithms are potential candidates to determine optimal/near-optimal solutions in the aforementioned problems. In these types of algorithms, random decision variables are produced as input data for a simulation model. Output data from
the simulation model can be used as input data for an optimization model. In such a process, newly-generated decision variables, based on previously calculated ones, can be improved. This process continues up to the maximum number of iterations for determining the best solution. Genetic algorithm (GA), particle swarm optimization (PSO), ant colony optimization (ACO), and simulated annealing (SA) are evolutionary algorithms that have been developed for solving optimization problems.
Multi-objective problems are another type of operations research problems which include a vector of objectives instead of a single objective. The main goal of multiobjective optimization techniques is to determine a set of optimal solutions, especially when objectives are conflicting. In traditional optimization methods, techniques such as the weighting approach are used in LP and NLP to produce just a single optimal point based on the considered weights. However, evolutionary algorithms can yield a set of nondominated solutions, Pareto, as the optimal solutions. Nondominated sorting genetic algorithm (NSGA), multi-colony ACO (MOACO), and multi-objective PSO (MOPSO) are some examples of multi-objective evolutionary optimization algorithms of this type.
The time-cost trade-off (TCTO) problem is a traditional bi-objective problem with a discretized decision space. Two existing objectives are minimization of: (1) the total cost and (2) the total time of project execution with respect to activity orders and relations and other management constraints. Thus there are different alternatives, from the best value of each objective to the worst one, satisfying the constraints and relations.
Solutions to the TCTO problem, especially using evolutionary algorithms as the optimization tool, have been reported by various investigators. Feng, Liu, and Burns (1997) categorized existing techniques for solving the TCTO problem in two mathematical and heuristic (evolutionary algorithms) methods. Li and Love (1997) used an improved GA to facilitate solving the TCTO problem. Hegazy (1999) used the GA to analyze the optimal time and cost of construction. Zheng, Thomas, and Kumaraswamy (2004) proposed adaptive weights derived from a previous generation for producing a search pressure toward the ideal point. Tareghian and Taheri (2006) developed a three interrelated binary integer programming technique for the TCTO problem. Rasmy, Abdelsalam, and Hussein (2008) applied a Pareto SA (PSA) algorithm to determine a set of nondominated solutions for the TCTO problem in the critical chain project.
Recently, maximization of equivalent quality of the project has been added to the time and cost as the third objective. Afshar, Kaveh, and Shoghli (2007) developed a new evolutionary algorithm, multi-colony ACO, for the time-cost-quality trade-off (TCQTO) problem. Rahimi and Iranmanesh (2008) solved the TCQTO problem using the MOPSO algorithm. They proposed a single-objective function based on the goal attainment method:
OF = fitness function; fi = ith objective function; and Fi = ith coordinate value of the ideal point. In fact, the TCQTO problem was transferred to a single-objective one by using Eq. (1) and the Pareto obtained by considering different combinations of weights in each run of the PSO algorithm. This process seems to be time-consuming because the PSO algorithm has to be used for different combinations of weights.
In this paper, two evolutionary algorithms, a multi-objective version of the PSO algorithm (MOPSO) and NSGA-II, are used to solve the TCTO and TCQTO problems. Although in both algorithms the search space is evaluated by a continuous search method, in this paper both algorithms are adapted to search in a discrete domain. Results are then compared to select the best algorithm.
Many optimization problems can be presented by the following general mathematical model:
f(x) = objective function; x = decision variables vector; X = decision variables space; and R = set of real numbers.
Fig. 1(a) shows a schematic of transferring data from a twodimensional decision variable space to a decision space in singleobjective problems. In multi-objective optimization problems, optimizing a vector of objectives is considered instead of satisfaction of a single objective. Generally, in mathematical form, multiobjective optimization problems can be defined as:

where m = number of objectives and N = set of natural numbers.
There are techniques such as the weighting method and e-constraint method which transfer multi-objective problems to a single-objective one using different combinations of a weighting vector and constraints. Thus, each optimal solution can be assigned to a specific combination of weighting vector and constraint. Hence, in each run of the algorithm, a single point (solution) can be achieved. However, multi-objective evolutionary algorithms are capable to find almost all candidate solutions (Pareto) in a single run.
Fig. 1(b) presents a schematic of transferring data from twodimensional decision variable space to the decision space in a two-objective problem. As it is shown, each set of decision vari-
ables has been related to a couple of objectives. Note that none of the solutions dominate the others. In other words, if all objective values of a solution dominate the correspondent values of another solution, the former will be a dominated solution and the latter will be removed. Otherwise, both solutions will be located in the nondominated set.
Fig. 2 shows dominated and nondominated relations between objective values in a bi-objective problem in which both objectives are minimization. In this figure, solutions labeled by 1 or 2 have nondominated conditions individually. Note that the set labeled 1 dominates the set labeled 2. In the optimization procedure, the best set of nondominated solutions is called Pareto-front. Thus, there are two Paretos in Fig. 2, in which the one labeled 1 is the
Multi-objective evolutionary algorithms
Schematic of decision and decision variable spaces in: (a) single-objective and (b) multi-objective problems.
Evolutionary algorithms are a subset of evolutionary computations which can perform optimal/near-optimal solutions in all types of problems (linear/nonlinear, discrete/continuous, convex/
Schematic of dominated and nondominated conditions of solutions in a bi-
nonconvex) using validated experimental theories of biological evolution and natural processes, particularly through activities of different species of animals.
A set of solutions resulting from a program run, without using any techniques such as the weighting approach that are directly related to decision-makersâ€™ opinions, is the most important advantage of evolutionary algorithms in the field of multi-objective optimization. Thus, these algorithms have been used as optimization tools in recent multi-objective optimization problems (Deb, 2001; Tan, Lee, & Khor, 2001). In this paper, two different types of multi-objective evolutionary algorithms, the MOPSO algorithm and NSGA-II are used as optimization tools in extraction solution of the TCTO and TCQTO problems.
Multi-objective particle swarm optimization (MOPSO) algorithm
The PSO algorithm is an optimization technique based on a bird migration pattern. In the real world, the movement of birds towards food can display a regular system in which each bird improves its position in the time dimension. In the PSO algorithm, each bird can be presented as a particle (single solution) and a set of the birds is identified as a swarm (set of solutions). Thus, in an optimization problem, the position of the ith particle (xi) can be represented by a D-dimensional vector:
where D = number of decision variables and N = swarm size. Moreover, the best bird (with the smallest distance from the food) is called the global best (Gbest), and the best position of a bird ever tried toward the food is the particle best (Pbest). Steps of the PSO algorithm are as follows:
In the first step, random solutions (xi) with a normal distribution of decision variables are produced. In the second step, those solutions are used in the simulation model as input data. The objective function for each particle (solution) is then calculated and stored in the memory of the algorithm. For the next step, Pbest and Gbest are assigned with respect to the best position of particles and swarm so far discovered, respectively. In the fourth step, the velocity is calculated as: r1t Pbesttid  xtid Ã¾ c2: rt2Gbesttd  xidt
vtidÃ¾1 = velocity of ith particle for dth dimension in (t + 1)th iteration; a = constriction factor which is a fixed pre-specified value and controls the velocity of particles in the decision variables space; wt = inertia weight parameter in tth iteration which is calculated by Eq. (8). This parameter starts from the maximum value (wMax) in the first iteration to the minimum value in the last iteration (iterMax). That is, at the beginning of search process, the effect of velocity (vtid) is more than that in later iterations. c1 = cognitive parameter; c2 = social parameter (c1 and c2 assign the proportion of Pbest and Gbest in the velocity); and rt1 and rt2 = uniformly distributed random numbers in [0,1] in the tth iteration. Hence, each particle moves in the decision space by a velocity vector with two elements. Thus, Pbesttid = best position of the ith particle for the dth dimension in the tth iteration and Gbesttd = best position of the swarm for the dth dimension in the tth iteration.
At the next step, resulting velocities are controlled using lower (vmin) and upper (vmax) bounds of velocity:
Finally, the particle position is calculated by using Eq. (10):
The resulting particle position is used as the new input for the simulation model in the second step and new objective functions are again calculated. This process continues up to the maximum number of iterations. The aforementioned PSO algorithm has a continuous search mechanism to move toward an optimal point.
The movement toward an optimal point in the single-objective PSO (SOPSO) algorithm is different from that in the MOPSO algorithm. In the SOPSO algorithm, each particle follows its objective function in the search process. In the MOPSO algorithm, however, the number of objective functions is more than one. Thus, the movement in the decision space toward each objective and consequently the search process should be adopted.
The vector evaluated PSO (VEPSO) is a multi-objective algorithm that uses one swarm for each objective. Thus, each swarm uses its particle position as the Pbest, but the Gbest of each swarm is replaced by the Gbest of other swarms for the next iteration. Fig. 3 shows an example of the transferring Pbest and Gbest in a three-objective problem.
In this paper, the proposed VEPSO algorithm (Parsopoulos & Vrahatis, 2002) is coupled with a dynamic external archive for transferring the produced particles in each iteration. Thus, the particles are compared and nondominated ones are stored and others are removed at the end of each iteration. In this mechanism, the member of an external archive can be reported in each iteration and the external archive size changes dynamically.
Nondominated sorting genetic algorithm (NSGA)-II
GA is a type of evolutionary algorithm in which a population set of chromosomes (solutions) moves toward better solutions. The evolution usually starts from a random population in the first generation (iteration). In each generation, the fitness of all chromosomes in the population is evaluated. Chromosomes are then stochastically selected from the current population (based on their fitness), and modified using the GA operators (crossover and mutation) to perform a new population. The new population is then used in the next iteration of the algorithm. Commonly, the algorithm process stops in the maximum number of generations. By increasing the objectives in different optimization problems, applications of the multi-objective GA (MOGA) have been recently developed from concepts borrowed from the single-objective GA (SOGA).
Srinivas and Deb (1994) used the nondominated sorting concept on the GA. Steps of the NSGA-II are as follows:
In the first step, a set of random solutions (chromosomes) with a uniform distribution are produced. The first generation is a N  D dimensions matrix, in which N and D are identified as the number of chromosomes (solutions) and decision variables (genes), respectively. There are dominated and nondominated solutions in the population that create different Paretos. In the second step, chromosomes are classified to the aforementioned Paretos using Eq. (11):
Nondominated sorting
dIj = crowded distance ofm	jth solution; M = number of objec-
fm and fm = values of mth objective for (j  1)th and (j + 1)th solution; fmMax = maximum value of mth objective function among solutions of the current population; and fmMin = minimum value of mth objective function among solutions of the current population.
In the aforementioned equation, index Ij denotes the jth solution in the sorted list and (j  1) and (j + 1) are the two nearest neighboring solutions on both sides of Ij. The algorithm then searches mostly near points (solutions) with more value of dIj . This process will cause the more uniform distribution of the resulting Pareto and a vast range of selections for the decision makers. The Pareto is then ranked from the best to the worst solutions, in which the comparison criterion is the distance from ideal Pareto-front with the assumed location. In the third step, the selection operator which is the crowded tournament is considered. It is used to select appropriate chromosomes (which are called parents) from the previous generation. The crowded tournament operator compares different solutions using two criteria: (1) a nondominated rank and (2) a crowding distance in the population. In this process, if a solution dominates the others, it will be selected as the parent. Otherwise, the solution with the higher value of crowding distance will be selected as the winner.
Deb and Agrawal (1995) developed a simulated binary recombination (crossover) operator, called the SBX operator, to combine two chromosomes and creating two new chromosomes (children). This operator is similar to one-point cut crossover in the binary data. The probability distribution is calculated:
5Ã°gc Ã¾ 1Ãžbg1cÃ¾2 ; otherwise	Ã°12Ãž
P(bi) = crossover probability; bi = difference between the objective functions of parents and children; gc = a constant which shows the difference between the objective functions of parents and children (a large value of gc gives a higher probability for creating near-parent solutions); and ui = a random value in [0,1]. The aforementioned difference between parents and children is
Schematic of discretization in the adaptive MOPSO.
calculated with Eq. (14) and the childrenâ€™s values are produced by Eq. (15):
bi Â¼ xparent1xchild1	 xxchild2parent2 	Ã°14Ãž
where xchild1 ; xchild2 = value of the first and second childâ€™s chromosomes and xparent1 ; xparent2 = value of the first and second parent chromosomes, respectively.


Cost (103 $)

Duration (day)
Cost (103 $)
Specification for the first test problem.
The other GA operator is mutation. A polynomial mutation operator which is proposed by Deb and Goyal (1996) has been used in this paper:
in which di = mutation value; ri = a random value in [0,1]; and gm = distribution constant of mutation. The d parameter is added to the parent gene value, as follows:
A new generation which is a combination of the parentsâ€™ and childrenâ€™s chromosomes is then produced. In the new generation, different chromosomes are ranked and chromosomes of the first rank are selected for the next generation. If the number of these chromosomes is less than the population size, chromosomes with a lower rank will be added to fulfill the new generation. Fig. 4 shows the NSGA-II procedure.
There are three main issues that are most important in a successful project: (1) it has to be on time (time); (2) it has to be within budget (cost); and (3) a project must meet the customerâ€™s requirement (quality). Time-cost-quality trade-off is a known and
Resulted Pareto-fronts using the MOPSO algorithm and NSGA-II for the TCTO problem.
Final Pareto using Merged of the MOPSO algorithm and NSGA-II for the TCTO problem.
Duration of different activities for a selected solution in the first test problem.
important problem whose main characteristic is decision-making in a discrete decision space. In this problem, there are three objectives: (1) minimizing the total time of the project; (2) minimizing the total cost of the project; and (3) maximizing the total quality of the project with respect to the order of the projectâ€™s activities, as follows:
Time = total time of project; A = set of activity; tiÃ°kÃž = duration of ith activity for kth option; Cost = total cost of project; aiÃ°kÃž = index of ith activity for kth option; cÃ°ikÃž = cost of ith activity for kth option; Quality = total quality of project; and wiÃ°kÃž = quality weight of ith activity for kth option.
The TCQTO problem is a three-objective problem in which the value of each objective decreases with an increase in other objectives. Thus, there is no single solution as the optimal point and a set of nondominated solutions/Pareto-front should be identified as the optimal set. Thus, evolutionary algorithms are suitable candidates to produce a set of solutions.
Adaptation of the MOPSO algorithm and NSGA-II in TCQTO problems
The TCTO and TCQTO are two- and three-objective problems with a discrete decision space. Any solution in these problems is related to a vector of time, cost, and quality. Thus, to find optimal solutions, evolutionary algorithms have been adapted to search in a discrete decision space.
In this paper, the MOPSO algorithm and NSGA-II have been used as the optimization tools. Both algorithms search the decision space based on a continuous method. To apply theses algorithms in the TCTO and TCQTO problems, a different technique has been proposed for each algorithm in which a continuous searching method is transferred to a discrete one.
The discrete MOPSO algorithm
In the MOPSO algorithm, to determine optimal solutions, a type of classification has been used which divides a feasible continuous decision space into discrete classes. In this method, integer decision variables are randomly produced in the first iteration. The velocity of each particle is then calculated with Eq. (7). Generally, this parameter may have different positive and negative continuous values. However, those values are considered to be classified to use as integer variables in the TCTO and TCQTO problems. Fig. 5 shows schematic of the discretization of the velocity parameter. As shown, continuous values are related to integer values. Thus, velocity is presented as an integer parameter which is added to the decision variable (x) and produces a new integer decision variable for the next iteration. The new variable is related to the corresponding vectors (time, cost, and quality) to calculate objective functions.
The discrete NSGA-II
As presented in the NSGA-II identification, this algorithm produces continuous variables using crossover and mutation operators. To adapt the NSGA-II for solving the TCTO and TCQTO problems, another type of classification has been used. In this process, all decision variables are limited in [0,1]. These variables are multiplied by 1000 and their integer part is separated and saved as the value of each variable. Each variable is then divided by the maximum states of related activity and the residual indicates the state of activity. Eqs. (21) and (22) present an example for an activity with three different states:
x = integer part of (x  1000); R = residual of x divided by 3; and x00 = new integer value of decision variable (x). According to this process, all values in [0,1] are transferred to an integer value.
In this paper, to apply the MOPSO algorithm and NSGA-II in TCTO and TCQTO problems, two different test problems are considered with two and three objectives, respectively. It should be noted that the time objective of this problem has been calculated considering the critical path method (CPM). It is concerned with two objectives: (1) planning the project schedule in a way that it is completed as quickly as possible and (2) identifying those activities where a delay in their execution is likely to affect the
The second test problem network.
Specification for the second test problem.


Activity weight (percent)

Resulted Pareto-fronts using the MOPSO algorithm and NSGA-II for the TCQTO problem.
overall end date of the project or later activities start dates. The CPM is used for projects that are made up of a number of individual activities. An activity is a specific task with time duration and a precedence relationship with other activities of the project. If some of the activities require other activities to finish before they can start, then the project becomes a complex set of activities (Bozorg Haddad, Mirmomeni, Zaredeh Mehrizi, & MariÃ±o, 2008).
Moreover, the same function evaluation has been considered for both algorithms. The number of particles and chromosomes are equal to 100 and the generation of NSGA-II is 500. However, two swarms have been used in the MOPSO algorithm and the maximum iteration is equal to 250.
To select an appropriate Pareto-front, a comparison criterion which is called generational distance (GD) has been used (Veldhuizen, 1999). This criterion is capable to present an average of distances from an optimal or ideal Pareto-front, as follows: vuffiffiffiffiffiffiffiffiffiffiffiffi
GD = generational distance; NS = number of solutions found; and di = euclidean distance (in the objective space) between members of the calculated Pareto and the nearest member of the ideal
To evaluate the MOPSO algorithm and NSGA-II in a TCTO problem, a test problem including 18 activities which has been initially presented by Feng et al. (1997) has been considered. Fig. 6 shows the network of this problem which includes activities arrangement. Table 1 presents these activities along with different options.
Resulting Pareto using the MOPSO algorithm and NSGA-II are presented in Fig. 7. As shown, both Paretos are approximately in the same location.
Because there is no known Pareto-front for the TCTO problem considered in this paper, an ideal point with the minimum value of each objective has been assumed to be the optimal Pareto-front. In fact, the ideal point is at the intersection of solutions with minimum values of time and cost. Because there are different units for time and cost, values of objective functions have been normalized to values in [0,1]. Numbers 0 and 1 have been assigned to solutions with the minimum value of each objective (best one) and the maximum value of each objective (worst one), respectively. In the current problem, possible minimum values of time and cost are 104 (day) and 99,740($), respectively, which have been replaced by the normalized value of zero for both time and cost.
The GD value for the resulting Pareto using the MOPSO algorithm and NSGA-II are 0.466 and 0.375, respectively. Thus, the NSGA-II Pareto is the more appropriate Pareto in the first test problem.
As shown in Fig. 7, minimum values for the time objective for the MOPSO algorithm and NSGA-II are different. Those minimum time values for the NSGA-II and MOPSO algorithm are 104 and
110 (day), respectively.
For comparison purposes, the Pareto of the MOPSO algorithm and NSGA-II have been merged and nondominated solutions have been presented as the final Pareto (Fig. 8). The proportions of nondominated solutions in the final Pareto yielded by each algorithm
Final Pareto using Merged of the MOPSO algorithm and NSGA-II for the TCQ problem.
were then calculated. Results showed that 57.89(%) of nondominated solutions were determined by the NSGA-II. Thus, the NSGA-II is more capable to determine appropriate solutions than the MOPSO algorithm.
To illustrate the efficiency of the CPM in time managing, the duration of each activity for a solution that has the lowest distance from ideal point (0,0) is shown in Fig. 9. The decision variables of the aforementioned solution are {1,4,3,3,4,3,3,1,2,2,3,1,3,3,1,5,1,1} corresponding to 117 (day) and 105,760 ($). According to related options for each activity, the time of project has been calculated to be 360 days without considering the CPM. Thus, using the CPM improves the total time of the project.
To apply the MOPSO algorithm and NSGA-II in a three-objective construction problem, the seven-activity TCQTO problem of Zheng and Thomas (2005) is considered. Fig. 10 shows the network of the TCQTO problem. Moreover, different options of each activity are presented in Table 2. According to this table, minimum and maxi-
mum options for decision making are 2 and 5, respectively. The best value for the single-objective problem is 60 (day), 95,800 ($), and 97 (%) for the first (Time), second (Cost) and third (Quality) objectives. Thus, the comparison point for calculating the GD criterion is equal to (0,0,1) after transferring solutions to the corresponding values between 0 and 1.
Fig. 11 shows the resulting Paretos using the MOPSO algorithm and NSGA-II. To compare these Paretos, the GD criterion is equal to 0.792 and 0.768 for the MOPSO algorithm and NSGA-II Paretofronts, respectively. Both algorithms achieved the optimal singleobjective solution. The merged Pareto, which is called final Pareto, is shown in Fig. 12. According to the final Pareto, 93.24 (%) of the solutions were obtained by the NSGA-II and the rest by the MOPSO procedure. Thus, the NSGA-II is more capable to find nondominated solutions than the MOPSO procedure.
To show the difference between optimization of two and three objectives in the TCQTO problem, different combinations of two objectives were considered. Resulting Paretos using the MOPSO
Cost (1000$)
Solutions for the two and three objective problem for: (a) cost-quality and (b) time-cost.
Duration of different activities for a selected solution in the second test problem.
algorithm with two objectives in the TCQTO problem are shown in Fig. 13. As shown, the number of nondominated solutions in the three-objective problem exceeds that of the bi-objective problem. However, most of the three-objective solutions are dominated solutions. Thus, an increase in the number of objectives adds the number of nondominated solutions to the nondominated solutions found in problems with fewer objectives. Note that there is no conflict between time and quality objectives in this problem. Thus, both objectives achieved the optimal solution using the same alternatives and options ({1,1,1,1,1,1,1}) as decision variables. Thus, there is no Pareto-front for the time and quality optimization problem.
To demonstrate the capability of using the CPM in the TCQTO problem, the duration time of a nondominated solution with the lowest distance from the normalized ideal point (0,0,1) is presented in Fig. 14. The total time of the project for the aforementioned solution ({3,1,1,2,2,3,1}) is 73 (day). The time duration was calculated to be 125 (day) without using the CPM. The cost and quality of this solution are 120,000 ($) and 85 (%), respectively.
Concluding remarks
Recently, project management problems have been considered to be multi-objective problems including time, cost, and the quality as objectives. In multi-objective problems, different objectives are commonly conflicting. In time-cost-quality trade-off (TCQTO) problems, the quality of the project has been considered as an objective which is improved by increasing the cost of the project. On the other hand, decreasing the time of the project increases the cost of the project. Thus, time and quality are conflicting with the cost of the project. However, the time and quality of a project usually changes in the same direction. Thus, a project with a less duration time achieves an upper level of quality. Evolutionary algorithms are suitable tools that can yield different solutions by considering existing conflicts.
The other specification of a TCQTO problem is having a discrete decision-variable space. Thus, the used algorithms should be adapted for using in the TCTO and TCQTO problems. In this paper, the MOPSO algorithm and NSGA-II were used to solve TCTO and TCQTO problems. These algorithms search the decision space in a continuous manner. To adapt the MOPSO algorithm and NSGA-II with the TCTO and TCQTO problems for discrete decision-making, two techniques were implemented. In the former method, the continuous decision rounds to the near integer value while the latter method uses a relative integer value. Moreover, to compare the Paretos and select an appropriate one, a comparison criterion called generational distance (GD) has been used.
Results showed that both NSGA-II and MOPSO algorithms can yield an acceptable number of nondominated solutions. The NSGA-II with a smaller value of GD in both TCTO and TCQTO problems has been nominated. The value of GD using the NSGA-II was 27.58 which has been improved (decreased) by 3.03% compared to that of the MOPSO algorithm. To confirm previous results, the resulting Paretos using the aforementioned algorithms were merged and nondominated solutions were considered to be the final Pareto. The proportion of nondominated solutions in the final Pareto was used as the other criterion for selecting an appropriate algorithm. Results showed that the capability of the NSGA-II is superior to that of the MOPSO procedure in determining the final Pareto for TCTO and TCQTO problems (57.89 and 93.24%, respectively).
