Cost‐effectiveness of construction safety programme elements
Matthew Hallowell
To cite this article: Matthew Hallowell (2010) Cost‐effectiveness of construction safety programme elements, Construction Management and Economics, 28: 1, 25-34, DOI:
To link to this article:
Full Terms & Conditions of access and use can be found at
Construction Management and Economics (January 2010) 28, 25–34
Cost-effectiveness of construction safety programme elements
University of Colorado, Civil, Environmental, and Architectural Engineering, 428 UCB, 1111 Engineering Drive, Boulder, 80303 USA
Received 13 August 2009; accepted 3 November 2009Taylor and Francis
Every year the construction industry accounts for a disproportionate injury rate when compared to the all-industry average. In recent years, incident rates have declined as a result of improvements in safety management. While there is a great deal of knowledge regarding the safety management strategies of highly effective construction firms, little is known about the cost-effectiveness of these strategies. Interviews with 26 representatives of construction firms headquartered in the US were undertaken to quantify the cost of implementing common safety programme elements by: (1) quantifying cost for each element per US$1 million of project scope; and (2) determining the distribution of safety funding to each element. Using these cost data and effectiveness ratings from previous research, the cost-effectiveness of 13 safety programme elements was quantified. The results indicate that the most cost-effective safety programme elements are subcontractor selection and management and upper management support and commitment. Alternatively, the least cost-effective elements are the employment of a full-time safety manager and record-keeping. The information presented in this paper may be used by practitioners to direct resource investments, strategically select a subset of safety programme elements when resources are limited, and to justify additional resource investment in accident prevention.
Introduction
It is no secret that safety is a tremendous concern within the construction industry. According to the 2007 Census of Fatal Occupational Injuries (CFOI), the US construction industry accounted for the highest fatality rate of all industries with 10.5 fatalities per 100 000 workers (BLS, 2009). Despite the fact that the construction industry only accounts for 8% of the American workforce, the industry consistently accounts for over 20% of all occupational fatalities (Center for Construction Research and Training, 2008; BLS, 2009). Studies conducted in the UK have shown similar evidence of a disproportionate fatality rate. While construction employs approximately 7.4% of the UK workforce, the industry accounts for 21.5% of all occupational fatalities (HSE, 2009).
In addition to the impacts of occupational injuries on the injured workers and their families, the financial costs associated with occupational injuries and illnesses are staggering. In 2004, the American construction industry experienced 460 000 disabling injuries resulting in an estimated cost of $15.64 billion (NSC, 2006) and the US Census Bureau (2006) found that employers in the construction industry spend more on worker’s compensation insurance premiums than is the case in any other industry. Furthermore, Rikhardsson and Impgaard (2004) estimate that the cost of occupational injuries resulted in a total loss of 2.6% to 3.8% of the European Union’s gross national product and Everett and Frank (1996) estimated that construction accidents accounted for 7.9% to 15% of the total costs of new construction.
Construction Management and Economics
ISSN 0144-6193 print/ISSN 1466-433X online © 2010 Taylor & Francis
Many inherent characteristics of the construction industry contribute to the relatively high injury rate including dynamic work environments, industry fragmentation, multiplicity of operations, proximity of multiple crews and industry culture (Fredricks et al., 2005). While these industry characteristics make construction safety management particularly challenging, construction organizations can promote safety by
implementing a comprehensive safety management programme, allocating sufficient resources for safetyrelated activities, and ensuring the active participation of upper-level managers in regular safety management efforts (Hinze, 2006).
In order to reduce the frequency and severity of construction accidents, firms implement safety programmes that include elements such as written safety plans, orientation and training, and subcontractor selection and management. Unfortunately, the expense of such elements deters many firms from establishing a comprehensive safety programme. It has been found that firms are more likely to put more emphasis on activities that prevent workplace accidents when managers are convinced that they are cost-effective (Lanoie and Trottier, 1998). While economic analyses have been performed in other industries to justify interventions that improve occupational safety and health, no such study has been performed in the construction industry.
In this paper the writer focuses on quantifying the costeffectiveness of common safety programme elements in construction. It is expected that this information may be used by practitioners to direct resource investments, strategically select a subset of safety programme elements when resources are limited, and to justify additional resource investment in accident prevention.
There is a well-established body of literature that discusses the elements of an effective safety programme. For example, Jaselskis et al. (1996) studied the effectiveness of safety programme elements by measuring the relative ability of each element to decrease a company’s experience modification rate (EMR) and recordable incident rates. Similarly, Sawacha et al. (1999) performed a factor analysis to determine the relative impacts of various safety programme elements. Recently, Molenaar et al. (2009) created a set of best practices by evaluating five latent variables through a structural equation model and Hallowell and Gambatese (2009) used the Delphi method to quantify the individual ability of safety programme elements to reduce the frequency and/or severity of construction injuries and illnesses. These studies, along with Hinze (2006) and Levitt and Samelson (1993), identify 13 highly effective safety programme elements. Using guidance from this body of literature, these 13 elements are listed and described in Table 1.
While it has been established that investment in accident prevention improves business performance, a thorough literature review revealed no study that focused on quantifying the cost of implementing individual construction safety programme elements.
However, several studies specifically attempt to perform a cost–benefit analysis of accident prevention programmes in other industries. First, Harms-Ringdhal (1990) performed a cost–benefit analysis for accident investigations and safety in the design of new equipment in three firms in the pulp and paper industry. This study found that the design measures prevented accidents, resulting in significant cost savings. Second, Bertrand (1991) analysed the cost–benefit of employee training, safety meetings, and investment in personal protective equipment (PPE) in two plants in the timber industry. The conclusion from this study was that all safety activities implemented by these firms were financially viable. Third, Spilling et al. (1986) determined that investment in ergonomic controls in the telecommunications industry was profitable. Finally, Lanoie and Trottier (1998) found that the conversion from a mechanical to a manual handling system in warehouses in Montreal was lucrative because of the number of accidents it prevented. All four studies reviewed reached the same conclusion: investment in accident prevention is profitable.
According to Hinze (2000), quantifying the cost– benefit of construction safety management is unrealistic for two reasons: (1) the complex and dynamic nature of construction projects; and (2) the difficulty of attributing cost savings to construction safety management activities. While cost–benefit analyses are unrealistic for construction safety management activities, it will be shown that cost-effectiveness analyses for particular injury prevention efforts are possible and may help construction managers to better understand the relative costs and benefits of safety management efforts. Ferry (1990) distinguishes between a cost– benefit analysis and a cost-effectiveness analysis. By his definition, a cost-effectiveness analysis assigns monetary costs and a measure of positive impact to individual safety management activities in an effort to identify the efforts with the greatest benefit to cost ratio. Cost–benefit analyses, however, focus on determining whether safety management efforts pay for themselves.
In this study the author deviates from the current body of knowledge by quantifying the cost-effectiveness of the 13 construction safety programme elements identified and described in Table 1. Specifically, new knowledge is generated by: (1) quantifying cost for each element per US$1 million of project scope; and (2) determining the distribution of safety funding to each element. Using these new data and ratings of relative effectiveness of the elements found in literature, cost-effectiveness ratings were calculated. A cost-effectiveness analysis was selected for this study because the information can be used to aid decision makers with resource allocation to safety programmes and to establish a framework to measure the economic performance of a safety programme. This is the first known attempt to quantify such values.
Research methods
According to Ossler (1984), the essential steps required to perform a cost-effectiveness analysis include: (1) identifying a stimulus or problem to be solved; (2) assigning monetary values to each element; (3) assigning a measure of effectiveness to each element; (4) calculating the effectiveness/cost ratio; and (5) comparison of ratios and inclusion of data in decision-making processes. Since previous research has quantified the relative effectiveness of essential elements and the importance of accident prevention, the data collection methodology for this study focuses on determining the cost of implementation.
The author selected structured interviews with executives, construction managers and safety managers as the method of quantifying the cost associated with common safety programme elements. Interviews were chosen over surveys because of the sensitivity and complexity of the information solicited and the desire to initiate conversation regarding the estimates provided and the methods used to obtain them. Since it was assumed that the data requested from these firms would be difficult to obtain, only individuals with direct access to financial records and complex knowledge of project expenditures were targeted. According to Patton (1990) such a ‘purposeful sample’ is ideal for enhancing validity when a large sample size is unrealistic.
In an effort to create a representative sample of building contractors headquartered in the United States, the memberships of regional Associated General Contractors (AGC) chapters (e.g. Oregon Columbia Chapter) and the membership of the American Society of Safety Engineers’ Construction Practice Specialty were contacted via e-mail. In order to qualify for participation, interviewees were required to be representatives of building construction firms with annual revenue greater than US$1 million. The sample was limited to building contractors because of the significant challenges associated with building construction and to reduce the scope of the study to a manageable level. This method of sampling was used in lieu of a convenience sample to enhance external validity. In total, 59 firms agreed to participate in the study.
Unfortunately, owing to the confidential nature of the membership lists, the precise response rate cannot be reported.
During the initial interviews it became clear that expenditure on safety can be a sensitive topic and is difficult to separate from other administrative expenditures. As a result, only 26 of the 59 firms (47%) were able provide accurate responses with confidence. All 26 of these firms have headquarters in the United States and 14 of the 26 firms (54%) have international offices. Also, all representatives described their firms as primarily ‘vertical’ contractors (i.e. building construction). There was a strong distribution in firm size in this sample. Five of the 26 (19%) firms were classified as small firms (annual revenue < US$10 million), 10 of the 26 (38%) firms were classified as medium-sized (US$10 million < annual revenue < US$100 million), and 11 of the 26 (43%) firms were classified as large firms (annual revenue > US$100 million). The sample had average revenue of US$1.23 billion, median annual revenue of US$55 million and a standard deviation in annual revenue of US$2.9 billion. Collectively, the sample of organizations had a large geographic spread including projects in all 50 US states.
The interviewees representing the 26 firms were well qualified, had intimate knowledge of their company’s safety practices, had access to accounting data and other knowledgeable individuals, and actively participated in all three rounds of interviews. The sample of interviewees included 11 (44%) upper-level managers, seven (24%) construction managers and eight (32%) safety managers. Upper-level managers included individuals with executive positions that included president, general manager, chief operating officer and chief executive officer. Alternatively, construction managers were individuals who were primarily responsible for managing individual projects and safety managers were typically responsible for worker safety and safety programme administration for multiple projects within their region. The construction industry experience of the interviewees ranged from 5 to 42 years, with an average of 18.7 years.
Interviews with representatives of these 26 firms were conducted in the three-step process. First, pilot interviews were conducted to inform the interviewees of the objectives of the study, the type of data needed, and the expected timeline for completion; to obtain a commitment from the interviewee to share their safety investment data; and to obtain demographic information about the interviewee and the firm. Finally, each interviewee was asked to gather accounting data and, if necessary, speak with knowledgeable representatives of the firm so that they were well prepared for the second round of interviews.
Explicit acknowledgement from upper management that worker safety and health is a primary goal of the firm demonstrated by participation in regular safety meetings and committees, and sufficient funding.
Subcontractor selection and mgt
Consideration of safety and health performance during the selection and management of subcontractors (e.g. pre-qualification and required compliance).
Employee involvement and evaluation
Including all employees in the formulation and execution of other safety elements and including participation and safe work behaviour in evaluations.
Job hazard analyses (JHA)
Review and recording activities associated with a construction process, highlighting potential hazardous exposures and documenting safe work practices that prevent injury.
Project-specific training/meetings
Establishing and communicating project-specific safety goals, plans and policies before the construction phase of the project.
Frequent worksite inspections
Inspections performed internally by a contractor’s safety manager, safety committee, representative of the contractor’s insurance provider or by an OSHA consultant to identify uncontrolled hazardous exposures.
Safety manager on site
Employment of a safety and health professional (i.e. an individual with formal construction safety and health experience and/or education) whose primary responsibility is to perform and direct the implementation of safety and health programme elements and serve as a resource for employees.
Identification and prevention of substance abuse of the workforce (includes random testing and testing after an injury).
Safety and health committees
Committee with the power to effect change and set policies, consisting of a diverse group including supervisors, labourers, representatives of key subcontractors, owner representatives, OSHA consultants may be formed with the sole purpose of addressing safety and health on the worksite.
S&H orientation/training
Participation of all new hires or transfers in orientation and training sessions that have a specific focus on safe work practices and company safety policies.
Written safety and health plan
Development of a documented plan that identifies project-specific safety objectives, unique hazards and methods for achieving success.
Regular reporting of the specifics of all accidents including information such as time, location, work-site conditions and cause.
Emergency response planning
Creation of a plan that documents the company’s policies and procedures in the case of a serious incident or catastrophe such as a fatality or an incident involving multiple serious injuries.
Approximately two weeks following the pilot interview, a second round of interviews was conducted with the same interviewees. The objectives of the second interview were to determine which of the 13 safety programme elements in Table 1 the interviewee’s organization includes as a part of the typical safety programme and to quantify the average investment in each of these elements per million dollars of project scope. The measure of cost per million dollars of project scope was selected because simply asking for total expenditure per project or per individual would not account for the number or size of the projects undertaken. To maintain consistency within the sample, the respondents were given the element definitions provided in Table 1 and were asked to estimate the recurring costs of each element including indirect costs such as loss of productivity and employee time. Interviewees were asked not to include the developmental costs (i.e. ‘first costs’) in their estimates. Table 1 Safety programme element descriptions
The third and final round of interviews was conducted approximately six months following the completion of the second round. The impetus for the third round of interviews was the relatively high degree of variability in responses and the lack of information related to marginal costs and administrative expenditures related to injury prevention. The strategy for overcoming these limitations was to conduct a third round of interviews that focused on quantifying the typical percentage of project tender price that is allocated to safety and to determine the approximate distribution of these funds to the elements in Table 1 and other organizational functions. Thus, the objectives of the third round of interviews were to quantify the average percentage of the tender price for a project that is invested in injury prevention; to quantify the approximate distribution of these funds among the 13 safety programme elements; and to discuss the potential impacts of marginal costs and inefficiency in the
estimates provided throughout the study. In this final round, interviewees were also given the opportunity to change their cost estimates from the second round. Approximately 25% of firms elected to change one or more estimates. In many respects, this third round can be considered a validation effort because the objectives were to confirm and refine previous estimates, collect similar cost data by focusing on percentage allocation rather than actual cost rates, and to discuss factors that limit the validity of the study.
Whenever possible, interviews were conducted faceto-face at the interviewee’s office for the first two rounds. All third round interviews, however, were conducted via teleconference. In some cases, a virtual meeting was conducted to facilitate discussion and share documentation. Several methods were used to reduce bias and enhance the validity and reliability of the results throughout the data collection process. First, multiple interviewers were involved in each of the three phases of interviews to limit the potential bias associated with the interpretation of results. Second, samples were collected from national databases rather than personal contacts to enhance external validity. Third, internal validity was enhanced by using consistent definitions of the safety programme elements (Table 1) and structured interview templates. Also to enhance internal validity, interviewees were asked to justify their estimates with documentation or input from colleagues whenever possible. Finally, collecting similar data in two forms (i.e. costs per million dollars of project scope and percentage of project scope invested) allowed for a comparison of values thus enhancing the reliability of the results. The limitations associated with this research approach are discussed in detail following the analysis of results.
While all 13 elements were not implemented by every firm, 21 (81%) had comprehensive project-specific safety programmes that included at least 10 of the 13 elements. The elements most commonly implemented as a part of their regular safety programme were written safety and health plan (100%), emergency response plan (100%) and project-specific training (100%). The most infrequently implemented elements were subcontractor selection and management (67%), employing a safety manager on site (71%) and upper management support and commitment (71%).
The first round of interviews with safety managers, project managers and executives yielded detailed cost data for the implementation of safety programme elements. These results are summarized in Table 2. This table highlights the first quartile, median, mean, third quartile, and standard deviation of cost value per million USD of project scope and the unitless coefficient of variation. As one can see from this table, the average cost of implementing elements ranged from a
median of $500/1MM project scope for emergency response plans to a median of $1275/1MM project scope for employing a site-specific safety manager. It is also apparent that there is a great deal of variability in the investment made among firms. Using the coefficient of variation (standard deviation divided by the mean) as a measure of relative variability, one can see that the variability ranged from a low of 0.74 for written safety and health plan to a high of 2.11 for inspections.
The variability associated with the elements reported in Table 2 is consistent with the subjective input obtained during unstructured discussions held during the interviews. While the majority of costs for all elements were employee time, interviewees expressed more difficulty quantifying the costs associated with programme elements that primarily required broad employee participation rather than a dedicated individual. This difficulty is reflected in the coefficients of variation. For example, the three elements with the highest coefficient of variability in estimates included inspections (2.11), safety and health committees (1.60), and employee training and regular safety meetings (1.45) while the three elements with the lowest coefficient of variability were written plan (0.74), record-keeping (0.91) and safety manager (1.01). Despite the significant range in investment, it is expected that the true cost of implementation is well represented by the mean reported cost. The mean will be used for subsequent analyses in lieu of the median because the mean accounts for differences in strategies implemented by participating organizations and methods of accounting. Further, it should be noted that the primary objective of this study was to quantify the costeffectiveness of the 13 safety programme elements; therefore, it is the relative costs of these elements, not the absolute costs, which are the greatest concern.
The results indicate that the three most costly safety programme elements, defined in dollars in investment per million dollars of project scope, are employing a site-specific safety manager ($2666), inspections ($2623) and training and regular safety meetings ($2449). The three least costly elements are emergency response plans ($825), subcontractor management ($998) and written safety plans ($1196).
To recall, one of the objectives of the third round of interviews was to report the data from the previous round and to provide the interviewees with an opportunity to revise their response in light of further data collection or discussions. In the third round, 21 firms (81%) were confident in their original response while five firms (19%) elected to alter one or more of their
Table 2	Costs of implementing safety programme elements (n = 26)

Coefficient of variation
Job hazard analyses (JHA)
Inspections
Orientation and training
One should note that the results reported in Table 2 reflect these changes.
The main objective of the third round of interviews was to quantify the percentage investment in injury prevention and the distribution of these funds among elements. The results indicate that, on average, the 26 firms invest 2.2% of the tender price in injury prevention. Eighty-six per cent of this investment is in the 13 elements highlighted in this study and the remaining 14% is invested in personal protective equipment (PPE), signage, other injury prevention techniques and administrative expenses. Not surprisingly, interviewees used the same accounting methods as were used to quantify the costs reported in Table 2 with the notable difference of considering percentages rather than actual costs. The interviewees were more confident in their estimates of percentages because percentage investment accounts for marginal costs and are relatively consistent among geographical regions whereas actual costs tend to be more variable. Coincidentally, the percentage estimates made by the interviewees in the third round had an average coefficient of variability of 0.74 which is approximately 40% lower than the average coefficient of variability for the cost estimates (1.23).
Table 3	Percentage distribution of funds to safety programme elements (n = 26)
Distribution in safety investment

Coefficient of variation
Job hazard analyses (JHA)
Inspections
Orientation and training
Despite the change in variability, the distribution of funds obtained during the third round (Table 3) was almost directly proportional to the cost estimates provided in Table 2. There are two aspects of Table 3 that must be noted. First, the percentage distribution to
each element is of the 86% of funds allocated to the safety programme (e.g. a mean of 6% allocation of funds to subcontractor management reflects the percentage of safety programme funds allocated to that element) and does not include the funds invested in general administration, PPE or signage. Second, one will note that the sum of the mean percentage allocation to the 13 elements adds up to 118%. This is due to the variability on responses among firms.
When discussing inefficiencies and marginal costs in the third round of interviews, the interviewees expressed difficulty identifying and describing the impact of inefficiency in the safety management process. In fact, studying the impact of inefficiency and methods of minimizing inefficiency in the safety management process was discussed by several interviewees as a good topic for future research.
The purpose of this analysis is to utilize the data collected in the research effort and the existing body of literature related to the relative effectiveness of safety programme elements to create cost-effectiveness ratings. Cost-effectiveness ratings were created by first evaluating literature that provided data that distinguishes among the effectiveness of some or all of the 13 elements highlighted in this study. These values were then divided by the average cost of implementation per million dollars of project scope (Table 2) and the average percentage fund allocation values (Table 3), to obtain two measures of the cost-effectiveness ratio.
In order to quantify the relative effectiveness of the 13 safety programme elements highlighted in this study, a thorough literature review was conducted to identify any studies that quantify the relative effectiveness of safety programme elements. Four studies were identified. First, Sawacha et al. (1999) performed a factor analysis based on the input of 120 building contractors. In this factor analysis they used the Pearson’s correlation coefficient to quantify the strength of the relationship that existed between each safety programme element and safety performance. In a second study Rajendran and Gambatese (2009) used the Delphi method to create a Sustainable Construction Safety and Health (SCSH) rating system similar in construct to LEED™. In the development of his rating scheme, he employed the Delphi method to quantify the number of points to be assigned to various injury prevention strategies. Points were assigned based on relative effectiveness. In part of a validation effort, Hallowell (2008) also used the Delphi method to rate the relative effectiveness of injury prevention strategies using a 1 to 10 scale. Finally, Hallowell and Gambatese (2009) quantified the relative ability of injury prevention strategies to mitigate safety risk. A summary of the ratings from these four studies is provided in Table 4.
Table 4	Summary of effectiveness ratings obtained from literature
Element	Sawacha et al. Rajendran (2007)	Hallowell (2008)	Hallowell and
(1999)	Gambatese (in press)




Orientation and training
Inspections
It should be noted that these studies focused on quantifying relative impacts of a wide range of safety prevention efforts. Therefore, some of the studies included all 13 elements from Table 1 while others included only a subset of elements. For example, Sawacha et al. (1999) included six of the 13 elements and Rajendran and Gambatese (2009) included 12 of the 13 elements while Hallowell (2008) and Hallowell
and Gambatese (2009) included all 13 elements in their analyses. It should also be noted that these studies also provided ratings for prevention strategies not highlighted in the present study (e.g. housekeeping).
Since these studies each quantify relative effectiveness on different scales, the results are combined through the following three-step process:
(1) Identify relative ratings on original scales.
(2) Calculate the percentage of maximum for each element (i.e. the rating of each element on the original scale divided by the maximum score for all elements on the particular scale utilized in the study).
(3) Determine the average percentage of maximum score for each element across all four studies.
The percentage of maximum (POM) technique is generally used in multi-criteria decision analyses, such as the analytic hierarchy process (AHP) when attributes are measured on various scales. This method is useful as it equally weights the results of the four studies and produces a unitless relative rating of effectiveness. The POM values for each study and the average POM of all four studies are provided in Table 4. For the remainder of this analysis, the average POM represents the effectiveness rating for each element.
To quantify the cost-effectiveness ratio for each of the 13 safety programme elements, the two measures of cost were divided by the average POM values. That is, the average cost of each element per million dollars of project scope (Table 2) was divided by the average POM from Table 4 and the percentage allocation of funds (Table 3) was also divided by the average POM.
Effectiveness
Cost-effectiveness ratio
% investmenteffectiveness ratio
Orientation and training
Job hazard analyses (JHA)
Inspections
Safety manager
Table 5	Cost-effectiveness ratings
These calculations are highlighted in Table 5 along with the two measures of cost-effectiveness.
As one can see from the analysis presented in Table 5, the most cost-effective elements are subcontractor selection and management, upper management support and commitment, employee involvement in safety management and planning, and written safety and health plans. These elements are highlighted as the most cost-effective because they were among the top five ratings cost-effectiveness ratings (i.e. lowest values) for both measures. The four least cost-effective elements are safety manager, record-keeping and accident analyses, training and regular safety meetings, and inspections. These are highlighted as the four least costeffective elements because they were among the bottom five cost-effectiveness ratings (i.e. highest values) for both measures. The consistency in these measures of cost-effectiveness show strong validity in the study.
The final analysis performed for this study was to use the analysis of variance (ANOVA) to test for a statistically significant difference in resource investments among small, medium and large firms. While the data were approximately normal, the samples for the firms of the various sizes were approximately equal, and the samples were independent, no statistical differences can be reported (p > 0.10). Guidance from Ramsey and Schafer (2002) was used when conducting this statistical analysis.
This study has several limitations that are due to the assumptions made, sampling techniques implemented and data collection processes. A general assumption throughout the analyses was that once an element is funded and implemented, it effects an immediate improvement on safety conditions. This assumption is made in part because determining the lag between investment and risk reduction would be very difficult to measure owing to the presence of confounding factors. Therefore, using the time value of money to determine present value costs is unrealistic with the current data. Furthermore, it was assumed that there was consistency in accounting procedures among firms. While this was validated somewhat through the interviews, specific documentation was not provided to the research team.
There are limitations associated with the sampling technique that adversely affect the external validity of the results. First, despite the fact that high quality data were obtained through multiple rounds of personal communication, the sample size is relatively small and confined to the firms willing to participate in this study. Therefore, the statistical validity of the results is limited. Moreover, the scope of inference is limited to large building construction firms headquartered in the United States because of the sampling techniques implemented. It is important to note, however, that the low sample size is a reflection of the small percentage of firms willing to divulge safety investment information, not a lack of effort.
The internal validity of the study was affected mainly by the data collection processes. The use of means to describe the costs made the data analysis vulnerable to the potential presence of outliers that could have biased the results. While the results were validated through multiple rounds of interviews and alternative methods of data collection, both the percentage investment and cost per million dollars of project scope do not account for inefficiencies in the safety management process. Furthermore, there are specific limitations associated with the cost per million dollars of project scope. First, firms were asked to estimate the indirect costs of implementation such as loss in productivity and employee time. The difficulty associated with estimating these indirect costs may explain some of the variability in the cost data. Second, the values as they have reported only represent the costs in 2008. Finally, these cost estimates do not include marginal costs that may be affected by economies of scale. Because of these limitations, the writer believes that the cost-effectiveness ratings based upon the percentage distribution of funds produced higher quality estimates.
Conclusions and recommendations
Using two measures of cost (i.e. cost per million dollars of project scope and percentage of safety budget invested) and ratings of relative effectiveness obtained from Sawacha et al. (1999), Rajendran (2007), Hallowell (2008) and Hallowell and Gambatese
(2009), the cost-effectiveness ratios for 13 highly effective safety programme elements were calculated. The analysis of the results indicate that the most costeffective safety programme elements are subcontractor selection and management and upper management support and commitment and the least cost-effective elements are employing a full-time safety manager and record-keeping.
The data also indicate that, on average, firms invest 2.2% of the tender price of a facility on injury prevention efforts. Research has shown the 13 elements described in this manuscript are commonly implemented and result in a reduction in recordable injury rates and EMR (Jaselksis et al., 1996; Hinze, 2006). Nevertheless, construction injuries still account for 3.4% of the total cost of new construction (Center for Construction Research and Training, 2008). When the costs are compared with investment in the 13 elements it is clear that increased investment is warranted. Such investment could be in the form of new safety programme elements or an increase in quality and scope of existing programmes. Before additional investments are made, however, it is important to analyse the cost–benefit and diminishing returns associated with new and existing accident prevention activities.
There are several immediate applications of these analyses to the construction industry. Research has found that traditional safety management practices are informal and lack objectivity (Hallowell and Gambatese, 2008). This is especially true for small firms which comprise over 70% of the global construction industry. The findings presented here can be used to formalize the safety management process and guide financial decision making in several ways. First, firms can select new elements for implementation based upon their estimated cost and their cost-effectiveness. While the median cost values may not apply to all firms, the percentage investments provide guidance for firms of all sizes. Second, the cost-effectiveness data may be used to direct funding decisions when resources are limited. For example, if a firm has a limited safety budget, increased investment in highly cost-effective elements such as upper management support and commitment and subcontractor selection and management will yield much greater benefits than investment in record-keeping and employing a safety manager. Finally, large firms with an advanced project management system can use the cost data during programme management, project planning, estimating, and accounting and to compare their distribution of funds with the 26 firms from this study.
The construction industry could benefit from additional research in the area of investment in construction safety management. Since this study is limited to firms that are headquartered in the United States, cost data could be obtained from firms with headquarters throughout the world. Additionally, the cost and effectiveness data are only available for the 13 safety programme elements highlighted in Table 1. While literature confirms that these programme elements are the most effective of the available elements, there are many other elements such as designing for safety, stretch and flex programmes, and behaviour-based safety which should be analysed as well. Future analyses may reveal highly cost-effective elements that are not part of standard safety programmes. Finally, the author recommends that additional research is conducted that validates or provides alternative cost data for the 13 elements included in this study.
