Augmented Reality and Unmanned Aerial Vehicle
Assist in Construction Management
1Department of Civil Engineering, National Taiwan University, email:
2Department of Civil Engineering, National Taiwan University, email:
This paper presents an ongoing work on using Unmanned Aerial Vehicle (UAV) in construction scenarios. Augmented reality (AR), the technologies integrating the real images and virtual rendering scene, will also be integrated to enhance the application of UAV.  The high viewpoint and the combination of real and virtual scene provide engineers augmented views to the construction site. They will increase the possibility of discovering the unfound problems. We have designed and prototyped an UAV with features important for the construction management: (1) stabilized image capturer, (2) site level image transmission and (3) telecommunication and viewing interface. The stabilized image capturer includes a 2-axis brushless motor gimbal which can continuous adjust the camera to aim a specific direction. The image transmission was carried out by using radio frequency transmitters which specifically optimized by considering the size of the construction site. The interface includes a multi-rotor UAV that has reliable telemetry control, a display that can render the mixed scene between virtual and real views using AR technology, and a wireless local area network (WLAN) system that provides access to realtime image stream for multiple devices. From preliminary tests, we found the system has the potential for discovering unnoticed detail problems in real construction site, such as vehicle path planning conflicts and structure spatial dilemmas. In the near future, we plan to test the UAV-AR solution in three common construction scenarios: typical building site, bridge inspection, and urban planning.
STATE-OF-ART UAV AND AR TECHNOLOGIES
UAV Technology. An UAV is an aircraft without a human pilot on board. The vehicle is controlled either autonomously by microprocessors on itself or under the telemetry control of operators using the ground station. In this paper, we focus on the aircraft sizes under 2000mm in width that can be easily operated by just one or two operators. Since UAVs are usually developed for specific purposes, its configuration can be varied for different task requirements. Generally speaking, a typical UAV application hardware consists of the following parts:
Unmanned aircraft. There are fixed-wing aircraft and rotorcraft depends on the aircraft’s lift method.
Control system, such as flight controller on the aircraft and ground station.
Telecommunication systems often use variety of radio frequencies for data communication.
Other equipment and mechanics, such as laser rangefinder and camera stabilization gimbal (see Figure 1).
Current UAV software often refers to the software of the ground station. Software is usually used to route the crafts through waypoints and provide task functions such as image capturing, returning home, and route editing. Recently, ground station software releases on the mobile device platforms allowing operators to use tablets and smart phones to control the aircrafts.
AR Technology. A definition was made by Azuma (1997) who defined AR technology as “3-D virtual objects […] integrated into a 3-D real environment in real time”. AR refers to the technology that attaches elements augmented by computer-generated sensory input, such as video or graphics, to the live view of a physical or real world environment. It is a concept where a view or image stream of reality can be modified and re-rendered by a computer. As a result, the technology functions by enhancing one‘s perception of reality. AR has lots of applications in educational and industrial fields (Wang 2008) and (Fang et al. 2009), especially in the training environment (Wagner et al. 2010). For example, Columbia University’s Mobile Augmented Reality System (MARS) integrated a mobile computer and headset with a compass, inclinometer and global positioning systems (GPS), allowing users to see representations of buildings in specific locations (Höllerer et al. 1999).
CHALLENGES OF CONSTRUCTION MANAGEMENT
Restriction of surveillance camera. Surveillance plays an important role in construction management. It is not only for monitoring purpose but also for offering managers and engineers a different point of view of the site. Currently, surveillance systems applied in construction site often uses closed-circuit television (CCTV) technology. CCTV is the use of video cameras to transmit a signal to a specific place, on a limited set of monitors (Martin et al. 2005). To use CCTV, we need to mount many cameras in the construction site for multiple viewpoints in order to achieve largest visibility. Once we need to change or add another viewpoint, we need to send a worker into the field to manually install an extra camera. Also, the cameras are fixed on structure, which means we need to spare space for camera installation in the site. The procedure is costly and inefficient which cause the lack of camera mobility and surveillance instantaneity. Planning of construction site activities. The integration of onsite activities into the path planning and scheduling of construction projects requires clear spatial analyses as references. Arkady (1999) had done a survey in UK and found that there exist certain work practices that do not work out well for the effective planning and scheduling of the totality construction process. Since traditional methods such as site visiting, layout drawing, and method statements are short of presenting visualized experience, a visualization system allowing managers to see physically or virtually is an opportunity for computing in civil and building engineering.
THE UAV-AR SOLUTION IMPLEMENTATION
UAV Hardware and Software. We choose multi-rotor UAV as our aircraft type for its high stability, mobility and wind resistibility. Its power management (electricity efficiency) cannot be as efficient as fixed-wing UAV but above reasons are more critical to safety and onsite applicability. We prototyped the UAV using designed hardware structure (see Figure 2, 3) and corresponding components (see Table 1).
Used Hardware Components.
Flight controller
- 400Hz refresh frequency.
- 1.5W(0.3A@5V) max power consumption.
- 0.6W(0.12A@5V) normal power consumption.
Speed controller
- 50Hz to 432Hz refresh rate of the throttle signal.
- Input Voltage: 2-6 cells lithium battery.
Tarot RC Carbon Fiber Props 15x5.5
- 5200mAh capacity (parallel connection).
The BaseCam Electronics 2-axis Gimbal Controller
- 16mm (35mm equiv. = 24mm) focal length.
- f/2.8 to f/22 aperture adjustment.
iFlight TX52W Image Transmitter - 5.8GHz Radio Frequency.
AR Implementation. For AR implementation, we use Unity 3D as our development platform. We also use the AR extension Vuforia SDK 2.0 which is a product of Qualcomm Connected Experiences, Inc ( Vuforia is a software platform for Android and iOS that enables apps to see images from a Vuforia target database on the devices or in the remote accesses. When a target is recognized through camera on the UAV, developed app generates augmented reality experiences, presents new functionality and designed content. We would use this to mix scenes between virtual and real views. A 3D building will be able to layer on the image stream in realtime (see Figure 4).
Concepts of applying AR on the image stream from UAV
WLAN System for Multiple Devices. In order to enhance the convenience and efficiency of the onsite surveillance, we want to make a telecommunication system for multiple users to view the same image stream simultaneously. We applied WLAN transmission method to distribute the realtime image stream to multiple. It allows construction professionals, such as managers, architects, and engineers, to use their own devices (smart phones, tablets, and computers) to access the stream and share their opinions. We use a Febon 100 USB CVBS (A/V) UVC grabber card for converting the analog image stream input to digital and that allows us to do AR processing in the Vuforia. Then we output the rendered image stream to Febon 220 wireless station to realize a WLAN environment that is able to transmit the image stream. We can now take it as a remote IP camera. Users can simply use any of IP camera connection apps to gain access to our AR view (see Figure 5). By this way, since nearly every platform has apps for IP cameras, we maximize the compatibility of different platforms and create lots of possibilities to use the image stream, such as monitoring and other image processing technologies.

We have practiced our UAV-AR solution on a construction site. The field is an clear and flat square region sized up to 9164 m2. Our UAV was flying at altitudes of 150-200 meters. We designed a standard workflow for this practice. First, we fly to the top of the site and capture a photo of entire site with camera pointing down perpendicularly to the ground surface. Second, we land the UAV and process the captured photo for Vuforia as AR target feature and import a 3D building model into the scene. Our ground station then has the enough information (target and image stream) to mix the virtual and real environment and generate the AR view (see Figure 6). Once the computational procedure is done, we are ready to take off and view the AR representation. Finally, we connect the output of the image stream though WLAN system and a 32-inch LCD display in order to offer two viewing options in the field (see Figure 7).
Figure 6. (1) Actual site image. (2, 3, 4) Screenshots of AR views.
Figure 7. (Left) Demonstration setup. (Right) View through large display.

This paper described a developing method that supports practitioners in the planning and scheduling of onsite procedures, identified unaware problems associated with current practices, and presented an alternative perspective, AR view, in which onsite restriction might be difficult to overcome. The proposed UAV-AR system, based on state-of-art UAV and AR technology, can aid practitioners in visualizing not only the actual field environment but also the virtual construction in site organization. Decision makers and site planners can not only observe simulated projects under real scenarios but can also rehearse the work and interact with a virtual project by flying around the site, all in full correspondence with the project schedule.
Applying AR dynamic presentation facilitates the visual validation and simulation of the construction project progress and creates new possibilities for the planning process which are not available from other existing methods.
In the near future, we plan to test the UAV-AR solution in three common construction scenarios: typical building site, bridge inspection, and urban planning. For typical building site, we will work on applying the solution on different level of construction completion to see how it can help in different cases. Bridge inspectors perform condition assessments on aging bridge structures. With application of UAV-AR solution, there are lots of possibilities to discover problems that they can not see from existing methods. Urban planning usually requires large scale views to visualize it. Unlike orthomosaic method, we can also integrated it with 3D terrain models and let users interact with it.
Arkady, R., Aviad, S. (1999). "VR-based planning of construction site activities." Automation in Construction 8(6):
Azuma, R. (1997). "A survey of augmented reality." Presence: Teleoperators and Virtual Environments 6(4):
Dajiang 	Innovation 	Technology 	Inc. 	(2013). 	“NAZA-M-V2” 	DJI
Fang, H.C., Ong, S.K., and Nee, A.Y.C. (2009). “Robot programming using augmented reality.” International Conference on CyberWorlds, UK, September 7–11.
"Exploring MARS: developing indoor and outdoor user interfaces to a
Mobile Augmented Reality System." Computers and Graphics 23(6):
Martin, G., Angela, S. (2005). “Assessing the impact of CCTV.” London: Home Office Research, Development and Statistics Directorate.
Wagner, D., Reitmayr, G., Mulloni, A., Drummond, T., and Schmalstieg, A. (2010). “Real-time detection and tracking for augmented reality on mobile phones.” IEEE Transactions on Visualization and Computer Graphics, 16 (3):
Wang, X. (2008). “Improving human–machine interfaces for construction equipment operations with mixed and augmented reality.” C. Balaguer, M. Abderrahim, (Eds.), Robotics and Automation in Construction, InTech, Austria, 349–362.
