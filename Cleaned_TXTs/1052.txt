Construction Management and Economics, 1992, 10, 397—413
Parameter prediction for cash flow forecasting models
Department of Surveying, University of Salford, Salford M5 4 WT, UK
The paper describes the application ofthe DHSSformula to 27 completed construction projects comprising four types — steel-framed low rise buildings, new build housing developments, housing refurbishment projects, and multi-house 'pre-paint' maintenance contracts. Application of the formula to individual projects indicates that the 'best' parameter values offer a ten-fold improvement over the published values based on project size. Similar results occur when using the best parameter valuesfor other two parameter models.
Various approaches are considered in attempting to predict the best parameter values of the models based on known characteristics ofthe project. A multiple linear regression with project value, duration, and type independent variables is shown not to produce any significant improvement on standard DHSS formula predictions. However, a reduction in the number of independent variables by cross validation produces an approximately 25 % improvement on standard DHSS formula forecasts outside the data base. Examination of the models derived from this analysis indicate the type of project to be of major importance.
Cash flow, forecasts, project type, regression, cross validation.
Introduction
The model most commonly used for expenditure forecasting in the UK is the two parameter model derived by the Hudson (1978), commonly known as the DHSS formula. The values of the parameters are provided over a range of project sizes as a result of Hudson's analysis of a large number of hospital projects. Different parameter values should, according to Hudson, be used for different types of construction rather than the general practice of applying his parameter values to all types of work.
Since Hudson's work, the emcacy of the DHSS formula seems to have received little attention. Peer's (1982) analysis of a small sample of data indicated that projects within the same building type group had similar expenditure patterns even when they were of different size and had a different rate of progress. What is not clear, however, is the extent of the differences between building type groups, especially in comparison with the DHSS formula and Hudson's parameter values. Nor is it clear what kinds of building work constitute a group in terms of expenditure profiles generally.
In this paper the expenditure flows for a set of 27 completed projects is examined to assess the effect of different building type groups in relation to the DHSS and, for ease of comparison, other similar two parameter models. Firstly, the best parameter values for each
model for each project is found by a method of successive approximation. Secondly, a standard linear multiple regression is used to analyse and predict model parameters via the value, duration and project type group. Finally, a non linear technique is used to find the best set of predictors for each model for projects outside the data base. Analysis of the resulting models indicates that: 1 . the inclusion of the project type grouping significantly improves the predictive power of the models, 2. all have similar predictive power, and 3. the predictive power is approximately 25% better than the DHSS formula with Hudson's parameter values.
The data consisted of details of 27 completed construction projects in the United Kingdom, together with their associated estimated monthly values. The data were obtained from one single private practice quantity surveying firm and two local authority surveying departments. All contract values were rebased to 1974 prices by means of the RICS Building Cost Information Service Tender Price Index (Appendix A).
Four project type groups were involved — steel-framed low rise buildings, new build housing developments, housing refurbishment projects, and multi-house 'pre-paint' maintenance contracts. The cumulative gross value of work executed, before adjustment for retention or fluctuations, was used since these adjustments vary between projects and may distort any model trying to reflect a general trend. In practice, of course, such adjustments can easily be applied for a specific project as an adjunct to the results provided by an expenditure model. Clearly, some knowledge of the likelihood of cost and time overruns is needed for a comprehensive treatment of the subject and it is intended to address this issue as an extension of the work described.
No adjustments were made for any inter-project variations such as winter working, industry holidays or delivery to site of steel or mechanical plant, since these adjustments were considered to be relatively small and have little effect on the results. An extension of the work to cover these aspects is also under consideration.

Four alternative models were considered: 1. the DHSS formula (Hudson, 1978); 2. the Kenley Wilson formula (Kenley and Wilson, 1989); 3. the Miskawi formula (Miskawi, 1989), and 4. the Berny—Howes formula (Berny and Howes, 1982). For comparative purposes, the following notation is adopted: V = total value of the contract (E); D=total duration of contract (days); v = percentage value complete; d = percentage of time complete;
a and b are constants.
prediction for cashflow x = d/100
The Kenley—Wilson formula is

The Miskawi formula is
The Berny—Howes formula is
Two problems are immediately apparent with these formulae. Firstly, the Kenley—Wilson formula contains the divisor 100—d which implies that 100 > d. It is important therefore to either omit values where d= 100 or raise the value of 100 slightly to say 100.1. The latter method has been adopted in this study. Secondly, the Miskawi formula contains a power variable 3d which is clearly inappropriate for d values approaching 100. This was overcome by substituting a new constant b for the d power in the formula.
Estimates of the DHSS formula constants, a and b, are provided by Hudson (1978) based on the contract value of the project. This method is termed here the standard DHSS formula. An attempt was made to estimate the values of the constants in the four formulae by method of
least squares, i.e. to minimize for each project

n are the valuation points recorded.
This was done numerically by a method of successive approximation for each of the 27 project data sets. The results are shown in Table 1 together with the mean square error
As the Table shows, no results were obtained for 1 3 of the Miskawi formula applications, due to the lack of a minimum least squares result within the bounds allowed (0 Sac 100). The Berney-Howes b values for projects 5, 6, 10, 24 and 26 may be regarded as spurious as, when a=0, v=x, a straight line.
The substantial, around ten-fold, improvement brought about by using 'best' estimates of the formulae constants is certainly encouraging. It should be noted however that the method of least squares is limited to a simple quantification of the aggregated differences between the model's predictions and the observed values and therefore provides no specific information concerning counter-intuitive predictions, such as negative values at the beginning and end of the curve, that sometimes occur with such one-element polynomial models. More sophisticated multi-element models exist to overcome these problems by providing independent variables potentially capable of modelling greater extremes and variability in expenditure (e.g. Tucker, 1986; Tucker, 1988; Khosrowshahi, 1991 ). Bearing in mind these limitations, a further analysis was conducted aimed at investigating the relationship between the model parameters and characteristics of the projects involved.
Analysis offormulae constants
Discussion. The first approach to this was to examine the relationship between the a and b values and the MSQ (a,b) for each project. The MSQ (a,b) was calculated over a range of a and b values and plotted in the form of a contour map. Figure I gives the results for project 3 analysed by the Kenley—Wilson formula. Although not contributing very much to the overall analysis, the contour maps were found to be a useful aid in understanding the nature of the lack of fit of the formulae between projects, particularly the sensitivity of the a and b parameter values on model performance.
These contour maps nicely illustrate the task in hand, which is to find a meaningful grouping of similar maps. This raises two issues. Firstly, what constitutes a 'meaningful' grouping, and secondly, what measure of similarity should be used?
The answer to the first of these questions is relatively straightforward and depends on the purpose of the analysis. In our case, the object was to find some suitable predictors that would be readily available in the project preconstruction phase. The standard DHSS formula, for instance, uses the contract value as a predictor. Other obvious predictors include the project type and duration.
predictionfor cashflow
The bounds of MSQ are defined as follows :

Contour map of MSQ for Project 3.
In addressing the second question, several approaches are available. One is to conduct a cluster analysis on the  grid. This would group similar project maps together from which we may be able to detect some pattern relating to say project type or size. A similar alternative is a factor analysis on the maps together with the type, value and duration
characteristics of interest. This would provide factor loadings that we may be able to interpret in terms of desired groupings. Another possibility is to revert back to the best estimates of a and b for each project and use multiple regression analysis on each with the project characteristics as independent variables. Major problems exist with each of these alternatives, the cluster and factor analysis only providing a limited connection between the MSQ(a b) values and the project characteristics of interest, and the regression analysis only utilizing a small part of the potential data present in the maps. Perhaps the biggest problem, however, is that all three approaches, being essentially linear models, rely on euclidian measures of the error term. In our case the error term is clearly non linear, being defined by Equations 1 to 4 above. As a result of these deliberations it was decided to utilize the method of successive approximation in the analysis of project characteristics.
Figure 2 shows the intended model conceived prior to analysis. This (Tl , T2 and T3) incorporates the three project characteristics ofinterest — project type, size (small/large), and duration (short/long) — as predictors of the a and b constants in Equations 1 to 4.
given project type, the required a and b values will lie on the line shown. Similarly for a given size and duration, the a and b values will lie on these (different) lines. Thus the correct a and b values for a project of given type, size and duration will lie somewhere in the triangle described at the intersection of the three lines (a proper statistical treatment would define the boundaries in probabilistic terms but this is beyond the capabilities of the relatively crude method (and researcher) employed here).
The implications of this in mathematical terms is that
where Tk is the type, k, of project and and represent the position and slope respectively of the lines.
Now by calculating the SSQ (a,b) over all the projects for a series of b values, the method of successive approximation can be used to estimate the values of and for each of the project characteristics.
The resulting and ß estimates for the Kenley Wilson formulation are given in Table 2. Figure 3 shows the actual model for V = 100 000, 500 000, 1 000 000, D = 100, 500, 1000, and the project types 1 to 4. As the figure shows, the hoped for convex-like structure of Figure 2 is absent, the parallel nature of the lines indicating a general lack of orthogonality among the variables. Similar results were also obtained for the DHSS and Berny—Howes alternatives.
Duration (D/IOO)
The lack of a convenient convex-like arrangement for model 1, together with the knowledge that the solution space (if it existed) resulting from this method may not neccessarily contain optimal estimates of the required a and b constants, suggests a better model to be the more obvious regression type of approach:
where Vis the contract value, in 100 000 units, D is the contract duration, in 100 day units, and T1, T2, and T4 are dummy variables representing project types 1, 2 and 4 found in the data. It is then proposed to minimize Equation 5 as before by inserting suitable and ß values into Equations 14 and 15 simultaneously (naturally one of the project types, type 3 in this case, must be omitted from the analysis to avoid over specification).
The method of successive approximation was again employed and the necessary and ß estimates obtained. The results for the Kenley—Wilson formulation are given in Table 3 (SSQerror — 13 981). The presence of 12 variables for only 27 cases is not particularly satisfactory — we would normally prefer the number of cases to be at least three to four time flow
the number of variables — but the results provide an indication of the general relative influence of the variables selected.
Reliability. As the most important application of the analysis is in forecasting values of the constants, 'error of forecast' or 'error rate' estimates are likely to be the most relevant and useful. * Two types of error rate estimates are available — parametric and non parametric. In this case a non parametric error rate estimate was considered to be most appropriate due to 1 . the small sample size, as the coefficient estimates are likely to be biased, and 2. although the least squares approach used here is known to be robust for mild departures from the implicit assumptions of the approach, i.e. normally distributed errors, the parametric estimates of the error rates of the approach are not necessarily robust in themselves.
Non parametric error rate estimators, and in particular, resampling methods are known to produce improved estimators of the error rates by appropriate bias correction of the apparent (error of prediction) error (McLachlan, 1987).
Three possible resampling methods were considered; I . cross validation, where one case is omitted in turn from the model derivation and the resulting coefficients applied to that case; 2. the jackknife method, where one case is omitted in turn from the model derivation and the resulting coemcients applied to the other cases; and 3. the bootstrap method, where the coefficients are used to generate simulated data from which a second set of coeffcients are obtained. For predictive applications, the cross validation method 1 . has the most intuitive appeal as, with the non time series data of this nature, each error value can be thought of as a real error that may arise in the 'real world' practice of forecasting.
For the data under study, cross validation involves the repeated estimation of regression coefficients for a series of selected case removals, in this case with one project removed for each estimation a total of 27 repeats. Thus and [3 estimates were made as described above but with project 1 removed from the data base. The a and b values were calculated from Equations 14 and 15, and the MSQ (a,b) error obtained for project 1. This was repeated for all the projects in turn. The results for the Kenley Wilson formulation are shown in Table 4.
Each row in this Table give the results of applying to that case the parameter estimates obtained by analysis of the data for all the other cases. The overall average MSQ is 80.34, a slight improvement over the standard DHSS equivalent of 81.79 (Table 1).
Variable parsimony. Previous experience of cross validation suggests that a reduced number of variables may increase the predictive ability of the model (Skitmore and Patchell, 1990). Ideally we should wish to extract the subset of variables which produces the lowest overall average MSQ. Some of the standard computer based statistical analysis procedures are able to provide this for more routine problems. Unlike standard parametric procedures however, where the significance of variables entering in and exiting from the equation may be readily obtained, the use of non parametric error rate estimates together with the non linear model is a major computational task.
To find the best subset involves the consideration of all possible combination of 1 to 12 variables, i.e.
As each combination involves the computation of a Table similar to Table 4, a task currently
*These measures of error concern the relationship between the actual values of a case variable and the value predicted by the model where the model is derived from a data base which does not include that case.
flowforecasting
requiring approximately 6 minutes cpu time, a full analysis of this kind would take over 34 days of computing time!
Several parametric approximating methods are available which may be utilized to reduce the computational burden. The most well known of these are forward, backward, and step wise regression. Forward regression involves the sequential selection and retention of individual variables most contributing to the reduction of the SSQ error term. Backward regression involves the sequential deletion of individual variables least contributing to the reduction in the SSQ error term. Stepwise regression is a combination of both forward and backward regression.
The use of all these methods in parametric problems has a common diffculty. As each variable is added to the equation, the SSQ error always reduces thus making the choice of termination criteria an important issue. With non parametric approaches, such as the cross validation method used in this study, the termination criteria is simply the reduction in SSQ error, as both forward and backward methods produce reductions that seem to tend to an optimal like solution.
Two methods were used in this analysis 1. forward regression to minimal SSQ error, followed by a stepwise regression of backward to minimum, forward to minimum etc; 2. backward regression to minimal SSQ error, followed by a step wise regression of forward to minimum, backward to minimum etc.
For the DHSS formulation, the forward regression resulted in the progressive inclusion of ßo (99.29), (75.34), (65.24), ß4 (60.20), and ß3 (59.98) whilst the backward regression eliminated only (75.00). The progressive mean square error is given in brackets. The Kenley—Wilson formulation forward regression resulted in the inclusion of ßo (99.80), (74.26), (67.79), (64.39), (61.94) and ß4 (61.21), followed by the backward exclusion of ao (60.25), whilst the backward regression eliminated (70.19), (64.10), (61.64) and (59.63). The Berny Howes formulation forward regression resulted in the inclusion of (72.21), [33 (68.72), ß5 (66.50), [30 (66.09) and (61.81 ), whilst the backward regression eliminated 132 (81.71 ) and ßl (71.07). The resulting best models are summarized in Table 5.
Several points of interest emerge from this analysis of the parsimonious models:
Summary of regression results
All models give similar results in terms of reliability with an MSQ improvement over the standard DHSS model (81.79 MSQ) of 26.8, 27.1 and 24.4 per cent for the DHSS, Kenley—Wilson, and Berny Howes formulations respectively;
All models include all the project type measures;
Only the Kenley—Wilson model utilizes the contract value measure;
None of the models include or ß2 — the duration related measures.
Revised models. The coemcient estimates of the revised models are shown in Table 6. The standard error values of the coemcients were not available but the mean square errors associated with the models were computed for comparative purposes. The resulting parameter estimates and mean square errors for each of the projects are shown in Table 7. Comparison with Table 1 confirms the improved predictive ability of the models over the standard DHSS model. It is of interest to note that the revised DHSS model, in contrast with the standard DHSS model does not contain any 'size' parameters.
The DHSS formula, since Hudson, seems to have received little testing on hospital or any other projects. This paper has described its application to some data concerning the expenditure flow on four types of projects — steel-framed low rise buildings, new build housing developments, housing refurbishment projects, and multi-house 'pre-paint' maintenance contracts. Comparison of the formula applied to individual projects using the recommended parameter values with the best parameter values, indicates that tenfold improvements may be made. Using the best parameter values for some other two parameter models produced similar results.
Various possibilities were considered in attempting to predict the best parameter values for the two parameter models based on known characteristics of the project. A multiple linear regression with project value, duration, and type independent variables failed to produce any significant improvement to the standard DHSS formula. However, a reduction in the number of independent variables by means of a cross validation approach produced an approximately 25% improvement on the standard DHSS formula by all the alternative models. Examination of the models derived from this analysis indicated the type of project to be a major contributor to this improvement with contract value being of lesser importance.
The work described in this paper provides an interesting example of the benefits of assessing the emcacy of regression models by reference to forecasts outside the data base of the analysis. In using the cross validation approach, the model is developed and tested
Results with the revişed formulae
simultaneously on this criteria. This clearly has considerable intuitive appeal. in addition, the fortuitous convex-like nature of the cross validation procedure when applied to these data provides an unexpected and welcome means of automatic variable parsimony. Future work Will extend the method to more complex multi„variable models incorporating time-cost overruns, seasonal variations, etc.
The author would like to acknowledge the contributions of Vernon Marston and Jon Tylee, both of Salford University Department of Surveying, in the collection of data, provision of references, and advice on the analysis described in this paper. Thanks are also due to the two anonymous reviewers who pointed out several errors and oversights in the first draft of the paper.
