Role of Data Analytics in Infrastructure Asset
Management: Overcoming Data Size and Quality Problems
This study explores the performance regime of different classification algorithms as they are applied to the analysis of asphalt pavement deterioration data. The aim is to examine how different algorithms deal with the typically limited and low-quality data sets in the infrastructure asset management domain, and whether better configurations of relevant algorithms help overcome these limitations. Furthermore, the emphasis on choosing the most affordable attributes (e.g., temperature and precipitation levels) makes the results reproducible to smaller municipalities. This analysis used the data of more than 3,000 examples of road sections, which were retrieved from the Long-Term Pavement Performance (LTPP) database. The algorithms examined in this study include two types of decision trees, naïve Bayes classifier, naïve Bayes coupled with kernels, logistic regression, k-nearest neighbors (k-NN), random forest, and gradient boosted trees. The performance of these algorithms is compared, and their weaknesses and strengths are discussed. They were all applied to predict the deterioration of pavement condition index (PCI). Of specific importance is the positive role of ensemble learning. It is shown how using higher efficiencies by using ensemble learning can compensate for data shortcomings. The accuracy of some of the models in predicting the PCI after 3 years exceeded 90%. Suggestions are made to improve the performance of some algorithms. For instance, the naïve Bayes classifier was coupled with kernel estimates to achieve a better accuracy. It is demonstrated that using kernel estimates can increase the accuracy of the naïve Bayes classifier dramatically. Further, the study examines the impact of data segmentation. Data were divided into four different climatic regions. The accuracy of prediction was sufficiently high after segmentation, with the highest accuracy in the dry and nonfreeze zone and the lowest performance in the region with a wet and freezing climate. 10.1061/JPEODX.0000175. © 2020 American Society of Civil Engineers.
Author keywords: Machine learning; Ensemble learning; Transportation asset management; Pavement condition index; Highway maintenance; Data preparation.
Introduction
Transportation asset management (TAM) planning helps municipalities keep their road networks in an acceptable level of service with a limited budget. One of the basic, yet very necessary, steps in preparing a TAM plan is assessment of current and prediction of future road conditions (El-Diraby et al. 2017). However, the accuracy of such assessments is hampered by the typically limited data size and, equally important, the lower quality of the data themselves [i.e., missing (El-Diraby et al. 2017; Piryonesi and El-Diraby 2020), inconsistent (Gharaibeh et al. 2010), and inaccurate data (Abdelaty et al. 2018)]. This study aims to examine the role of analytics algorithms not only in predicting conditions/deterioration in roads, but also doing so with limited data sets. So, an important question is if some algorithms can address this typical problem in asset management.
The selected target variable for deterioration modeling in this study is the pavement condition index (PCI). The PCI has a
Instructor, Dept. of Civil and Mineral Engineering, Univ. of Toronto, 35 St. George St., Toronto, ON, Canada M5S 1A4 (corresponding author).
Professor, Dept. of Civil and Mineral Engineering, Univ. of Toronto, 35 St. George St., Toronto, ON, Canada M5S 1A4.
Note. This manuscript was submitted on May 21, 2019; approved on December 2, 2019; published online on April 8, 2020. Discussion period open until September 8, 2020; separate discussions must be submitted for individual papers. This paper is part of the Journal of Transportation Engineering, Part B: Pavements, © ASCE, ISSN 2573-5438.
significant role in all TAM decisions. It is one of the main indicators for measuring asphalt road deterioration and assessing levels of service. In fact, 58 municipalities in Ontario, Canada, were surveyed about the type of performance indicators they use to represent the level of service of their roads. As shown in Fig. 1, the PCI was the most popular. Yet, there is limited research on the application of machine learning to PCI prediction. With an exception of two studies that targeted PCI (e.g., Piryonesi and El-Diraby 2018; Kırbaş and Karaşahin 2016), most researchers have focused on predicting the International Roughness Index (IRI) or the analysis of a single distress. This could be because preparing PCI values from the Long-Term Pavement Performance (LTPP) database requires some data preparation effort (Piryonesi and El-Diraby 2018; Shahnazari et al. 2012; Table 1 reviews related work in this domain (43 studies). Fig. 2 also offers a breakdown of studies that addressed pavement performance modeling.
Although the PCI is important in itself, because this study’s analysis is targeting the effects of data size and algorithms, PCI predictions serve as a case for such a line of analysis. Future studies can benchmark this work to conduct similar analyses to address data limitations for other performance measures of TAM.
The deterioration of roads is a complicated nonlinear process that depends on many factors that relate to design characteristic, climatic, and operational attributes. Such a complicated and context-sensitive phenomenon cannot be easily formulated using a single logical syllogism or a mathematical formula. It requires analyses that are sophisticated enough to consider different facets of the problem. However, currently, most DOTs and municipalities
Performance indicators used by municipalities in Ontario, Canada.
depend on deterioration curves for predicting road condition (El-Diraby et al. 2017; Despite their simplicity and popularity, these curves have a few drawbacks. First, they are deterministic and cannot take into account uncertainties. Furthermore, they only rely on age and overlook important attributes such as the maintenance history and traffic of roads (Ens 2012; Piryonesi and El-Diraby 2018; Other deterioration models, such as Markov models, can address some of these drawbacks (Black et al. 2005; Li et al. 1996). For instance, Markov models are probabilistic. However, they have been criticized for disregarding the maintenance history of roads (Ens 2012; Piryonesi and Tavakolan 2017).
Data analytics is an alternative tool for predicting the deterioration of roads. However, it is not as popular as the aforementioned techniques. This lack of popularity rooted in two possible reasons: (1) the lack of reliable data for training models (Abdelaty et al. 2018; El-Diraby et al. 2017; and (2) the lack of interpretability. The latter results from most previous studies tending to use neural networks, which are not easy to interpret (Ford et al. 2012). A handful of researchers have used more intelligible classifiers, such as decision trees, but they reported accuracy numbers that may not be high enough (Chi et al. 2014; Piryonesi and El-Diraby 2017, 2018).
In this paper, ensemble learning is deployed as a solution to the low accuracy of classifiers in predicting the future condition of roads. Particularly, boosting and bagging as two examples of ensemble learning are showcased, and their results are compared and interpreted. The main advantage of these approaches is that a more accurate model can be trained by merging weak learners such as decision trees. The training data were retrieved from the LTPP database.
Furthermore, in this paper, different types of classifiers are examined, and their weaknesses and strengths are explained. Some solutions for improving the accuracy of classifiers are discussed and implemented. The following algorithms were considered in this comparison.
Naïve Bayes Classifier
As the name suggests, naïve Bayes classifier works based on the Bayes rule. Prior and conditional probabilities are calculated from the data set. For continuous variables, a univariate Gaussian distribution is used to estimate their class-conditional marginal densities. A histogram is used for discrete attributes. The underlying assumption of this classifier is that predictor attributes are independent; hence, it is called naïve. This simple classifier is popular when the number of features is large given its small computational complexity (Hastie et al. 2009; Provost and Fawcett 2013).
Naïve Bayes Classifier with Kernel
Kernel density estimation could help increase the accuracy of a naïve Bayes classifier. Kernel, in this context, is a localization technique and should not be confused with the kernel method. The latter is used for regularized nonlinear modeling coupled with algorithms such as support vector machine (Hastie et al. 2009). When coupled with naïve Bayes classifiers, kernel density estimates are used to estimate conditional marginal densities of each class. Different functions, such as Gaussian or Epanechnikov, could be used for local smoothing (Hastie et al. 2009). In this paper, Gaussian kernels are used. Naïve Bayes per se is a nonparametric algorithm. However, when using a kernel-based naïve Bayes classifier, the user should set two parameters: the bandwidth and the number of kernels.
Decision Trees
Decision trees are among the most popular classification algorithms. Part of their popularity stems from their intelligibility and ease of interpretation. As their name suggests, these algorithms generate a classifier tree based on the trends in the data set. Primitive versions of decision trees, such as iterative dichotomiser 3 (ID3) and concept learning system (CLS), were only able to learn from discrete data (Wu et al. 2008), whereas their descendants (e.g., C4.5) are capable of learning from both continuous and discrete variables.
Decision trees create segmentation of the data set. They start with the most informative attribute and split the data based on a test. Therefore, at least two branches grow out of each node. Then, the nodes in each branch will split based on their informativeness. The terminal node of a tree is called a leaf, which is ideally pure and belongs to a particular class. Different trees may use different measures for defining informativeness. Most trees rely on entropy or the Gini index (Hastie et al. 2009; Provost and Fawcett 2013; Wu et al. 2008). The information gain and level of homogeneity of each leaf will be determined through the parameters of the tree (Lin and Chen 2012).
Ensemble Learning
Ensemble learning refers to a group of technique that include combining multiple base learners to diminish their weaknesses and superpose their strengths. The general process of ensemble learning is twofold, first generating a population of base learners from the training set and then combining them to create the strong predictor. Different ensemble techniques have different approaches for combining the base learners. Two important categories of ensemble learning include bagging and boosting. These, respectively, rely on committee voting and weighted voting (Hastie et al. 2009). In this paper, both approaches were used, and it was shown that although both methods increase the accuracy of a classifier, boosting is more effective given its more sophisticated learning process.
Condition assessment and deterioration modeling are not only the basis for maintenance and rehabilitation, but also help decision makers proactively develop capital planning and schedule future maintenance interventions. Some of the most well-known measures
Summary of studies on pavement performance modeling

Size of training data
